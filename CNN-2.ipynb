{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOEkhI0A5+RTD2eLLlCLFBY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Uf2O4akJw55s"},"outputs":[],"source":["import pandas as pd\n","import pickle\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","from keras import backend as K\n","from keras.models import load_model, Model\n","from keras.layers import Flatten, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.layers import LeakyReLU\n","#!pip install np_utils\n","from keras import utils\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# set random seeds\n","\n","# removed the import statement for set_session from tensorflow.compat.v1.keras.backend\n","np.random.seed(1)\n","tf.random.set_seed(2)\n","\n","# limit gpu usage for keras with tensorflow 1\n","# config = tf.compat.v1.ConfigProto()\n","# config.gpu_options.allow_growth = True\n","# set_session(tf.compat.v1.Session(config=config))\n","\n","# If you need to use set_session, try this instead:\n","# from tensorflow.python.keras.backend import set_session"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q6PQSjXoxJqn","executionInfo":{"status":"ok","timestamp":1741392932020,"user_tz":300,"elapsed":22175,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"893da979-e5dd-4f6c-d1a7-4393d42eb9f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\n","import os\n","if not os.path.isfile('/content/drive/MyDrive/LOBCNN/data/data.zip'):\n","    !wget https://raw.githubusercontent.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/master/data/data.zip\n","    !unzip -n data.zip\n","    print('data downloaded.')\n","else:\n","    print('data already existed.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rLMgziZxLuf","executionInfo":{"status":"ok","timestamp":1741392933497,"user_tz":300,"elapsed":1478,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"64c74542-c312-4760-c43e-b2a9452884cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data already existed.\n"]}]},{"cell_type":"code","source":["def prepare_x(data):\n","    df1 = data[:40, :].T\n","    return np.array(df1)\n","\n","def get_label(data):\n","    lob = data[-5:, :].T\n","    return lob\n","\n","def data_classification(X, Y, T):\n","    [N, D] = X.shape\n","    df = np.array(X)\n","    dY = np.array(Y)\n","    dataY = dY[T - 1:N]\n","    dataX = np.zeros((N - T + 1, T, D))\n","    for i in range(T, N + 1):\n","        dataX[i - T] = df[i - T:i, :]\n","    return dataX.reshape(dataX.shape + (1,)), dataY\n","\n","def prepare_x_y(data, k, T):\n","    x = prepare_x(data)\n","    y = get_label(data)\n","    x, y = data_classification(x, y, T=T)\n","    y = y[:,k] - 1\n","    y = utils.to_categorical(y, 3)\n","    return x, y"],"metadata":{"id":"2pNXow5axOqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dec_data = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Train_Dst_NoAuction_DecPre_CF_7.txt')\n","dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n","dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n","\n","dec_test1 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_7.txt')\n","dec_test2 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_8.txt')\n","dec_test3 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_9.txt')\n","dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n","\n","k = 4 # which prediction horizon\n","T = 100 # the length of a single input\n","n_hiddens = 64\n","checkpoint_filepath = './model_tensorflow1_weights'\n","\n","trainX_CNN, trainY_CNN = prepare_x_y(dec_train, k, T)\n","valX_CNN, valY_CNN = prepare_x_y(dec_val, k, T)\n","testX_CNN, testY_CNN = prepare_x_y(dec_test, k, T)\n","\n","print(trainX_CNN.shape, trainY_CNN.shape)\n","print(valX_CNN.shape, valY_CNN.shape)\n","print(testX_CNN.shape, testY_CNN.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZO39HwpoxQSV","executionInfo":{"status":"ok","timestamp":1741392959017,"user_tz":300,"elapsed":25480,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"904993ac-2e53-43ae-df0c-f90942a4425b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(203701, 100, 40, 1) (203701, 3)\n","(50851, 100, 40, 1) (50851, 3)\n","(139488, 100, 40, 1) (139488, 3)\n"]}]},{"cell_type":"code","source":["def create_cnn2(T, NF, number_of_lstm):\n","    input_lmd = Input(shape=(T, NF, 1))\n","\n","    # build the convolutional block\n","    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(input_lmd)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","\n","    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","\n","    conv_first1 = Conv2D(32, (1, 10))(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n","\n","    # build the inception module\n","    convsecond_1 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n","    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n","    convsecond_1 = Conv2D(64, (3, 1), padding='same')(convsecond_1)\n","    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n","\n","    convsecond_2 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n","    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n","    convsecond_2 = Conv2D(64, (5, 1), padding='same')(convsecond_2)\n","    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n","\n","    convsecond_3 = MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n","    convsecond_3 = Conv2D(64, (1, 1), padding='same')(convsecond_3)\n","    convsecond_3 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_3)\n","\n","    convsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n","    conv_reshape = Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(convsecond_output)\n","    conv_flatten = Flatten()(conv_reshape)\n","    out = Dense(3, activation='softmax')(conv_flatten)\n","    model = Model(inputs=input_lmd, outputs=out)\n","    adam = keras.optimizers.Adam(learning_rate=0.0001)\n","    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","cnn2 = create_cnn2(trainX_CNN.shape[1], trainX_CNN.shape[2], n_hiddens)\n","cnn2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ynjZibxxxR3E","executionInfo":{"status":"ok","timestamp":1741392961827,"user_tz":300,"elapsed":1797,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"e13766d4-743b-4f46-f2d3-5e3597ff6314"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m96\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m2,080\u001b[0m │ leaky_re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m10,272\u001b[0m │ leaky_re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m2,112\u001b[0m │ leaky_re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m2,112\u001b[0m │ leaky_re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_9 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m12,352\u001b[0m │ leaky_re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m20,544\u001b[0m │ leaky_re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m2,112\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_10            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n","│                           │                        │                │ leaky_re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n","│                           │                        │                │ leaky_re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19200\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m57,603\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ leaky_re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10,272</span> │ leaky_re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ leaky_re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ leaky_re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ leaky_re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ leaky_re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_10            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ leaky_re_lu_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n","│                           │                        │                │ leaky_re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n","│                           │                        │                │ leaky_re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19200</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">57,603</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,051\u001b[0m (523.64 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,051</span> (523.64 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,051\u001b[0m (523.64 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,051</span> (523.64 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["%%time\n","weights_path = '/content/drive/MyDrive/weights_best_CNN.hdf5'\n","cnn2.load_weights(weights_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XiEwO6NKxZqk","executionInfo":{"status":"ok","timestamp":1741392962249,"user_tz":300,"elapsed":419,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"273fad6f-9684-400e-b3d7-1a90c50b308b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 42.4 ms, sys: 11.8 ms, total: 54.2 ms\n","Wall time: 863 ms\n"]}]},{"cell_type":"code","source":["test_loss, test_acc = cnn2.evaluate(testX_CNN, testY_CNN)\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_acc}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zHr52WrxcdU","executionInfo":{"status":"ok","timestamp":1741051798542,"user_tz":300,"elapsed":17449,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"b7d29ac5-66dc-4b9c-fcb8-4358c8d77ade"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.7863 - loss: 0.5594\n","Test Loss: 0.6089046001434326\n","Test Accuracy: 0.7606604099273682\n"]}]},{"cell_type":"code","source":["# Step 2: Make predictions\n","y_pred = cnn2.predict(testX_CNN)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true = np.argmax(testY_CNN, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrPAHOXdxd90","executionInfo":{"status":"ok","timestamp":1741051813127,"user_tz":300,"elapsed":14582,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"9a834949-30fa-4fab-c063-2f0798fb6d1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step\n"]}]},{"cell_type":"code","source":["print(classification_report(np.argmax(testY_CNN, axis=1), np.argmax(cnn2.predict(testX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaF3HhimxgdW","executionInfo":{"status":"ok","timestamp":1741051826348,"user_tz":300,"elapsed":13215,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"c42c98f9-476c-4c30-968e-5ef074c830e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.77      0.75     47915\n","           1       0.82      0.76      0.79     48050\n","           2       0.73      0.76      0.74     43523\n","\n","    accuracy                           0.76    139488\n","   macro avg       0.76      0.76      0.76    139488\n","weighted avg       0.76      0.76      0.76    139488\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve, auc\n","\n","# Get predicted probabilities for the positive class\n","y_pred_proba = cnn2.predict(testX_CNN)[:, 1]\n","\n","# Calculate precision and recall\n","precision, recall, thresholds = precision_recall_curve(testY_CNN[:, 1], y_pred_proba)\n","\n","# Calculate area under the curve\n","auc_score = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label=f'AUC = {auc_score:.2f}')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"8G5z-gBjxiU-","executionInfo":{"status":"ok","timestamp":1741051840213,"user_tz":300,"elapsed":13862,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"84295849-3018-453e-ec31-3c029a25a2da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["train_loss, train_acc = cnn2.evaluate(trainX_CNN, trainY_CNN)\n","print(f\"Test Loss: {train_loss}\")\n","print(f\"Test Accuracy: {train_acc}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwoEtVwdxkUE","executionInfo":{"status":"ok","timestamp":1741051886380,"user_tz":300,"elapsed":22541,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"253d85e9-f1c0-450e-c484-437bdc59623f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.4593\n","Test Loss: 0.4447004199028015\n","Test Accuracy: 0.8298584818840027\n"]}]},{"cell_type":"code","source":["print(classification_report(np.argmax(trainY_CNN, axis=1), np.argmax(cnn2.predict(trainX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-Fsfx3IxyK0","executionInfo":{"status":"ok","timestamp":1741051912412,"user_tz":300,"elapsed":21322,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"3cea4edb-0562-4c0b-9505-ebbf4d967413"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.86      0.84     84426\n","           1       0.81      0.72      0.76     36210\n","           2       0.83      0.85      0.84     83065\n","\n","    accuracy                           0.83    203701\n","   macro avg       0.83      0.81      0.82    203701\n","weighted avg       0.83      0.83      0.83    203701\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve, auc\n","\n","# Get predicted probabilities for the positive class\n","y_pred_proba = cnn2.predict(trainX_CNN)[:, 1]\n","\n","# Calculate precision and recall\n","precision, recall, thresholds = precision_recall_curve(trainY_CNN[:, 1], y_pred_proba)\n","\n","# Calculate area under the curve\n","auc_score = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label=f'AUC = {auc_score:.2f}')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"rF31FBpkx40k","executionInfo":{"status":"ok","timestamp":1741051937023,"user_tz":300,"elapsed":19282,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"c5788561-f2da-4bd5-f1de-0ed57be90a20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["\"TRADING STRATEGY ON TEST BEFORE ATTACK\""],"metadata":{"id":"yylSSJNUENEE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import numpy as np\n","import pandas as pd\n","\n","print(\"Getting predictions...\")\n","train_predictions = cnn2.predict(testX_CNN)\n","\n","# First define our strategy function\n","def implement_fi2010_strategy(predictions, dec_data, budget=100, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"\n","    Implements trading strategy using the FI-2010 paper's methodology\n","\n","    Args:\n","        predictions: numpy array of model predictions (n_samples, 3)\n","        dec_data: numpy array of decoded price data\n","        budget: amount to invest per trade\n","        prob_threshold: probability threshold for trading\n","        k: prediction horizon (number of steps to look ahead)\n","        alpha: threshold for determining price movement direction\n","    \"\"\"\n","    # Get normalized ask and bid prices\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","\n","    trades_info = []\n","\n","    for i in range(k, min_length):\n","        # Calculate m+ (future average)\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","        max_prob = np.max([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","\n","        if max_prob > prob_threshold and pred_class != 1:  # not stable\n","            # Determine actual direction using same threshold as training\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","\n","            # Long trade (UP prediction)\n","            if pred_class == 2:\n","                shares = budget / mid_prices[i]\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 2],\n","                    'correct': actual_direction == 1,\n","                    'index': i\n","                })\n","\n","            # Short trade (DOWN prediction)\n","            elif pred_class == 0:\n","                shares = budget / mid_prices[i]\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 0],\n","                    'correct': actual_direction == -1,\n","                    'index': i\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","\n","        # Print performance metrics\n","        print(\"\\nTrading Performance:\")\n","        print(f\"Total trades: {len(trades_df)}\")\n","        print(f\"Win rate: {(trades_df['correct'].mean() * 100):.2f}%\")\n","        print(f\"Total profit: ${trades_df['profit'].sum():.2f}\")\n","        print(f\"Average profit per trade: ${trades_df['profit'].mean():.4f}\")\n","\n","        print(\"\\nDirection Analysis:\")\n","        for direction in ['up', 'down']:\n","            mask = trades_df['movement'] == direction\n","            if mask.any():\n","                direction_df = trades_df[mask]\n","                print(f\"\\n{direction.upper()} trades:\")\n","                print(f\"Count: {len(direction_df)}\")\n","                print(f\"Win rate: {(direction_df['correct'].mean() * 100):.2f}%\")\n","                print(f\"Total profit: ${direction_df['profit'].sum():.2f}\")\n","                print(f\"Average profit: ${direction_df['profit'].mean():.4f}\")\n","\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","# Test different probability thresholds\n","thresholds = [0.8, 0.85, 0.9, 0.95, 0.99]\n","results = []\n","\n","print(\"Testing strategy with different thresholds...\")\n","for threshold in thresholds:\n","    print(f\"\\nTesting threshold: {threshold}\")\n","    result = implement_fi2010_strategy(\n","        predictions=train_predictions,\n","        dec_data=dec_test,\n","        prob_threshold=threshold,\n","        k=4,\n","        alpha=0.001\n","    )\n","    if result:\n","        results.append(result)\n","\n","# Create summary table\n","if results:\n","    results_df = pd.DataFrame(results)\n","    print(\"\\nSummary of results for different probability thresholds:\")\n","    pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))\n","    print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tb5LQYQrx_VE","executionInfo":{"status":"ok","timestamp":1741052020714,"user_tz":300,"elapsed":32136,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"cff6485b-f2e5-4798-e092-e11f3fd25100"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting predictions...\n","\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step\n","Testing strategy with different thresholds...\n","\n","Testing threshold: 0.8\n","\n","Trading Performance:\n","Total trades: 52516\n","Win rate: 0.51%\n","Total profit: $436.05\n","Average profit per trade: $0.0083\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 24422\n","Win rate: 0.47%\n","Total profit: $135.69\n","Average profit: $0.0056\n","\n","DOWN trades:\n","Count: 28094\n","Win rate: 0.54%\n","Total profit: $300.36\n","Average profit: $0.0107\n","\n","Testing threshold: 0.85\n","\n","Trading Performance:\n","Total trades: 46028\n","Win rate: 0.51%\n","Total profit: $503.32\n","Average profit per trade: $0.0109\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 21403\n","Win rate: 0.49%\n","Total profit: $226.48\n","Average profit: $0.0106\n","\n","DOWN trades:\n","Count: 24625\n","Win rate: 0.53%\n","Total profit: $276.84\n","Average profit: $0.0112\n","\n","Testing threshold: 0.9\n","\n","Trading Performance:\n","Total trades: 38153\n","Win rate: 0.48%\n","Total profit: $599.70\n","Average profit per trade: $0.0157\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 17760\n","Win rate: 0.50%\n","Total profit: $355.17\n","Average profit: $0.0200\n","\n","DOWN trades:\n","Count: 20393\n","Win rate: 0.48%\n","Total profit: $244.52\n","Average profit: $0.0120\n","\n","Testing threshold: 0.95\n","\n","Trading Performance:\n","Total trades: 27574\n","Win rate: 0.46%\n","Total profit: $290.87\n","Average profit per trade: $0.0105\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 12844\n","Win rate: 0.53%\n","Total profit: $71.59\n","Average profit: $0.0056\n","\n","DOWN trades:\n","Count: 14730\n","Win rate: 0.40%\n","Total profit: $219.28\n","Average profit: $0.0149\n","\n","Testing threshold: 0.99\n","\n","Trading Performance:\n","Total trades: 12099\n","Win rate: 0.50%\n","Total profit: $173.27\n","Average profit per trade: $0.0143\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 5560\n","Win rate: 0.58%\n","Total profit: $-8.42\n","Average profit: $-0.0015\n","\n","DOWN trades:\n","Count: 6539\n","Win rate: 0.43%\n","Total profit: $181.69\n","Average profit: $0.0278\n","\n","Summary of results for different probability thresholds:\n","   threshold  total_profit  num_trades  win_rate  avg_profit  long_trades  \\\n","0   0.800000    436.049894       52516  0.506512    0.008303        24422   \n","1   0.850000    503.320658       46028  0.510559    0.010935        21403   \n","2   0.900000    599.695112       38153  0.484890    0.015718        17760   \n","3   0.950000    290.870590       27574  0.460579    0.010549        12844   \n","4   0.990000    173.269076       12099  0.495909    0.014321         5560   \n","\n","   short_trades  \n","0         28094  \n","1         24625  \n","2         20393  \n","3         14730  \n","4          6539  \n"]}]},{"cell_type":"code","source":["\"TRADING STRATEGY ON TRAIN DATA BEFORE ATTACK\"\n","import numpy as np\n","import pandas as pd\n","\n","print(\"Getting predictions...\")\n","train_predictions = cnn2.predict(trainX_CNN)\n","\n","# First define our strategy function\n","def implement_fi2010_strategy(predictions, dec_data, budget=100, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"\n","    Implements trading strategy using the FI-2010 paper's methodology\n","\n","    Args:\n","        predictions: numpy array of model predictions (n_samples, 3)\n","        dec_data: numpy array of decoded price data\n","        budget: amount to invest per trade\n","        prob_threshold: probability threshold for trading\n","        k: prediction horizon (number of steps to look ahead)\n","        alpha: threshold for determining price movement direction\n","    \"\"\"\n","    # Get normalized ask and bid prices\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","\n","    trades_info = []\n","\n","    for i in range(k, min_length):\n","        # Calculate m+ (future average) according to paper\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","\n","        # Calculate actual price movement using paper's method\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","        max_prob = np.max([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","\n","        if max_prob > prob_threshold and pred_class != 1:  # not stable\n","            # Determine actual direction using same threshold as training\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","\n","            # Long trade (UP prediction)\n","            if pred_class == 2:\n","                shares = budget / mid_prices[i]\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 2],\n","                    'correct': actual_direction == 1,\n","                    'index': i\n","                })\n","\n","            # Short trade (DOWN prediction)\n","            elif pred_class == 0:\n","                shares = budget / mid_prices[i]\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 0],\n","                    'correct': actual_direction == -1,\n","                    'index': i\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","\n","        # Print performance metrics\n","        print(\"\\nTrading Performance:\")\n","        print(f\"Total trades: {len(trades_df)}\")\n","        print(f\"Win rate: {(trades_df['correct'].mean() * 100):.2f}%\")\n","        print(f\"Total profit: ${trades_df['profit'].sum():.2f}\")\n","        print(f\"Average profit per trade: ${trades_df['profit'].mean():.4f}\")\n","\n","        print(\"\\nDirection Analysis:\")\n","        for direction in ['up', 'down']:\n","            mask = trades_df['movement'] == direction\n","            if mask.any():\n","                direction_df = trades_df[mask]\n","                print(f\"\\n{direction.upper()} trades:\")\n","                print(f\"Count: {len(direction_df)}\")\n","                print(f\"Win rate: {(direction_df['correct'].mean() * 100):.2f}%\")\n","                print(f\"Total profit: ${direction_df['profit'].sum():.2f}\")\n","                print(f\"Average profit: ${direction_df['profit'].mean():.4f}\")\n","\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","# Test different probability thresholds\n","thresholds = [0.8, 0.85, 0.9, 0.95, 0.99]\n","results = []\n","\n","print(\"Testing strategy with different thresholds...\")\n","for threshold in thresholds:\n","    print(f\"\\nTesting threshold: {threshold}\")\n","    result = implement_fi2010_strategy(\n","        predictions=train_predictions,\n","        dec_data=dec_train,\n","        prob_threshold=threshold,\n","        k=4,\n","        alpha=0.001\n","    )\n","    if result:\n","        results.append(result)\n","\n","# Create summary table\n","if results:\n","    results_df = pd.DataFrame(results)\n","    print(\"\\nSummary of results for different probability thresholds:\")\n","    pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))\n","    print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSycMAmNyQnj","executionInfo":{"status":"ok","timestamp":1741052104328,"user_tz":300,"elapsed":48269,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"80018159-758f-4ef0-c96c-1546f530e419"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting predictions...\n","\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n","Testing strategy with different thresholds...\n","\n","Testing threshold: 0.8\n","\n","Trading Performance:\n","Total trades: 108763\n","Win rate: 0.68%\n","Total profit: $-493.30\n","Average profit per trade: $-0.0045\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 53649\n","Win rate: 0.69%\n","Total profit: $-59.81\n","Average profit: $-0.0011\n","\n","DOWN trades:\n","Count: 55114\n","Win rate: 0.67%\n","Total profit: $-433.49\n","Average profit: $-0.0079\n","\n","Testing threshold: 0.85\n","\n","Trading Performance:\n","Total trades: 96836\n","Win rate: 0.68%\n","Total profit: $-461.07\n","Average profit per trade: $-0.0048\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 47811\n","Win rate: 0.69%\n","Total profit: $-45.43\n","Average profit: $-0.0010\n","\n","DOWN trades:\n","Count: 49025\n","Win rate: 0.67%\n","Total profit: $-415.64\n","Average profit: $-0.0085\n","\n","Testing threshold: 0.9\n","\n","Trading Performance:\n","Total trades: 82197\n","Win rate: 0.68%\n","Total profit: $-327.79\n","Average profit per trade: $-0.0040\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 40784\n","Win rate: 0.70%\n","Total profit: $20.39\n","Average profit: $0.0005\n","\n","DOWN trades:\n","Count: 41413\n","Win rate: 0.66%\n","Total profit: $-348.18\n","Average profit: $-0.0084\n","\n","Testing threshold: 0.95\n","\n","Trading Performance:\n","Total trades: 61337\n","Win rate: 0.66%\n","Total profit: $-135.87\n","Average profit per trade: $-0.0022\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 30758\n","Win rate: 0.69%\n","Total profit: $14.44\n","Average profit: $0.0005\n","\n","DOWN trades:\n","Count: 30579\n","Win rate: 0.62%\n","Total profit: $-150.31\n","Average profit: $-0.0049\n","\n","Testing threshold: 0.99\n","\n","Trading Performance:\n","Total trades: 28270\n","Win rate: 0.67%\n","Total profit: $16.22\n","Average profit per trade: $0.0006\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 14499\n","Win rate: 0.66%\n","Total profit: $3.15\n","Average profit: $0.0002\n","\n","DOWN trades:\n","Count: 13771\n","Win rate: 0.68%\n","Total profit: $13.07\n","Average profit: $0.0009\n","\n","Summary of results for different probability thresholds:\n","   threshold  total_profit  num_trades  win_rate  avg_profit  long_trades  \\\n","0   0.800000   -493.299759      108763  0.683137   -0.004536        53649   \n","1   0.850000   -461.071004       96836  0.679499   -0.004761        47811   \n","2   0.900000   -327.788839       82197  0.678857   -0.003988        40784   \n","3   0.950000   -135.870591       61337  0.655396   -0.002215        30758   \n","4   0.990000     16.217288       28270  0.668553    0.000574        14499   \n","\n","   short_trades  \n","0         55114  \n","1         49025  \n","2         41413  \n","3         30579  \n","4         13771  \n"]}]},{"cell_type":"code","source":["def calculate_perturbation_volume(original, perturbed):\n","    original_flat = original.reshape(original.shape[0], -1)\n","    perturbed_flat = perturbed.reshape(perturbed.shape[0], -1)\n","    perturbation = np.linalg.norm(original_flat - perturbed_flat, ord=2, axis=1)\n","    avg_perturbation = np.mean(perturbation)\n","    return avg_perturbation"],"metadata":{"id":"RT7ivbYkKb5I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"ADVERSARIAL ATTACK ON 3 EPSILON VALUES\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import precision_score, recall_score, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Define constants\n","max_test_size = testX_CNN.shape[0]\n","batch_size = 2000\n","num_batches = max_test_size // batch_size\n","epsilon_values = [0.000001, 0.00001, 0.0001]\n","num_iterations = 5\n","step_size = 0.01\n","\n","# Define your model\n","model = cnn2\n","\n","avg_accuracies1 = {}\n","avg_accuracies2 = {}\n","perturbed_volumes1 = {}\n","perturbed_volumes2 = {}\n","# Define dictionaries to hold precision and recall\n","avg_precision1 = {}\n","avg_recall1 = {}\n","avg_precision2 = {}\n","avg_recall2 = {}\n","# Define dictionaries to hold ROC AUC scores\n","avg_roc_auc1 = {}\n","avg_roc_auc2 = {}\n","\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","def data_set(testX_CNN, start_idx, end_idx):\n","    shifted_testX_CNN = tf.concat([testX_CNN[start_idx:end_idx, 1:100, :, :], testX_CNN[start_idx:end_idx, 99:, :, :]], axis=1)\n","    return shifted_testX_CNN\n","\n","def fgsm_attack(images, labels, epsilon):\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        predictions = model(images)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","    gradient = tape.gradient(loss, images)\n","    signed_grad = tf.sign(gradient)\n","\n","    signed_masked = signed_grad.numpy()\n","    signed_masked[:, :99, :, :] = 0\n","    signed_masked[:, 99:, ::2, :] = 0\n","    signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","    perturbed_images = images + epsilon * signed_masked\n","    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","    return perturbed_images\n","\"\"\"\n","with tf.GradientTape() as tape: automatically tracks operations for gradient calculation\n","tape.watch(images): Explicitly tells the gradient tape to watch the images tensor for gradient calculation\n","loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions):\n","Calculates the loss between the true labels and the model's predictions\n","Uses categorical cross-entropy loss because this is a classification problem\n","from_logits=False indicates that the predictions are already probabilities (softmax has been applied)\n","gradient = tape.gradient(loss, images)\n","Calculates the gradient of the loss with respect to the input images\n","This tells us how to change the input to maximize the loss (i.e., make the model more likely to misclassify)\n","signed_grad = tf.sign(gradient)\n","Applies the sign function to the gradient to get the direction of the gradient\n","signed_masked[:, :99, :, :] = 0:\n","Sets the gradients for the first 99 time steps to zero\n","This ensures we only perturb the last time step (t=99), which is what the model primarily bases its prediction on\n","Within the last time step (t=99), this sets gradients for every other feature to zero\n","The ::2 slice is accessing only even indices, which likely correspond to price data in the LOB\n","This ensures we only perturb volume data and not price data, making the attack more realistic\n","signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32):\n","Converts the masked gradient signs back to a TensorFlow tensor for further operations\n","perturbed_images = images + epsilon * signed_masked:\n","Creates adversarial examples by adding the perturbation to the original images\n","The perturbation is the sign of the gradient scaled by epsilon\n","perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","Clips the perturbed values to ensure they stay within valid range [0,1]\n","\"\"\"\n","def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","    perturbed_images = tf.identity(images)\n","\n","    for _ in range(num_iterations):\n","        # Gradient step\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","        gradient = tape.gradient(loss, perturbed_images)\n","        signed_grad = tf.sign(gradient)\n","\n","        # Apply masking to gradient\n","        signed_masked = signed_grad.numpy()\n","        signed_masked[:, :99, :, :] = 0\n","        signed_masked[:, 99:, ::2, :] = 0\n","        signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","        # Apply gradient step\n","        perturbed_images = perturbed_images + step_size * signed_masked\n","\n","        # Step 1: Apply volume constraint\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","        # Step 2: Apply L2 norm constraint (projection step)\n","        delta = perturbed_images - images  # Calculate current perturbation\n","\n","        # Reshape to flatten all dimensions except batch\n","        delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","        # Calculate L2 norm on the flattened dimensions\n","        norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","        # Reshape norm for broadcasting\n","        norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","        # Scale perturbation\n","        scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","        delta = delta * scaling\n","\n","        perturbed_images = images + delta  # Apply constrained perturbation\n","\n","        # Step 3: Apply clipping to valid range [0,1]\n","        perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","        # Step 4: Re-apply volume constraint after all other constraints\n","        # This ensures volume constraint takes precedence if there's a conflict\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","    return perturbed_images\n","\n","# Example usage in the main loop:\n","# Replace:\n","# perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon)\n","# With:\n","# perturbed_images1 = pgd_attack_with_volume_constraint(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","\n","def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","    images = images.numpy()\n","    slices = [slice(None)] * images.ndim\n","    testX_CNN = testX_CNN[start_idx:end_idx]\n","    for idx in range(images.shape[dimension]):\n","        slices[dimension] = idx\n","        images[tuple(slices)] = np.maximum(images[tuple(slices)], testX_CNN[tuple(slices)])\n","    images = tf.convert_to_tensor(images, dtype=tf.float32)\n","    return images\n","\n","def plot_roc_curve(y_true, y_score1, y_score2, epsilon):\n","    \"\"\"\n","    Plot ROC curve for both attacks at a specific epsilon value\n","    \"\"\"\n","    # Get number of classes\n","    n_classes = y_score1.shape[1]\n","\n","    # Compute ROC curve and ROC area for each class for PGD\n","    fpr1 = dict()\n","    tpr1 = dict()\n","    roc_auc1 = dict()\n","    for i in range(n_classes):\n","        fpr1[i], tpr1[i], _ = roc_curve(y_true[:, i], y_score1[:, i])\n","        roc_auc1[i] = auc(fpr1[i], tpr1[i])\n","\n","    # Compute ROC curve and ROC area for each class for FGSM\n","    fpr2 = dict()\n","    tpr2 = dict()\n","    roc_auc2 = dict()\n","    for i in range(n_classes):\n","        fpr2[i], tpr2[i], _ = roc_curve(y_true[:, i], y_score2[:, i])\n","        roc_auc2[i] = auc(fpr2[i], tpr2[i])\n","\n","    # Calculate macro average ROC curve and ROC area\n","    all_fpr1 = np.unique(np.concatenate([fpr1[i] for i in range(n_classes)]))\n","    all_fpr2 = np.unique(np.concatenate([fpr2[i] for i in range(n_classes)]))\n","\n","    mean_tpr1 = np.zeros_like(all_fpr1)\n","    mean_tpr2 = np.zeros_like(all_fpr2)\n","    for i in range(n_classes):\n","        mean_tpr1 += np.interp(all_fpr1, fpr1[i], tpr1[i])\n","        mean_tpr2 += np.interp(all_fpr2, fpr2[i], tpr2[i])\n","\n","    mean_tpr1 /= n_classes\n","    mean_tpr2 /= n_classes\n","\n","    macro_roc_auc1 = auc(all_fpr1, mean_tpr1)\n","    macro_roc_auc2 = auc(all_fpr2, mean_tpr2)\n","\n","    # Plot ROC curve only as per the requirement\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(all_fpr1, mean_tpr1, label=f'PGD Attack - Macro-average ROC (AUC = {macro_roc_auc1:.2f})',\n","             color='blue', linestyle='solid', linewidth=2)\n","    plt.plot(all_fpr2, mean_tpr2, label=f'FGSM Attack - Macro-average ROC (AUC = {macro_roc_auc2:.2f})',\n","             color='red', linestyle='dashed', linewidth=2)\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for PGD and FGSM Attacks with ε = {epsilon}')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the figure\n","    plt.savefig(f'roc_curve_epsilon_{epsilon}.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    return macro_roc_auc1, macro_roc_auc2\n","\n","# Lists to store all prediction probabilities and true labels for ROC curves\n","all_true_labels_onehot = []\n","all_pred_probs_pgd = []\n","all_pred_probs_fgsm = []\n","\n","for epsilon in epsilon_values:\n","    print(f\"Epsilon value: {epsilon}\")\n","    total_accuracy1 = 0.0\n","    total_accuracy2 = 0.0\n","    total_perturbation1 = 0.0\n","    total_perturbation2 = 0.0\n","    all_true_labels = []\n","    all_predicted_labels1 = []\n","    all_predicted_labels2 = []\n","\n","    # For this epsilon, collect all prediction probabilities\n","    epsilon_true_labels_onehot = []\n","    epsilon_pred_probs_pgd = []\n","    epsilon_pred_probs_fgsm = []\n","\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = (i + 1) * batch_size\n","\n","        batch_images = data_set(testX_CNN, start_idx, end_idx)\n","        batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","        batch_labels = testY_CNN[start_idx:end_idx]\n","\n","        perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","        perturbed_images2 = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","        perturbation1 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images1.numpy())\n","        perturbation2 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images2.numpy())\n","\n","        total_perturbation1 += perturbation1\n","        total_perturbation2 += perturbation2\n","\n","        X_perturbed1 = perturbed_images1.numpy()\n","        X_perturbed2 = perturbed_images2.numpy()\n","\n","        # Get raw probabilities for ROC curve\n","        adversarial_probs1 = model.predict(X_perturbed1)\n","        adversarial_probs2 = model.predict(X_perturbed2)\n","\n","        # Get predicted labels\n","        adversarial_predictions1 = np.argmax(adversarial_probs1, axis=1)\n","        adversarial_predictions2 = np.argmax(adversarial_probs2, axis=1)\n","\n","        # Collect data for ROC curve\n","        epsilon_true_labels_onehot.append(batch_labels)\n","        epsilon_pred_probs_pgd.append(adversarial_probs1)\n","        epsilon_pred_probs_fgsm.append(adversarial_probs2)\n","\n","        # Append results for precision and recall calculation\n","        true_labels_batch = np.argmax(batch_labels, axis=1)\n","        all_true_labels.extend(true_labels_batch)\n","        all_predicted_labels1.extend(adversarial_predictions1)\n","        all_predicted_labels2.extend(adversarial_predictions2)\n","\n","        accuracy1 = accuracy_score(true_labels_batch, adversarial_predictions1)\n","        accuracy2 = accuracy_score(true_labels_batch, adversarial_predictions2)\n","        total_accuracy1 += accuracy1\n","        total_accuracy2 += accuracy2\n","\n","    average_accuracy1 = total_accuracy1 / num_batches\n","    average_accuracy2 = total_accuracy2 / num_batches\n","    avg_perturbation1 = total_perturbation1 / num_batches\n","    avg_perturbation2 = total_perturbation2 / num_batches\n","\n","    # Concatenate all batches for this epsilon\n","    epsilon_true_labels_onehot = np.vstack(epsilon_true_labels_onehot)\n","    epsilon_pred_probs_pgd = np.vstack(epsilon_pred_probs_pgd)\n","    epsilon_pred_probs_fgsm = np.vstack(epsilon_pred_probs_fgsm)\n","\n","    # Calculate and plot ROC curve\n","    roc_auc1, roc_auc2 = plot_roc_curve(\n","        epsilon_true_labels_onehot,\n","        epsilon_pred_probs_pgd,\n","        epsilon_pred_probs_fgsm,\n","        epsilon\n","    )\n","\n","    avg_roc_auc1[epsilon] = roc_auc1\n","    avg_roc_auc2[epsilon] = roc_auc2\n","\n","    # Calculate precision and recall\n","    precision1 = precision_score(all_true_labels, all_predicted_labels1, average='macro')\n","    recall1 = recall_score(all_true_labels, all_predicted_labels1, average='macro')\n","    precision2 = precision_score(all_true_labels, all_predicted_labels2, average='macro')\n","    recall2 = recall_score(all_true_labels, all_predicted_labels2, average='macro')\n","\n","    avg_precision1[epsilon] = precision1\n","    avg_recall1[epsilon] = recall1\n","    avg_precision2[epsilon] = precision2\n","    avg_recall2[epsilon] = recall2\n","\n","    # Generate classification reports\n","    pgd_report = classification_report(all_true_labels, all_predicted_labels1, output_dict=True)\n","    fgsm_report = classification_report(all_true_labels, all_predicted_labels2, output_dict=True)\n","\n","    print(f\"Average accuracy of PGD attack for epsilon value {epsilon}: {average_accuracy1}\")\n","    avg_accuracies1[epsilon] = average_accuracy1\n","    print(f\"Average accuracy of FGSM attack for epsilon value {epsilon}: {average_accuracy2}\")\n","    avg_accuracies2[epsilon] = average_accuracy2\n","    print(f\"Average perturbation volume for PGD attack with epsilon {epsilon}: {avg_perturbation1}\")\n","    perturbed_volumes1[epsilon] = avg_perturbation1\n","    print(f\"Average perturbation volume for FGSM attack with epsilon {epsilon}: {avg_perturbation2}\")\n","    perturbed_volumes2[epsilon] = avg_perturbation2\n","\n","    # Print precision and recall\n","    print(f\"Average precision of PGD attack for epsilon value {epsilon}: {precision1}\")\n","    print(f\"Average recall of PGD attack for epsilon value {epsilon}: {recall1}\")\n","    print(f\"Average precision of FGSM attack for epsilon value {epsilon}: {precision2}\")\n","    print(f\"Average recall of FGSM attack for epsilon value {epsilon}: {recall2}\")\n","\n","    # Print ROC AUC\n","    print(f\"ROC AUC of PGD attack for epsilon value {epsilon}: {roc_auc1}\")\n","    print(f\"ROC AUC of FGSM attack for epsilon value {epsilon}: {roc_auc2}\")\n","\n","    # Print classification reports\n","    print(f\"\\nClassification Report for PGD Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels1))\n","\n","    print(f\"\\nClassification Report for FGSM Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels2))\n","\n","    # Clean up\n","    tf.keras.backend.clear_session()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkpLUwbTzDRr","executionInfo":{"status":"ok","timestamp":1741393937734,"user_tz":300,"elapsed":852892,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"7de5f53d-1ce1-4830-eafd-78ddbe15fbc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon value: 1e-06\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Average accuracy of PGD attack for epsilon value 1e-06: 0.4811521739130434\n","Average accuracy of FGSM attack for epsilon value 1e-06: 0.7467463768115941\n","Average perturbation volume for PGD attack with epsilon 1e-06: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 1e-06: 4.471045835141895e-06\n","Average precision of PGD attack for epsilon value 1e-06: 0.484922693120722\n","Average recall of PGD attack for epsilon value 1e-06: 0.48119158438014065\n","Average precision of FGSM attack for epsilon value 1e-06: 0.7458069016572928\n","Average recall of FGSM attack for epsilon value 1e-06: 0.7460814760220483\n","ROC AUC of PGD attack for epsilon value 1e-06: 0.6451441598399459\n","ROC AUC of FGSM attack for epsilon value 1e-06: 0.8935021733126447\n","\n","Classification Report for PGD Attack (ε = 1e-06):\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.56      0.51     47512\n","           1       0.52      0.39      0.45     47269\n","           2       0.46      0.49      0.47     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.48      0.48      0.48    138000\n","weighted avg       0.49      0.48      0.48    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1e-06):\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.73      0.73     47512\n","           1       0.78      0.79      0.78     47269\n","           2       0.72      0.72      0.72     43219\n","\n","    accuracy                           0.75    138000\n","   macro avg       0.75      0.75      0.75    138000\n","weighted avg       0.75      0.75      0.75    138000\n","\n","Epsilon value: 1e-05\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Average accuracy of PGD attack for epsilon value 1e-05: 0.4811521739130434\n","Average accuracy of FGSM attack for epsilon value 1e-05: 0.7462246376811592\n","Average perturbation volume for PGD attack with epsilon 1e-05: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 1e-05: 4.4720573962389395e-05\n","Average precision of PGD attack for epsilon value 1e-05: 0.484922693120722\n","Average recall of PGD attack for epsilon value 1e-05: 0.48119158438014065\n","Average precision of FGSM attack for epsilon value 1e-05: 0.7452883731545782\n","Average recall of FGSM attack for epsilon value 1e-05: 0.7455606599441914\n","ROC AUC of PGD attack for epsilon value 1e-05: 0.6451435098992332\n","ROC AUC of FGSM attack for epsilon value 1e-05: 0.893202696454291\n","\n","Classification Report for PGD Attack (ε = 1e-05):\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.56      0.51     47512\n","           1       0.52      0.39      0.45     47269\n","           2       0.46      0.49      0.47     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.48      0.48      0.48    138000\n","weighted avg       0.49      0.48      0.48    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1e-05):\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.73      0.73     47512\n","           1       0.78      0.79      0.78     47269\n","           2       0.72      0.72      0.72     43219\n","\n","    accuracy                           0.75    138000\n","   macro avg       0.75      0.75      0.75    138000\n","weighted avg       0.75      0.75      0.75    138000\n","\n","Epsilon value: 0.0001\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Average accuracy of PGD attack for epsilon value 0.0001: 0.4811304347826086\n","Average accuracy of FGSM attack for epsilon value 0.0001: 0.7417246376811595\n","Average perturbation volume for PGD attack with epsilon 0.0001: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 0.0001: 0.0004470691391084667\n","Average precision of PGD attack for epsilon value 0.0001: 0.4849001740728321\n","Average recall of PGD attack for epsilon value 0.0001: 0.48116980411338295\n","Average precision of FGSM attack for epsilon value 0.0001: 0.7407993314825067\n","Average recall of FGSM attack for epsilon value 0.0001: 0.7410569379665505\n","ROC AUC of PGD attack for epsilon value 0.0001: 0.645137548989448\n","ROC AUC of FGSM attack for epsilon value 0.0001: 0.8901781650427719\n","\n","Classification Report for PGD Attack (ε = 0.0001):\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.56      0.51     47512\n","           1       0.52      0.39      0.45     47269\n","           2       0.46      0.49      0.47     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.48      0.48      0.48    138000\n","weighted avg       0.49      0.48      0.48    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.0001):\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.72      0.73     47512\n","           1       0.77      0.78      0.78     47269\n","           2       0.71      0.72      0.72     43219\n","\n","    accuracy                           0.74    138000\n","   macro avg       0.74      0.74      0.74    138000\n","weighted avg       0.74      0.74      0.74    138000\n","\n"]}]},{"cell_type":"code","source":["\"\"\"ADVERSARIAL ATTACK ON 1 EPSILON VALUES\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import precision_score, recall_score, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Define constants\n","max_test_size = testX_CNN.shape[0]\n","batch_size = 2000\n","num_batches = max_test_size // batch_size\n","epsilon_values = [0.01]\n","num_iterations = 5\n","step_size = 0.01\n","\n","# Define your model\n","model = cnn2\n","\n","avg_accuracies1 = {}\n","avg_accuracies2 = {}\n","perturbed_volumes1 = {}\n","perturbed_volumes2 = {}\n","# Define dictionaries to hold precision and recall\n","avg_precision1 = {}\n","avg_recall1 = {}\n","avg_precision2 = {}\n","avg_recall2 = {}\n","# Define dictionaries to hold ROC AUC scores\n","avg_roc_auc1 = {}\n","avg_roc_auc2 = {}\n","\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","def data_set(testX_CNN, start_idx, end_idx):\n","    shifted_testX_CNN = tf.concat([testX_CNN[start_idx:end_idx, 1:100, :, :], testX_CNN[start_idx:end_idx, 99:, :, :]], axis=1)\n","    return shifted_testX_CNN\n","\n","def fgsm_attack(images, labels, epsilon):\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        predictions = model(images)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","    gradient = tape.gradient(loss, images)\n","    signed_grad = tf.sign(gradient)\n","\n","    signed_masked = signed_grad.numpy()\n","    signed_masked[:, :99, :, :] = 0\n","    signed_masked[:, 99:, ::2, :] = 0\n","    signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","    perturbed_images = images + epsilon * signed_masked\n","    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","    return perturbed_images\n","\n","def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","    perturbed_images = tf.identity(images)\n","\n","    for _ in range(num_iterations):\n","        # Gradient step\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","        gradient = tape.gradient(loss, perturbed_images)\n","        signed_grad = tf.sign(gradient)\n","\n","        # Apply masking to gradient\n","        signed_masked = signed_grad.numpy()\n","        signed_masked[:, :99, :, :] = 0\n","        signed_masked[:, 99:, ::2, :] = 0\n","        signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","        # Apply gradient step\n","        perturbed_images = perturbed_images + step_size * signed_masked\n","\n","        # Step 1: Apply volume constraint\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","        # Step 2: Apply L2 norm constraint (projection step)\n","        delta = perturbed_images - images  # Calculate current perturbation\n","\n","        # Reshape to flatten all dimensions except batch\n","        delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","        # Calculate L2 norm on the flattened dimensions\n","        norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","        # Reshape norm for broadcasting\n","        norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","        # Scale perturbation\n","        scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","        delta = delta * scaling\n","\n","        perturbed_images = images + delta  # Apply constrained perturbation\n","\n","        # Step 3: Apply clipping to valid range [0,1]\n","        perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","        # Step 4: Re-apply volume constraint after all other constraints\n","        # This ensures volume constraint takes precedence if there's a conflict\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","    return perturbed_images\n","\n","# Example usage in the main loop:\n","# Replace:\n","# perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon)\n","# With:\n","# perturbed_images1 = pgd_attack_with_volume_constraint(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","\n","def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","    images = images.numpy()\n","    slices = [slice(None)] * images.ndim\n","    testX_CNN = testX_CNN[start_idx:end_idx]\n","    for idx in range(images.shape[dimension]):\n","        slices[dimension] = idx\n","        images[tuple(slices)] = np.maximum(images[tuple(slices)], testX_CNN[tuple(slices)])\n","    images = tf.convert_to_tensor(images, dtype=tf.float32)\n","    return images\n","\n","def plot_roc_curve(y_true, y_score1, y_score2, epsilon):\n","    \"\"\"\n","    Plot ROC curve for both attacks at a specific epsilon value\n","    \"\"\"\n","    # Get number of classes\n","    n_classes = y_score1.shape[1]\n","\n","    # Compute ROC curve and ROC area for each class for PGD\n","    fpr1 = dict()\n","    tpr1 = dict()\n","    roc_auc1 = dict()\n","    for i in range(n_classes):\n","        fpr1[i], tpr1[i], _ = roc_curve(y_true[:, i], y_score1[:, i])\n","        roc_auc1[i] = auc(fpr1[i], tpr1[i])\n","\n","    # Compute ROC curve and ROC area for each class for FGSM\n","    fpr2 = dict()\n","    tpr2 = dict()\n","    roc_auc2 = dict()\n","    for i in range(n_classes):\n","        fpr2[i], tpr2[i], _ = roc_curve(y_true[:, i], y_score2[:, i])\n","        roc_auc2[i] = auc(fpr2[i], tpr2[i])\n","\n","    # Calculate macro average ROC curve and ROC area\n","    all_fpr1 = np.unique(np.concatenate([fpr1[i] for i in range(n_classes)]))\n","    all_fpr2 = np.unique(np.concatenate([fpr2[i] for i in range(n_classes)]))\n","\n","    mean_tpr1 = np.zeros_like(all_fpr1)\n","    mean_tpr2 = np.zeros_like(all_fpr2)\n","    for i in range(n_classes):\n","        mean_tpr1 += np.interp(all_fpr1, fpr1[i], tpr1[i])\n","        mean_tpr2 += np.interp(all_fpr2, fpr2[i], tpr2[i])\n","\n","    mean_tpr1 /= n_classes\n","    mean_tpr2 /= n_classes\n","\n","    macro_roc_auc1 = auc(all_fpr1, mean_tpr1)\n","    macro_roc_auc2 = auc(all_fpr2, mean_tpr2)\n","\n","    # Plot ROC curve only as per the requirement\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(all_fpr1, mean_tpr1, label=f'PGD Attack - Macro-average ROC (AUC = {macro_roc_auc1:.2f})',\n","             color='blue', linestyle='solid', linewidth=2)\n","    plt.plot(all_fpr2, mean_tpr2, label=f'FGSM Attack - Macro-average ROC (AUC = {macro_roc_auc2:.2f})',\n","             color='red', linestyle='dashed', linewidth=2)\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for PGD and FGSM Attacks with ε = {epsilon}')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the figure\n","    plt.savefig(f'roc_curve_epsilon_{epsilon}.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    return macro_roc_auc1, macro_roc_auc2\n","\n","# Lists to store all prediction probabilities and true labels for ROC curves\n","all_true_labels_onehot = []\n","all_pred_probs_pgd = []\n","all_pred_probs_fgsm = []\n","\n","for epsilon in epsilon_values:\n","    print(f\"Epsilon value: {epsilon}\")\n","    total_accuracy1 = 0.0\n","    total_accuracy2 = 0.0\n","    total_perturbation1 = 0.0\n","    total_perturbation2 = 0.0\n","    all_true_labels = []\n","    all_predicted_labels1 = []\n","    all_predicted_labels2 = []\n","\n","    # For this epsilon, collect all prediction probabilities\n","    epsilon_true_labels_onehot = []\n","    epsilon_pred_probs_pgd = []\n","    epsilon_pred_probs_fgsm = []\n","\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = (i + 1) * batch_size\n","\n","        batch_images = data_set(testX_CNN, start_idx, end_idx)\n","        batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","        batch_labels = testY_CNN[start_idx:end_idx]\n","\n","        perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","        perturbed_images2 = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","        perturbation1 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images1.numpy())\n","        perturbation2 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images2.numpy())\n","\n","        total_perturbation1 += perturbation1\n","        total_perturbation2 += perturbation2\n","\n","        X_perturbed1 = perturbed_images1.numpy()\n","        X_perturbed2 = perturbed_images2.numpy()\n","\n","        # Get raw probabilities for ROC curve\n","        adversarial_probs1 = model.predict(X_perturbed1)\n","        adversarial_probs2 = model.predict(X_perturbed2)\n","\n","        # Get predicted labels\n","        adversarial_predictions1 = np.argmax(adversarial_probs1, axis=1)\n","        adversarial_predictions2 = np.argmax(adversarial_probs2, axis=1)\n","\n","        # Collect data for ROC curve\n","        epsilon_true_labels_onehot.append(batch_labels)\n","        epsilon_pred_probs_pgd.append(adversarial_probs1)\n","        epsilon_pred_probs_fgsm.append(adversarial_probs2)\n","\n","        # Append results for precision and recall calculation\n","        true_labels_batch = np.argmax(batch_labels, axis=1)\n","        all_true_labels.extend(true_labels_batch)\n","        all_predicted_labels1.extend(adversarial_predictions1)\n","        all_predicted_labels2.extend(adversarial_predictions2)\n","\n","        accuracy1 = accuracy_score(true_labels_batch, adversarial_predictions1)\n","        accuracy2 = accuracy_score(true_labels_batch, adversarial_predictions2)\n","        total_accuracy1 += accuracy1\n","        total_accuracy2 += accuracy2\n","\n","    average_accuracy1 = total_accuracy1 / num_batches\n","    average_accuracy2 = total_accuracy2 / num_batches\n","    avg_perturbation1 = total_perturbation1 / num_batches\n","    avg_perturbation2 = total_perturbation2 / num_batches\n","\n","    # Concatenate all batches for this epsilon\n","    epsilon_true_labels_onehot = np.vstack(epsilon_true_labels_onehot)\n","    epsilon_pred_probs_pgd = np.vstack(epsilon_pred_probs_pgd)\n","    epsilon_pred_probs_fgsm = np.vstack(epsilon_pred_probs_fgsm)\n","\n","    # Calculate and plot ROC curve\n","    roc_auc1, roc_auc2 = plot_roc_curve(\n","        epsilon_true_labels_onehot,\n","        epsilon_pred_probs_pgd,\n","        epsilon_pred_probs_fgsm,\n","        epsilon\n","    )\n","\n","    avg_roc_auc1[epsilon] = roc_auc1\n","    avg_roc_auc2[epsilon] = roc_auc2\n","\n","    # Calculate precision and recall\n","    precision1 = precision_score(all_true_labels, all_predicted_labels1, average='macro')\n","    recall1 = recall_score(all_true_labels, all_predicted_labels1, average='macro')\n","    precision2 = precision_score(all_true_labels, all_predicted_labels2, average='macro')\n","    recall2 = recall_score(all_true_labels, all_predicted_labels2, average='macro')\n","\n","    avg_precision1[epsilon] = precision1\n","    avg_recall1[epsilon] = recall1\n","    avg_precision2[epsilon] = precision2\n","    avg_recall2[epsilon] = recall2\n","\n","    # Generate classification reports\n","    pgd_report = classification_report(all_true_labels, all_predicted_labels1, output_dict=True)\n","    fgsm_report = classification_report(all_true_labels, all_predicted_labels2, output_dict=True)\n","\n","    print(f\"Average accuracy of PGD attack for epsilon value {epsilon}: {average_accuracy1}\")\n","    avg_accuracies1[epsilon] = average_accuracy1\n","    print(f\"Average accuracy of FGSM attack for epsilon value {epsilon}: {average_accuracy2}\")\n","    avg_accuracies2[epsilon] = average_accuracy2\n","    print(f\"Average perturbation volume for PGD attack with epsilon {epsilon}: {avg_perturbation1}\")\n","    perturbed_volumes1[epsilon] = avg_perturbation1\n","    print(f\"Average perturbation volume for FGSM attack with epsilon {epsilon}: {avg_perturbation2}\")\n","    perturbed_volumes2[epsilon] = avg_perturbation2\n","\n","    # Print precision and recall\n","    print(f\"Average precision of PGD attack for epsilon value {epsilon}: {precision1}\")\n","    print(f\"Average recall of PGD attack for epsilon value {epsilon}: {recall1}\")\n","    print(f\"Average precision of FGSM attack for epsilon value {epsilon}: {precision2}\")\n","    print(f\"Average recall of FGSM attack for epsilon value {epsilon}: {recall2}\")\n","\n","    # Print ROC AUC\n","    print(f\"ROC AUC of PGD attack for epsilon value {epsilon}: {roc_auc1}\")\n","    print(f\"ROC AUC of FGSM attack for epsilon value {epsilon}: {roc_auc2}\")\n","\n","    # Print classification reports\n","    print(f\"\\nClassification Report for PGD Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels1))\n","\n","    print(f\"\\nClassification Report for FGSM Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels2))\n","\n","    # Clean up\n","    tf.keras.backend.clear_session()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSLg44cVIALJ","executionInfo":{"status":"ok","timestamp":1741394274921,"user_tz":300,"elapsed":279699,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"d8505a9b-47e5-475f-f997-b54443b20918"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon value: 0.01\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Average accuracy of PGD attack for epsilon value 0.01: 0.480268115942029\n","Average accuracy of FGSM attack for epsilon value 0.01: 0.4538695652173914\n","Average perturbation volume for PGD attack with epsilon 0.01: 2.2640044255101164\n","Average perturbation volume for FGSM attack with epsilon 0.01: 0.040475365908249565\n","Average precision of PGD attack for epsilon value 0.01: 0.48404309821134667\n","Average recall of PGD attack for epsilon value 0.01: 0.48029653807904626\n","Average precision of FGSM attack for epsilon value 0.01: 0.4626188093914296\n","Average recall of FGSM attack for epsilon value 0.01: 0.4588019177153028\n","ROC AUC of PGD attack for epsilon value 0.01: 0.6444652321702774\n","ROC AUC of FGSM attack for epsilon value 0.01: 0.6982582055323703\n","\n","Classification Report for PGD Attack (ε = 0.01):\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.56      0.51     47512\n","           1       0.52      0.39      0.45     47269\n","           2       0.46      0.49      0.47     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.48      0.48      0.48    138000\n","weighted avg       0.48      0.48      0.48    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.01):\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.66      0.55     47512\n","           1       0.48      0.08      0.14     47269\n","           2       0.43      0.64      0.51     43219\n","\n","    accuracy                           0.45    138000\n","   macro avg       0.46      0.46      0.40    138000\n","weighted avg       0.46      0.45      0.40    138000\n","\n"]}]},{"cell_type":"code","source":["def calculate_perturbation_volume(original, perturbed):\n","    original_flat = original.reshape(original.shape[0], -1)\n","    perturbed_flat = perturbed.reshape(perturbed.shape[0], -1)\n","    perturbation = np.linalg.norm(original_flat - perturbed_flat, ord=2, axis=1)\n","    avg_perturbation = np.mean(perturbation)\n","    return avg_perturbation"],"metadata":{"id":"ydEzA2BeKtw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"ADVERSARIAL ATTACK ON 4 EPSILON VALUES\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import precision_score, recall_score, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Define constants\n","max_test_size = testX_CNN.shape[0]\n","batch_size = 2000\n","num_batches = max_test_size // batch_size\n","epsilon_values = [0.01, 0.1, 1, 10]\n","num_iterations = 5\n","step_size = 0.01\n","\n","# Define your model\n","model = cnn2\n","\n","avg_accuracies1 = {}\n","avg_accuracies2 = {}\n","perturbed_volumes1 = {}\n","perturbed_volumes2 = {}\n","# Define dictionaries to hold precision and recall\n","avg_precision1 = {}\n","avg_recall1 = {}\n","avg_precision2 = {}\n","avg_recall2 = {}\n","# Define dictionaries to hold ROC AUC scores\n","avg_roc_auc1 = {}\n","avg_roc_auc2 = {}\n","\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","def data_set(testX_CNN, start_idx, end_idx):\n","    shifted_testX_CNN = tf.concat([testX_CNN[start_idx:end_idx, 1:100, :, :], testX_CNN[start_idx:end_idx, 99:, :, :]], axis=1)\n","    return shifted_testX_CNN\n","\n","def fgsm_attack(images, labels, epsilon):\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        predictions = model(images)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","    gradient = tape.gradient(loss, images)\n","    signed_grad = tf.sign(gradient)\n","\n","    signed_masked = signed_grad.numpy()\n","    signed_masked[:, :99, :, :] = 0\n","    signed_masked[:, 99:, ::2, :] = 0\n","    signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","    perturbed_images = images + epsilon * signed_masked\n","    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","    return perturbed_images\n","\n","def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","    perturbed_images = tf.identity(images)\n","\n","    for _ in range(num_iterations):\n","        # Gradient step\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","        gradient = tape.gradient(loss, perturbed_images)\n","        signed_grad = tf.sign(gradient)\n","\n","        # Apply masking to gradient\n","        signed_masked = signed_grad.numpy()\n","        signed_masked[:, :99, :, :] = 0\n","        signed_masked[:, 99:, ::2, :] = 0\n","        signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","        # Apply gradient step\n","        perturbed_images = perturbed_images + step_size * signed_masked\n","\n","        # Step 1: Apply volume constraint\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","        # Step 2: Apply L2 norm constraint (projection step)\n","        delta = perturbed_images - images  # Calculate current perturbation\n","\n","        # Reshape to flatten all dimensions except batch\n","        delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","        # Calculate L2 norm on the flattened dimensions\n","        norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","        # Reshape norm for broadcasting\n","        norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","        # Scale perturbation\n","        scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","        delta = delta * scaling\n","\n","        perturbed_images = images + delta  # Apply constrained perturbation\n","\n","        # Step 3: Apply clipping to valid range [0,1]\n","        perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","        # Step 4: Re-apply volume constraint after all other constraints\n","        # This ensures volume constraint takes precedence if there's a conflict\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","    return perturbed_images\n","\n","def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","    images = images.numpy()\n","    slices = [slice(None)] * images.ndim\n","    testX_CNN = testX_CNN[start_idx:end_idx]\n","    for idx in range(images.shape[dimension]):\n","        slices[dimension] = idx\n","        images[tuple(slices)] = np.maximum(images[tuple(slices)], testX_CNN[tuple(slices)])\n","    images = tf.convert_to_tensor(images, dtype=tf.float32)\n","    return images\n","\n","def plot_roc_curve(y_true, y_score1, y_score2, epsilon):\n","    \"\"\"\n","    Plot ROC curve for both attacks at a specific epsilon value\n","    \"\"\"\n","    # Get number of classes\n","    n_classes = y_score1.shape[1]\n","\n","    # Compute ROC curve and ROC area for each class for PGD\n","    fpr1 = dict()\n","    tpr1 = dict()\n","    roc_auc1 = dict()\n","    for i in range(n_classes):\n","        fpr1[i], tpr1[i], _ = roc_curve(y_true[:, i], y_score1[:, i])\n","        roc_auc1[i] = auc(fpr1[i], tpr1[i])\n","\n","    # Compute ROC curve and ROC area for each class for FGSM\n","    fpr2 = dict()\n","    tpr2 = dict()\n","    roc_auc2 = dict()\n","    for i in range(n_classes):\n","        fpr2[i], tpr2[i], _ = roc_curve(y_true[:, i], y_score2[:, i])\n","        roc_auc2[i] = auc(fpr2[i], tpr2[i])\n","\n","    # Calculate macro average ROC curve and ROC area\n","    all_fpr1 = np.unique(np.concatenate([fpr1[i] for i in range(n_classes)]))\n","    all_fpr2 = np.unique(np.concatenate([fpr2[i] for i in range(n_classes)]))\n","\n","    mean_tpr1 = np.zeros_like(all_fpr1)\n","    mean_tpr2 = np.zeros_like(all_fpr2)\n","    for i in range(n_classes):\n","        mean_tpr1 += np.interp(all_fpr1, fpr1[i], tpr1[i])\n","        mean_tpr2 += np.interp(all_fpr2, fpr2[i], tpr2[i])\n","\n","    mean_tpr1 /= n_classes\n","    mean_tpr2 /= n_classes\n","\n","    macro_roc_auc1 = auc(all_fpr1, mean_tpr1)\n","    macro_roc_auc2 = auc(all_fpr2, mean_tpr2)\n","\n","    # Plot ROC curve only as per the requirement\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(all_fpr1, mean_tpr1, label=f'PGD Attack - Macro-average ROC (AUC = {macro_roc_auc1:.2f})',\n","             color='blue', linestyle='solid', linewidth=2)\n","    plt.plot(all_fpr2, mean_tpr2, label=f'FGSM Attack - Macro-average ROC (AUC = {macro_roc_auc2:.2f})',\n","             color='red', linestyle='dashed', linewidth=2)\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for PGD and FGSM Attacks with ε = {epsilon}')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the figure\n","    plt.savefig(f'roc_curve_epsilon_{epsilon}.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    return macro_roc_auc1, macro_roc_auc2\n","\n","# Lists to store all prediction probabilities and true labels for ROC curves\n","all_true_labels_onehot = []\n","all_pred_probs_pgd = []\n","all_pred_probs_fgsm = []\n","\n","for epsilon in epsilon_values:\n","    print(f\"Epsilon value: {epsilon}\")\n","    total_accuracy1 = 0.0\n","    total_accuracy2 = 0.0\n","    total_perturbation1 = 0.0\n","    total_perturbation2 = 0.0\n","    all_true_labels = []\n","    all_predicted_labels1 = []\n","    all_predicted_labels2 = []\n","\n","    # For this epsilon, collect all prediction probabilities\n","    epsilon_true_labels_onehot = []\n","    epsilon_pred_probs_pgd = []\n","    epsilon_pred_probs_fgsm = []\n","\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = (i + 1) * batch_size\n","\n","        batch_images = data_set(testX_CNN, start_idx, end_idx)\n","        batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","        batch_labels = testY_CNN[start_idx:end_idx]\n","\n","        perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","        perturbed_images2 = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","        perturbation1 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images1.numpy())\n","        perturbation2 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images2.numpy())\n","\n","        total_perturbation1 += perturbation1\n","        total_perturbation2 += perturbation2\n","\n","        X_perturbed1 = perturbed_images1.numpy()\n","        X_perturbed2 = perturbed_images2.numpy()\n","\n","        # Get raw probabilities for ROC curve\n","        adversarial_probs1 = model.predict(X_perturbed1)\n","        adversarial_probs2 = model.predict(X_perturbed2)\n","\n","        # Get predicted labels\n","        adversarial_predictions1 = np.argmax(adversarial_probs1, axis=1)\n","        adversarial_predictions2 = np.argmax(adversarial_probs2, axis=1)\n","\n","        # Collect data for ROC curve\n","        epsilon_true_labels_onehot.append(batch_labels)\n","        epsilon_pred_probs_pgd.append(adversarial_probs1)\n","        epsilon_pred_probs_fgsm.append(adversarial_probs2)\n","\n","        # Append results for precision and recall calculation\n","        true_labels_batch = np.argmax(batch_labels, axis=1)\n","        all_true_labels.extend(true_labels_batch)\n","        all_predicted_labels1.extend(adversarial_predictions1)\n","        all_predicted_labels2.extend(adversarial_predictions2)\n","\n","        accuracy1 = accuracy_score(true_labels_batch, adversarial_predictions1)\n","        accuracy2 = accuracy_score(true_labels_batch, adversarial_predictions2)\n","        total_accuracy1 += accuracy1\n","        total_accuracy2 += accuracy2\n","\n","    average_accuracy1 = total_accuracy1 / num_batches\n","    average_accuracy2 = total_accuracy2 / num_batches\n","    avg_perturbation1 = total_perturbation1 / num_batches\n","    avg_perturbation2 = total_perturbation2 / num_batches\n","\n","    # Concatenate all batches for this epsilon\n","    epsilon_true_labels_onehot = np.vstack(epsilon_true_labels_onehot)\n","    epsilon_pred_probs_pgd = np.vstack(epsilon_pred_probs_pgd)\n","    epsilon_pred_probs_fgsm = np.vstack(epsilon_pred_probs_fgsm)\n","\n","    # Calculate and plot ROC curve\n","    roc_auc1, roc_auc2 = plot_roc_curve(\n","        epsilon_true_labels_onehot,\n","        epsilon_pred_probs_pgd,\n","        epsilon_pred_probs_fgsm,\n","        epsilon\n","    )\n","\n","    avg_roc_auc1[epsilon] = roc_auc1\n","    avg_roc_auc2[epsilon] = roc_auc2\n","\n","    # Calculate precision and recall\n","    precision1 = precision_score(all_true_labels, all_predicted_labels1, average='macro')\n","    recall1 = recall_score(all_true_labels, all_predicted_labels1, average='macro')\n","    precision2 = precision_score(all_true_labels, all_predicted_labels2, average='macro')\n","    recall2 = recall_score(all_true_labels, all_predicted_labels2, average='macro')\n","\n","    avg_precision1[epsilon] = precision1\n","    avg_recall1[epsilon] = recall1\n","    avg_precision2[epsilon] = precision2\n","    avg_recall2[epsilon] = recall2\n","\n","    # Generate classification reports\n","    pgd_report = classification_report(all_true_labels, all_predicted_labels1, output_dict=True)\n","    fgsm_report = classification_report(all_true_labels, all_predicted_labels2, output_dict=True)\n","\n","    print(f\"Average accuracy of PGD attack for epsilon value {epsilon}: {average_accuracy1}\")\n","    avg_accuracies1[epsilon] = average_accuracy1\n","    print(f\"Average accuracy of FGSM attack for epsilon value {epsilon}: {average_accuracy2}\")\n","    avg_accuracies2[epsilon] = average_accuracy2\n","    print(f\"Average perturbation volume for PGD attack with epsilon {epsilon}: {avg_perturbation1}\")\n","    perturbed_volumes1[epsilon] = avg_perturbation1\n","    print(f\"Average perturbation volume for FGSM attack with epsilon {epsilon}: {avg_perturbation2}\")\n","    perturbed_volumes2[epsilon] = avg_perturbation2\n","\n","    # Print precision and recall\n","    print(f\"Average precision of PGD attack for epsilon value {epsilon}: {precision1}\")\n","    print(f\"Average recall of PGD attack for epsilon value {epsilon}: {recall1}\")\n","    print(f\"Average precision of FGSM attack for epsilon value {epsilon}: {precision2}\")\n","    print(f\"Average recall of FGSM attack for epsilon value {epsilon}: {recall2}\")\n","\n","    # Print ROC AUC\n","    print(f\"ROC AUC of PGD attack for epsilon value {epsilon}: {roc_auc1}\")\n","    print(f\"ROC AUC of FGSM attack for epsilon value {epsilon}: {roc_auc2}\")\n","\n","    # Print classification reports\n","    print(f\"\\nClassification Report for PGD Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels1))\n","\n","    print(f\"\\nClassification Report for FGSM Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels2))\n","\n","    # Clean up\n","    tf.keras.backend.clear_session()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Nm9V4PezPW7","executionInfo":{"status":"ok","timestamp":1741395518020,"user_tz":300,"elapsed":1152916,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"31cb2369-cb2a-4f8b-f758-de6a41c876f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon value: 0.01\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Average accuracy of PGD attack for epsilon value 0.01: 0.480268115942029\n","Average accuracy of FGSM attack for epsilon value 0.01: 0.4538695652173914\n","Average perturbation volume for PGD attack with epsilon 0.01: 2.2640044255101164\n","Average perturbation volume for FGSM attack with epsilon 0.01: 0.040475365908249565\n","Average precision of PGD attack for epsilon value 0.01: 0.48404309821134667\n","Average recall of PGD attack for epsilon value 0.01: 0.48029653807904626\n","Average precision of FGSM attack for epsilon value 0.01: 0.4626188093914296\n","Average recall of FGSM attack for epsilon value 0.01: 0.4588019177153028\n","ROC AUC of PGD attack for epsilon value 0.01: 0.6444652321702774\n","ROC AUC of FGSM attack for epsilon value 0.01: 0.6982582055323703\n","\n","Classification Report for PGD Attack (ε = 0.01):\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.56      0.51     47512\n","           1       0.52      0.39      0.45     47269\n","           2       0.46      0.49      0.47     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.48      0.48      0.48    138000\n","weighted avg       0.48      0.48      0.48    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.01):\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.66      0.55     47512\n","           1       0.48      0.08      0.14     47269\n","           2       0.43      0.64      0.51     43219\n","\n","    accuracy                           0.45    138000\n","   macro avg       0.46      0.46      0.40    138000\n","weighted avg       0.46      0.45      0.40    138000\n","\n","Epsilon value: 0.1\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Average accuracy of PGD attack for epsilon value 0.1: 0.4713260869565218\n","Average accuracy of FGSM attack for epsilon value 0.1: 0.4438260869565218\n","Average perturbation volume for PGD attack with epsilon 0.1: 2.264095197769179\n","Average perturbation volume for FGSM attack with epsilon 0.1: 0.3284203911173171\n","Average precision of PGD attack for epsilon value 0.1: 0.4755303340754651\n","Average recall of PGD attack for epsilon value 0.1: 0.4712932716640062\n","Average precision of FGSM attack for epsilon value 0.1: 0.42648246537330814\n","Average recall of FGSM attack for epsilon value 0.1: 0.4478940897596875\n","ROC AUC of PGD attack for epsilon value 0.1: 0.6372814833097108\n","ROC AUC of FGSM attack for epsilon value 0.1: 0.6384939123638927\n","\n","Classification Report for PGD Attack (ε = 0.1):\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.55      0.50     47512\n","           1       0.52      0.39      0.44     47269\n","           2       0.45      0.47      0.46     43219\n","\n","    accuracy                           0.47    138000\n","   macro avg       0.48      0.47      0.47    138000\n","weighted avg       0.48      0.47      0.47    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.1):\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.74      0.57     47512\n","           1       0.40      0.00      0.00     47269\n","           2       0.43      0.60      0.50     43219\n","\n","    accuracy                           0.44    138000\n","   macro avg       0.43      0.45      0.36    138000\n","weighted avg       0.43      0.44      0.35    138000\n","\n","Epsilon value: 1\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Average accuracy of PGD attack for epsilon value 1: 0.3765942028985508\n","Average accuracy of FGSM attack for epsilon value 1: 0.4186014492753622\n","Average perturbation volume for PGD attack with epsilon 1: 2.266117651177489\n","Average perturbation volume for FGSM attack with epsilon 1: 3.093316589576611\n","Average precision of PGD attack for epsilon value 1: 0.3819734589609267\n","Average recall of PGD attack for epsilon value 1: 0.37693655019383066\n","Average precision of FGSM attack for epsilon value 1: 0.43246533005242765\n","Average recall of FGSM attack for epsilon value 1: 0.42113311887508686\n","ROC AUC of PGD attack for epsilon value 1: 0.5340870219587407\n","ROC AUC of FGSM attack for epsilon value 1: 0.6085496853053451\n","\n","Classification Report for PGD Attack (ε = 1):\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.47      0.42     47512\n","           1       0.42      0.26      0.32     47269\n","           2       0.35      0.39      0.37     43219\n","\n","    accuracy                           0.38    138000\n","   macro avg       0.38      0.38      0.37    138000\n","weighted avg       0.38      0.38      0.37    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1):\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.72      0.54     47512\n","           1       0.47      0.02      0.03     47269\n","           2       0.40      0.53      0.46     43219\n","\n","    accuracy                           0.42    138000\n","   macro avg       0.43      0.42      0.34    138000\n","weighted avg       0.43      0.42      0.34    138000\n","\n","Epsilon value: 10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Average accuracy of PGD attack for epsilon value 10: 0.22156521739130436\n","Average accuracy of FGSM attack for epsilon value 10: 0.4186014492753622\n","Average perturbation volume for PGD attack with epsilon 10: 2.2709118859923403\n","Average perturbation volume for FGSM attack with epsilon 10: 3.093316589576611\n","Average precision of PGD attack for epsilon value 10: 0.16769176627993201\n","Average recall of PGD attack for epsilon value 10: 0.22335496076982753\n","Average precision of FGSM attack for epsilon value 10: 0.43246533005242765\n","Average recall of FGSM attack for epsilon value 10: 0.42113311887508686\n","ROC AUC of PGD attack for epsilon value 10: 0.35742700279259343\n","ROC AUC of FGSM attack for epsilon value 10: 0.6085496853053451\n","\n","Classification Report for PGD Attack (ε = 10):\n","              precision    recall  f1-score   support\n","\n","           0       0.27      0.37      0.31     47512\n","           1       0.01      0.00      0.01     47269\n","           2       0.23      0.29      0.26     43219\n","\n","    accuracy                           0.22    138000\n","   macro avg       0.17      0.22      0.19    138000\n","weighted avg       0.17      0.22      0.19    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 10):\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.72      0.54     47512\n","           1       0.47      0.02      0.03     47269\n","           2       0.40      0.53      0.46     43219\n","\n","    accuracy                           0.42    138000\n","   macro avg       0.43      0.42      0.34    138000\n","weighted avg       0.43      0.42      0.34    138000\n","\n"]}]},{"cell_type":"code","source":["\"\"\"TRADING STRATEGY AFTER ATTACK ON 3 EPSILON VALUES\"\"\"\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","def run_adversarial_trading_analysis(model, testX_CNN, testY_CNN, dec_test, epsilon_values, batch_size=2000):\n","    \"\"\"Run trading strategy analysis with adversarial attacks\"\"\"\n","    results_pgd = []\n","    results_fgsm = []\n","    thresholds = [0.85, 0.90, 0.95, 0.99]  # Explicit thresholds\n","\n","    def data_set(testX_CNN, start_idx, end_idx):\n","        \"\"\"Prepare the dataset by shifting\"\"\"\n","        shifted_testX_CNN = tf.concat([\n","            testX_CNN[start_idx:end_idx, 1:100, :, :],\n","            testX_CNN[start_idx:end_idx, 99:, :, :]\n","        ], axis=1)\n","        return tf.cast(shifted_testX_CNN, tf.float32)\n","\n","    def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","        \"\"\"Apply volume constraints to the images\"\"\"\n","        images = images.numpy()\n","        slices = [slice(None)] * images.ndim\n","        testX_CNN_batch = testX_CNN[start_idx:end_idx]\n","        for idx in range(images.shape[dimension]):\n","            slices[dimension] = idx\n","            images[tuple(slices)] = np.maximum(\n","                images[tuple(slices)],\n","                testX_CNN_batch[tuple(slices)]\n","            )\n","        return tf.convert_to_tensor(images, dtype=tf.float32)\n","\n","    def get_model_predictions(perturbed_images):\n","        \"\"\"Get model predictions with error handling\"\"\"\n","        try:\n","            with tf.device('/CPU:0'):\n","                predictions = model(perturbed_images, training=False)\n","                return predictions.numpy()\n","        except Exception as e:\n","            print(f\"Error in model prediction: {str(e)}\")\n","            return None\n","\n","    def fgsm_attack(images, labels, epsilon):\n","        \"\"\"Implement FGSM attack\"\"\"\n","        try:\n","            with tf.GradientTape() as tape:\n","                tape.watch(images)\n","                predictions = model(images, training=False)\n","                loss = tf.keras.losses.CategoricalCrossentropy()(labels, predictions)\n","\n","            gradient = tape.gradient(loss, images)\n","            signed_grad = tf.sign(gradient)\n","\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            perturbed_images = images + epsilon * signed_masked\n","            return tf.clip_by_value(perturbed_images, 0, 1)\n","        except Exception as e:\n","            print(f\"Error in FGSM attack: {str(e)}\")\n","            return None\n","\n","\n","    def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","        perturbed_images = tf.identity(images)\n","\n","        for _ in range(num_iterations):\n","            # Gradient step\n","            with tf.GradientTape() as tape:\n","                tape.watch(perturbed_images)\n","                predictions = model(perturbed_images)\n","                loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","            gradient = tape.gradient(loss, perturbed_images)\n","            signed_grad = tf.sign(gradient)\n","\n","            # Apply masking to gradient\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            # Apply gradient step\n","            perturbed_images = perturbed_images + step_size * signed_masked\n","\n","            # Step 1: Apply volume constraint\n","            perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","            # Step 2: Apply L2 norm constraint (projection step)\n","            delta = perturbed_images - images  # Calculate current perturbation\n","\n","            # Reshape to flatten all dimensions except batch\n","            delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","            # Calculate L2 norm on the flattened dimensions\n","            norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","            # Reshape norm for broadcasting\n","            norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","            # Scale perturbation\n","            scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","            delta = delta * scaling\n","\n","            perturbed_images = images + delta  # Apply constrained perturbation\n","\n","            # Step 3: Apply clipping to valid range [0,1]\n","            perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","            # Step 4: Re-apply volume constraint after all other constraints\n","            # This ensures volume constraint takes precedence if there's a conflict\n","            perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","        return perturbed_images\n","\n","    max_test_size = testX_CNN.shape[0]\n","    num_batches = max_test_size // batch_size\n","\n","    for epsilon in epsilon_values:\n","        print(f\"\\nAnalyzing epsilon: {epsilon}\")\n","\n","        pgd_predictions = []\n","        fgsm_predictions = []\n","\n","        for i in range(num_batches):\n","            start_idx = i * batch_size\n","            end_idx = min((i + 1) * batch_size, max_test_size)\n","\n","            try:\n","                # Prepare batch data\n","                batch_images = data_set(testX_CNN, start_idx, end_idx)\n","                batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","                batch_labels = testY_CNN[start_idx:end_idx]\n","\n","                # Generate adversarial examples\n","                perturbed_images_pgd = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","                perturbed_images_fgsm = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","                if perturbed_images_pgd is not None and perturbed_images_fgsm is not None:\n","                    # Calculate perturbation volumes\n","                    pgd_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_pgd - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    fgsm_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_fgsm - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    print(f\"Batch {i+1}/{num_batches} - PGD volume: {pgd_volume:.6f}, FGSM volume: {fgsm_volume:.6f}\")\n","\n","                    # Get predictions\n","                    pgd_pred = get_model_predictions(perturbed_images_pgd)\n","                    fgsm_pred = get_model_predictions(perturbed_images_fgsm)\n","\n","                    if pgd_pred is not None:\n","                        pgd_predictions.append(pgd_pred)\n","                    if fgsm_pred is not None:\n","                        fgsm_predictions.append(fgsm_pred)\n","\n","            except Exception as e:\n","                print(f\"Error processing batch {i}: {str(e)}\")\n","                continue\n","\n","            tf.keras.backend.clear_session()\n","\n","        if pgd_predictions and fgsm_predictions:\n","            pgd_predictions = np.vstack(pgd_predictions)\n","            fgsm_predictions = np.vstack(fgsm_predictions)\n","\n","            # Process for each threshold\n","            for threshold in thresholds:\n","                # Process PGD results\n","                pgd_result = implement_fi2010_strategy(\n","                    predictions=pgd_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if pgd_result:\n","                    pgd_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'PGD'\n","                    })\n","                    results_pgd.append(pgd_result)\n","\n","                # Process FGSM results\n","                fgsm_result = implement_fi2010_strategy(\n","                    predictions=fgsm_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if fgsm_result:\n","                    fgsm_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'FGSM'\n","                    })\n","                    results_fgsm.append(fgsm_result)\n","\n","    # Create DataFrames\n","    pgd_df = pd.DataFrame(results_pgd) if results_pgd else pd.DataFrame()\n","    fgsm_df = pd.DataFrame(results_fgsm) if results_fgsm else pd.DataFrame()\n","\n","    # Display detailed summaries\n","    if not pgd_df.empty:\n","        print(\"\\nPGD Attack Summary by Threshold:\")\n","        summary_pgd = pgd_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        # Format the display\n","        pd.set_option('display.float_format', lambda x: '%.4f' % x)\n","        print(\"\\nPGD Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_pgd.loc[eps])\n","\n","    if not fgsm_df.empty:\n","        print(\"\\nFGSM Attack Summary by Threshold:\")\n","        summary_fgsm = fgsm_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        print(\"\\nFGSM Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_fgsm.loc[eps])\n","\n","    return pgd_df, fgsm_df\n","\n","def implement_fi2010_strategy(predictions, dec_data, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"Implementation of the FI-2010 trading strategy\"\"\"\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","    trades_info = []\n","    budget = 100\n","\n","    for i in range(k, min_length):\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax(predictions[i])\n","        max_prob = np.max(predictions[i])\n","\n","        if max_prob > prob_threshold and pred_class != 1:\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","            shares = budget / mid_prices[i]\n","\n","            if pred_class == 2:  # Long trade\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'profit': profit,\n","                    'correct': actual_direction == 1\n","                })\n","            elif pred_class == 0:  # Short trade\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'profit': profit,\n","                    'correct': actual_direction == -1\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","epsilon_values = [0.1, 1, 10]\n","results_pgd, results_fgsm = run_adversarial_trading_analysis(\n","    model=model,\n","    testX_CNN=testX_CNN,\n","    testY_CNN=testY_CNN,\n","    dec_test=dec_test,\n","    epsilon_values=epsilon_values,\n","    batch_size=2000\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGh8oPlU08FC","executionInfo":{"status":"ok","timestamp":1741396852918,"user_tz":300,"elapsed":1130504,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"c12c5706-dd7b-4335-8029-068dca136007"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Analyzing epsilon: 0.1\n","Batch 1/69 - PGD volume: 0.164485, FGSM volume: 0.313527\n","Batch 2/69 - PGD volume: 4.589868, FGSM volume: 0.330917\n","Batch 3/69 - PGD volume: 6.256168, FGSM volume: 0.335541\n","Batch 4/69 - PGD volume: 6.275187, FGSM volume: 0.339270\n","Batch 5/69 - PGD volume: 6.400707, FGSM volume: 0.332946\n","Batch 6/69 - PGD volume: 5.701828, FGSM volume: 0.336859\n","Batch 7/69 - PGD volume: 4.511963, FGSM volume: 0.343240\n","Batch 8/69 - PGD volume: 4.263456, FGSM volume: 0.339537\n","Batch 9/69 - PGD volume: 4.204227, FGSM volume: 0.338541\n","Batch 10/69 - PGD volume: 4.127592, FGSM volume: 0.340656\n","Batch 11/69 - PGD volume: 6.201607, FGSM volume: 0.330585\n","Batch 12/69 - PGD volume: 4.585088, FGSM volume: 0.332009\n","Batch 13/69 - PGD volume: 1.555244, FGSM volume: 0.332970\n","Batch 14/69 - PGD volume: 1.289550, FGSM volume: 0.333536\n","Batch 15/69 - PGD volume: 1.111898, FGSM volume: 0.332902\n","Batch 16/69 - PGD volume: 1.227553, FGSM volume: 0.329902\n","Batch 17/69 - PGD volume: 1.326565, FGSM volume: 0.323252\n","Batch 18/69 - PGD volume: 1.618934, FGSM volume: 0.315561\n","Batch 19/69 - PGD volume: 1.660653, FGSM volume: 0.315858\n","Batch 20/69 - PGD volume: 1.641510, FGSM volume: 0.317056\n","Batch 21/69 - PGD volume: 1.704530, FGSM volume: 0.317064\n","Batch 22/69 - PGD volume: 1.730240, FGSM volume: 0.316862\n","Batch 23/69 - PGD volume: 1.518139, FGSM volume: 0.315689\n","Batch 24/69 - PGD volume: 1.517826, FGSM volume: 0.316991\n","Batch 25/69 - PGD volume: 1.565952, FGSM volume: 0.315905\n","Batch 26/69 - PGD volume: 1.540854, FGSM volume: 0.317790\n","Batch 27/69 - PGD volume: 2.059161, FGSM volume: 0.317602\n","Batch 28/69 - PGD volume: 1.796127, FGSM volume: 0.316283\n","Batch 29/69 - PGD volume: 1.652586, FGSM volume: 0.324207\n","Batch 30/69 - PGD volume: 1.202889, FGSM volume: 0.339734\n","Batch 31/69 - PGD volume: 1.654392, FGSM volume: 0.334691\n","Batch 32/69 - PGD volume: 1.129876, FGSM volume: 0.333936\n","Batch 33/69 - PGD volume: 1.299875, FGSM volume: 0.335676\n","Batch 34/69 - PGD volume: 1.470574, FGSM volume: 0.338185\n","Batch 35/69 - PGD volume: 0.855574, FGSM volume: 0.343920\n","Batch 36/69 - PGD volume: 1.096550, FGSM volume: 0.343592\n","Batch 37/69 - PGD volume: 1.451882, FGSM volume: 0.340465\n","Batch 38/69 - PGD volume: 1.070381, FGSM volume: 0.335061\n","Batch 39/69 - PGD volume: 2.008562, FGSM volume: 0.340729\n","Batch 40/69 - PGD volume: 2.309821, FGSM volume: 0.335477\n","Batch 41/69 - PGD volume: 2.414186, FGSM volume: 0.337103\n","Batch 42/69 - PGD volume: 2.440820, FGSM volume: 0.337050\n","Batch 43/69 - PGD volume: 2.450301, FGSM volume: 0.340021\n","Batch 44/69 - PGD volume: 2.408777, FGSM volume: 0.332030\n","Batch 45/69 - PGD volume: 2.146757, FGSM volume: 0.328317\n","Batch 46/69 - PGD volume: 1.646788, FGSM volume: 0.317084\n","Batch 47/69 - PGD volume: 1.693528, FGSM volume: 0.316429\n","Batch 48/69 - PGD volume: 1.636279, FGSM volume: 0.316031\n","Batch 49/69 - PGD volume: 2.753690, FGSM volume: 0.316361\n","Batch 50/69 - PGD volume: 1.833186, FGSM volume: 0.317169\n","Batch 51/69 - PGD volume: 1.753896, FGSM volume: 0.316161\n","Batch 52/69 - PGD volume: 1.757358, FGSM volume: 0.316283\n","Batch 53/69 - PGD volume: 2.183680, FGSM volume: 0.313978\n","Batch 54/69 - PGD volume: 2.115732, FGSM volume: 0.316626\n","Batch 55/69 - PGD volume: 1.877950, FGSM volume: 0.320330\n","Batch 56/69 - PGD volume: 2.578568, FGSM volume: 0.337812\n","Batch 57/69 - PGD volume: 1.401843, FGSM volume: 0.342385\n","Batch 58/69 - PGD volume: 2.690943, FGSM volume: 0.346202\n","Batch 59/69 - PGD volume: 2.353764, FGSM volume: 0.343217\n","Batch 60/69 - PGD volume: 1.505237, FGSM volume: 0.351722\n","Batch 61/69 - PGD volume: 1.624507, FGSM volume: 0.334141\n","Batch 62/69 - PGD volume: 1.422902, FGSM volume: 0.334527\n","Batch 63/69 - PGD volume: 1.145121, FGSM volume: 0.332481\n","Batch 64/69 - PGD volume: 1.603540, FGSM volume: 0.319422\n","Batch 65/69 - PGD volume: 1.767290, FGSM volume: 0.316321\n","Batch 66/69 - PGD volume: 1.813725, FGSM volume: 0.316794\n","Batch 67/69 - PGD volume: 1.829396, FGSM volume: 0.316594\n","Batch 68/69 - PGD volume: 2.013160, FGSM volume: 0.317649\n","Batch 69/69 - PGD volume: 2.009771, FGSM volume: 0.316247\n","\n","Analyzing epsilon: 1\n","Batch 1/69 - PGD volume: 0.194080, FGSM volume: 3.110354\n","Batch 2/69 - PGD volume: 4.595016, FGSM volume: 3.057953\n","Batch 3/69 - PGD volume: 6.256173, FGSM volume: 3.064937\n","Batch 4/69 - PGD volume: 6.275190, FGSM volume: 3.045851\n","Batch 5/69 - PGD volume: 6.400712, FGSM volume: 3.054503\n","Batch 6/69 - PGD volume: 5.701836, FGSM volume: 3.059499\n","Batch 7/69 - PGD volume: 4.511977, FGSM volume: 3.043240\n","Batch 8/69 - PGD volume: 4.263474, FGSM volume: 3.058929\n","Batch 9/69 - PGD volume: 4.204245, FGSM volume: 3.049168\n","Batch 10/69 - PGD volume: 4.127613, FGSM volume: 3.052654\n","Batch 11/69 - PGD volume: 6.201612, FGSM volume: 3.074555\n","Batch 12/69 - PGD volume: 4.585183, FGSM volume: 3.069391\n","Batch 13/69 - PGD volume: 1.556853, FGSM volume: 3.110656\n","Batch 14/69 - PGD volume: 1.292317, FGSM volume: 3.072230\n","Batch 15/69 - PGD volume: 1.117156, FGSM volume: 3.080141\n","Batch 16/69 - PGD volume: 1.231138, FGSM volume: 3.065510\n","Batch 17/69 - PGD volume: 1.329167, FGSM volume: 3.092419\n","Batch 18/69 - PGD volume: 1.619230, FGSM volume: 3.128719\n","Batch 19/69 - PGD volume: 1.660819, FGSM volume: 3.134836\n","Batch 20/69 - PGD volume: 1.642203, FGSM volume: 3.150800\n","Batch 21/69 - PGD volume: 1.705234, FGSM volume: 3.143054\n","Batch 22/69 - PGD volume: 1.730713, FGSM volume: 3.143185\n","Batch 23/69 - PGD volume: 1.519132, FGSM volume: 3.135693\n","Batch 24/69 - PGD volume: 1.518258, FGSM volume: 3.134501\n","Batch 25/69 - PGD volume: 1.566636, FGSM volume: 3.126399\n","Batch 26/69 - PGD volume: 1.541751, FGSM volume: 3.140379\n","Batch 27/69 - PGD volume: 2.059252, FGSM volume: 3.151036\n","Batch 28/69 - PGD volume: 1.796508, FGSM volume: 3.139911\n","Batch 29/69 - PGD volume: 1.653422, FGSM volume: 3.098429\n","Batch 30/69 - PGD volume: 1.206852, FGSM volume: 3.049312\n","Batch 31/69 - PGD volume: 1.656176, FGSM volume: 3.080350\n","Batch 32/69 - PGD volume: 1.134677, FGSM volume: 3.059678\n","Batch 33/69 - PGD volume: 1.304020, FGSM volume: 3.074241\n","Batch 34/69 - PGD volume: 1.472306, FGSM volume: 3.058765\n","Batch 35/69 - PGD volume: 0.865854, FGSM volume: 3.067777\n","Batch 36/69 - PGD volume: 1.104046, FGSM volume: 3.067658\n","Batch 37/69 - PGD volume: 1.455593, FGSM volume: 3.050789\n","Batch 38/69 - PGD volume: 1.078104, FGSM volume: 3.068099\n","Batch 39/69 - PGD volume: 2.010855, FGSM volume: 3.046519\n","Batch 40/69 - PGD volume: 2.309906, FGSM volume: 3.068206\n","Batch 41/69 - PGD volume: 2.414258, FGSM volume: 3.085673\n","Batch 42/69 - PGD volume: 2.440883, FGSM volume: 3.070914\n","Batch 43/69 - PGD volume: 2.450377, FGSM volume: 3.111016\n","Batch 44/69 - PGD volume: 2.408863, FGSM volume: 3.051478\n","Batch 45/69 - PGD volume: 2.146847, FGSM volume: 3.094254\n","Batch 46/69 - PGD volume: 1.647166, FGSM volume: 3.145014\n","Batch 47/69 - PGD volume: 1.693745, FGSM volume: 3.138383\n","Batch 48/69 - PGD volume: 1.637131, FGSM volume: 3.133209\n","Batch 49/69 - PGD volume: 2.753710, FGSM volume: 3.140050\n","Batch 50/69 - PGD volume: 1.833302, FGSM volume: 3.147036\n","Batch 51/69 - PGD volume: 1.754059, FGSM volume: 3.132392\n","Batch 52/69 - PGD volume: 1.757575, FGSM volume: 3.136312\n","Batch 53/69 - PGD volume: 2.183783, FGSM volume: 3.116194\n","Batch 54/69 - PGD volume: 2.115971, FGSM volume: 3.138577\n","Batch 55/69 - PGD volume: 1.879620, FGSM volume: 3.095590\n","Batch 56/69 - PGD volume: 2.579235, FGSM volume: 3.046816\n","Batch 57/69 - PGD volume: 1.406970, FGSM volume: 3.032229\n","Batch 58/69 - PGD volume: 2.692929, FGSM volume: 3.047412\n","Batch 59/69 - PGD volume: 2.354155, FGSM volume: 3.038565\n","Batch 60/69 - PGD volume: 1.509383, FGSM volume: 3.021533\n","Batch 61/69 - PGD volume: 1.626691, FGSM volume: 3.064151\n","Batch 62/69 - PGD volume: 1.426451, FGSM volume: 3.064912\n","Batch 63/69 - PGD volume: 1.151088, FGSM volume: 3.065131\n","Batch 64/69 - PGD volume: 1.604348, FGSM volume: 3.147135\n","Batch 65/69 - PGD volume: 1.769505, FGSM volume: 3.132436\n","Batch 66/69 - PGD volume: 1.814738, FGSM volume: 3.133229\n","Batch 67/69 - PGD volume: 1.829956, FGSM volume: 3.138933\n","Batch 68/69 - PGD volume: 2.013719, FGSM volume: 3.155445\n","Batch 69/69 - PGD volume: 2.010374, FGSM volume: 3.134500\n","\n","Analyzing epsilon: 10\n","Batch 1/69 - PGD volume: 0.194080, FGSM volume: 3.110354\n","Batch 2/69 - PGD volume: 4.595870, FGSM volume: 3.057953\n","Batch 3/69 - PGD volume: 6.257250, FGSM volume: 3.064937\n","Batch 4/69 - PGD volume: 6.276420, FGSM volume: 3.045851\n","Batch 5/69 - PGD volume: 6.401768, FGSM volume: 3.054503\n","Batch 6/69 - PGD volume: 5.703114, FGSM volume: 3.059499\n","Batch 7/69 - PGD volume: 4.513594, FGSM volume: 3.043240\n","Batch 8/69 - PGD volume: 4.265323, FGSM volume: 3.058929\n","Batch 9/69 - PGD volume: 4.205965, FGSM volume: 3.049168\n","Batch 10/69 - PGD volume: 4.129447, FGSM volume: 3.052654\n","Batch 11/69 - PGD volume: 6.202601, FGSM volume: 3.074555\n","Batch 12/69 - PGD volume: 4.588260, FGSM volume: 3.069391\n","Batch 13/69 - PGD volume: 1.563102, FGSM volume: 3.110656\n","Batch 14/69 - PGD volume: 1.297956, FGSM volume: 3.072230\n","Batch 15/69 - PGD volume: 1.120692, FGSM volume: 3.080141\n","Batch 16/69 - PGD volume: 1.236073, FGSM volume: 3.065510\n","Batch 17/69 - PGD volume: 1.334150, FGSM volume: 3.092419\n","Batch 18/69 - PGD volume: 1.626324, FGSM volume: 3.128719\n","Batch 19/69 - PGD volume: 1.668757, FGSM volume: 3.134836\n","Batch 20/69 - PGD volume: 1.650213, FGSM volume: 3.150800\n","Batch 21/69 - PGD volume: 1.713225, FGSM volume: 3.143054\n","Batch 22/69 - PGD volume: 1.737631, FGSM volume: 3.143185\n","Batch 23/69 - PGD volume: 1.526369, FGSM volume: 3.135693\n","Batch 24/69 - PGD volume: 1.526820, FGSM volume: 3.134501\n","Batch 25/69 - PGD volume: 1.574508, FGSM volume: 3.126399\n","Batch 26/69 - PGD volume: 1.549731, FGSM volume: 3.140379\n","Batch 27/69 - PGD volume: 2.066943, FGSM volume: 3.151036\n","Batch 28/69 - PGD volume: 1.803459, FGSM volume: 3.139911\n","Batch 29/69 - PGD volume: 1.659718, FGSM volume: 3.098429\n","Batch 30/69 - PGD volume: 1.211097, FGSM volume: 3.049312\n","Batch 31/69 - PGD volume: 1.661666, FGSM volume: 3.080350\n","Batch 32/69 - PGD volume: 1.138728, FGSM volume: 3.059678\n","Batch 33/69 - PGD volume: 1.308023, FGSM volume: 3.074241\n","Batch 34/69 - PGD volume: 1.478364, FGSM volume: 3.058765\n","Batch 35/69 - PGD volume: 0.866665, FGSM volume: 3.067777\n","Batch 36/69 - PGD volume: 1.107274, FGSM volume: 3.067658\n","Batch 37/69 - PGD volume: 1.459858, FGSM volume: 3.050789\n","Batch 38/69 - PGD volume: 1.079965, FGSM volume: 3.068099\n","Batch 39/69 - PGD volume: 2.014534, FGSM volume: 3.046519\n","Batch 40/69 - PGD volume: 2.314173, FGSM volume: 3.068206\n","Batch 41/69 - PGD volume: 2.418944, FGSM volume: 3.085673\n","Batch 42/69 - PGD volume: 2.445383, FGSM volume: 3.070914\n","Batch 43/69 - PGD volume: 2.454409, FGSM volume: 3.111016\n","Batch 44/69 - PGD volume: 2.412987, FGSM volume: 3.051478\n","Batch 45/69 - PGD volume: 2.151833, FGSM volume: 3.094254\n","Batch 46/69 - PGD volume: 1.654212, FGSM volume: 3.145014\n","Batch 47/69 - PGD volume: 1.701239, FGSM volume: 3.138383\n","Batch 48/69 - PGD volume: 1.644501, FGSM volume: 3.133209\n","Batch 49/69 - PGD volume: 2.759394, FGSM volume: 3.140050\n","Batch 50/69 - PGD volume: 1.840829, FGSM volume: 3.147036\n","Batch 51/69 - PGD volume: 1.761686, FGSM volume: 3.132392\n","Batch 52/69 - PGD volume: 1.765606, FGSM volume: 3.136312\n","Batch 53/69 - PGD volume: 2.192008, FGSM volume: 3.116194\n","Batch 54/69 - PGD volume: 2.122173, FGSM volume: 3.138577\n","Batch 55/69 - PGD volume: 1.884207, FGSM volume: 3.095590\n","Batch 56/69 - PGD volume: 2.583586, FGSM volume: 3.046816\n","Batch 57/69 - PGD volume: 1.409641, FGSM volume: 3.032229\n","Batch 58/69 - PGD volume: 2.696414, FGSM volume: 3.047412\n","Batch 59/69 - PGD volume: 2.358402, FGSM volume: 3.038565\n","Batch 60/69 - PGD volume: 1.513153, FGSM volume: 3.021533\n","Batch 61/69 - PGD volume: 1.630754, FGSM volume: 3.064151\n","Batch 62/69 - PGD volume: 1.429878, FGSM volume: 3.064912\n","Batch 63/69 - PGD volume: 1.153612, FGSM volume: 3.065131\n","Batch 64/69 - PGD volume: 1.610870, FGSM volume: 3.147135\n","Batch 65/69 - PGD volume: 1.774184, FGSM volume: 3.132436\n","Batch 66/69 - PGD volume: 1.820810, FGSM volume: 3.133229\n","Batch 67/69 - PGD volume: 1.836387, FGSM volume: 3.138933\n","Batch 68/69 - PGD volume: 2.020070, FGSM volume: 3.155445\n","Batch 69/69 - PGD volume: 2.016036, FGSM volume: 3.134500\n","\n","PGD Attack Summary by Threshold:\n","\n","PGD Analysis Results:\n","\n","Epsilon: 0.1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         -28.1349  48083.0000    0.4534\n","0.9000           1.1100  38672.0000    0.4655\n","0.9500          42.4608  26036.0000    0.4955\n","0.9900          41.4784   8416.0000    0.4753\n","\n","Epsilon: 1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500        -384.3686  55393.0000    0.4513\n","0.9000        -372.6733  45210.0000    0.4667\n","0.9500        -283.9174  30811.0000    0.4674\n","0.9900          77.4950   9744.0000    0.3592\n","\n","Epsilon: 10\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500        -376.6006  77576.0000    0.3880\n","0.9000        -309.0703  66529.0000    0.3938\n","0.9500        -269.5307  48610.0000    0.4073\n","0.9900          -2.7170  16622.0000    0.3429\n","\n","FGSM Attack Summary by Threshold:\n","\n","FGSM Analysis Results:\n","\n","Epsilon: 0.1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500          88.7230  79898.0000    0.3917\n","0.9000         241.8948  66760.0000    0.3880\n","0.9500           6.4041  47441.0000    0.3794\n","0.9900          93.4777  18847.0000    0.4192\n","\n","Epsilon: 1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         334.4375  93705.0000    0.4130\n","0.9000         250.5322  84852.0000    0.4196\n","0.9500         126.2845  71170.0000    0.4286\n","0.9900        -147.9719  45484.0000    0.4309\n","\n","Epsilon: 10\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         334.4375  93705.0000    0.4130\n","0.9000         250.5322  84852.0000    0.4196\n","0.9500         126.2845  71170.0000    0.4286\n","0.9900        -147.9719  45484.0000    0.4309\n"]}]},{"cell_type":"code","source":["\"\"\"TRADING STRATEGY AFTER ATTACK ON 3 EPSILON VALUES\"\"\"\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","def run_adversarial_trading_analysis(model, testX_CNN, testY_CNN, dec_test, epsilon_values, batch_size=2000):\n","    \"\"\"Run trading strategy analysis with adversarial attacks\"\"\"\n","    results_pgd = []\n","    results_fgsm = []\n","    thresholds = [0.85, 0.90, 0.95, 0.99]  # Explicit thresholds\n","\n","    def data_set(testX_CNN, start_idx, end_idx):\n","        \"\"\"Prepare the dataset by shifting\"\"\"\n","        shifted_testX_CNN = tf.concat([\n","            testX_CNN[start_idx:end_idx, 1:100, :, :],\n","            testX_CNN[start_idx:end_idx, 99:, :, :]\n","        ], axis=1)\n","        return tf.cast(shifted_testX_CNN, tf.float32)\n","\n","    def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","        \"\"\"Apply volume constraints to the images\"\"\"\n","        images = images.numpy()\n","        slices = [slice(None)] * images.ndim\n","        testX_CNN_batch = testX_CNN[start_idx:end_idx]\n","        for idx in range(images.shape[dimension]):\n","            slices[dimension] = idx\n","            images[tuple(slices)] = np.maximum(\n","                images[tuple(slices)],\n","                testX_CNN_batch[tuple(slices)]\n","            )\n","        return tf.convert_to_tensor(images, dtype=tf.float32)\n","\n","    def get_model_predictions(perturbed_images):\n","        \"\"\"Get model predictions with error handling\"\"\"\n","        try:\n","            with tf.device('/CPU:0'):\n","                predictions = model(perturbed_images, training=False)\n","                return predictions.numpy()\n","        except Exception as e:\n","            print(f\"Error in model prediction: {str(e)}\")\n","            return None\n","\n","    def fgsm_attack(images, labels, epsilon):\n","        \"\"\"Implement FGSM attack\"\"\"\n","        try:\n","            with tf.GradientTape() as tape:\n","                tape.watch(images)\n","                predictions = model(images, training=False)\n","                loss = tf.keras.losses.CategoricalCrossentropy()(labels, predictions)\n","\n","            gradient = tape.gradient(loss, images)\n","            signed_grad = tf.sign(gradient)\n","\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            perturbed_images = images + epsilon * signed_masked\n","            return tf.clip_by_value(perturbed_images, 0, 1)\n","        except Exception as e:\n","            print(f\"Error in FGSM attack: {str(e)}\")\n","            return None\n","\n","\n","    def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","        perturbed_images = tf.identity(images)\n","\n","        for _ in range(num_iterations):\n","            # Gradient step\n","            with tf.GradientTape() as tape:\n","                tape.watch(perturbed_images)\n","                predictions = model(perturbed_images)\n","                loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","            gradient = tape.gradient(loss, perturbed_images)\n","            signed_grad = tf.sign(gradient)\n","\n","            # Apply masking to gradient\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            # Apply gradient step\n","            perturbed_images = perturbed_images + step_size * signed_masked\n","\n","            # Step 1: Apply volume constraint\n","            perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","            # Step 2: Apply L2 norm constraint (projection step)\n","            delta = perturbed_images - images  # Calculate current perturbation\n","\n","            # Reshape to flatten all dimensions except batch\n","            delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","            # Calculate L2 norm on the flattened dimensions\n","            norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","            # Reshape norm for broadcasting\n","            norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","            # Scale perturbation\n","            scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","            delta = delta * scaling\n","\n","            perturbed_images = images + delta  # Apply constrained perturbation\n","\n","            # Step 3: Apply clipping to valid range [0,1]\n","            perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","            # Step 4: Re-apply volume constraint after all other constraints\n","            # This ensures volume constraint takes precedence if there's a conflict\n","            perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","        return perturbed_images\n","\n","    max_test_size = testX_CNN.shape[0]\n","    num_batches = max_test_size // batch_size\n","\n","    for epsilon in epsilon_values:\n","        print(f\"\\nAnalyzing epsilon: {epsilon}\")\n","\n","        pgd_predictions = []\n","        fgsm_predictions = []\n","\n","        for i in range(num_batches):\n","            start_idx = i * batch_size\n","            end_idx = min((i + 1) * batch_size, max_test_size)\n","\n","            try:\n","                # Prepare batch data\n","                batch_images = data_set(testX_CNN, start_idx, end_idx)\n","                batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","                batch_labels = testY_CNN[start_idx:end_idx]\n","\n","                # Generate adversarial examples\n","                perturbed_images_pgd = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","                perturbed_images_fgsm = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","                if perturbed_images_pgd is not None and perturbed_images_fgsm is not None:\n","                    # Calculate perturbation volumes\n","                    pgd_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_pgd - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    fgsm_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_fgsm - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    print(f\"Batch {i+1}/{num_batches} - PGD volume: {pgd_volume:.6f}, FGSM volume: {fgsm_volume:.6f}\")\n","\n","                    # Get predictions\n","                    pgd_pred = get_model_predictions(perturbed_images_pgd)\n","                    fgsm_pred = get_model_predictions(perturbed_images_fgsm)\n","\n","                    if pgd_pred is not None:\n","                        pgd_predictions.append(pgd_pred)\n","                    if fgsm_pred is not None:\n","                        fgsm_predictions.append(fgsm_pred)\n","\n","            except Exception as e:\n","                print(f\"Error processing batch {i}: {str(e)}\")\n","                continue\n","\n","            tf.keras.backend.clear_session()\n","\n","        if pgd_predictions and fgsm_predictions:\n","            pgd_predictions = np.vstack(pgd_predictions)\n","            fgsm_predictions = np.vstack(fgsm_predictions)\n","\n","            # Process for each threshold\n","            for threshold in thresholds:\n","                # Process PGD results\n","                pgd_result = implement_fi2010_strategy(\n","                    predictions=pgd_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if pgd_result:\n","                    pgd_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'PGD'\n","                    })\n","                    results_pgd.append(pgd_result)\n","\n","                # Process FGSM results\n","                fgsm_result = implement_fi2010_strategy(\n","                    predictions=fgsm_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if fgsm_result:\n","                    fgsm_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'FGSM'\n","                    })\n","                    results_fgsm.append(fgsm_result)\n","\n","    # Create DataFrames\n","    pgd_df = pd.DataFrame(results_pgd) if results_pgd else pd.DataFrame()\n","    fgsm_df = pd.DataFrame(results_fgsm) if results_fgsm else pd.DataFrame()\n","\n","    # Display detailed summaries\n","    if not pgd_df.empty:\n","        print(\"\\nPGD Attack Summary by Threshold:\")\n","        summary_pgd = pgd_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        # Format the display\n","        pd.set_option('display.float_format', lambda x: '%.4f' % x)\n","        print(\"\\nPGD Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_pgd.loc[eps])\n","\n","    if not fgsm_df.empty:\n","        print(\"\\nFGSM Attack Summary by Threshold:\")\n","        summary_fgsm = fgsm_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        print(\"\\nFGSM Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_fgsm.loc[eps])\n","\n","    return pgd_df, fgsm_df\n","\n","def implement_fi2010_strategy(predictions, dec_data, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"Implementation of the FI-2010 trading strategy\"\"\"\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","    trades_info = []\n","    budget = 100\n","\n","    for i in range(k, min_length):\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax(predictions[i])\n","        max_prob = np.max(predictions[i])\n","\n","        if max_prob > prob_threshold and pred_class != 1:\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","            shares = budget / mid_prices[i]\n","\n","            if pred_class == 2:  # Long trade\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'profit': profit,\n","                    'correct': actual_direction == 1\n","                })\n","            elif pred_class == 0:  # Short trade\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'profit': profit,\n","                    'correct': actual_direction == -1\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","epsilon_values = [0.000001, 0.00001, 0.0001, 0.001,0.01]\n","results_pgd, results_fgsm = run_adversarial_trading_analysis(\n","    model=model,\n","    testX_CNN=testX_CNN,\n","    testY_CNN=testY_CNN,\n","    dec_test=dec_test,\n","    epsilon_values=epsilon_values,\n","    batch_size=2000\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qc7XvKwP3hBY","executionInfo":{"status":"ok","timestamp":1741399748907,"user_tz":300,"elapsed":1935928,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"32d07e42-42c2-4d5c-d3e5-46c3ad0a78a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Analyzing epsilon: 1e-06\n","Batch 1/69 - PGD volume: 0.158479, FGSM volume: 0.000004\n","Batch 2/69 - PGD volume: 4.589767, FGSM volume: 0.000004\n","Batch 3/69 - PGD volume: 6.256168, FGSM volume: 0.000004\n","Batch 4/69 - PGD volume: 6.275187, FGSM volume: 0.000004\n","Batch 5/69 - PGD volume: 6.400707, FGSM volume: 0.000004\n","Batch 6/69 - PGD volume: 5.701828, FGSM volume: 0.000004\n","Batch 7/69 - PGD volume: 4.511963, FGSM volume: 0.000004\n","Batch 8/69 - PGD volume: 4.263456, FGSM volume: 0.000004\n","Batch 9/69 - PGD volume: 4.204227, FGSM volume: 0.000004\n","Batch 10/69 - PGD volume: 4.127592, FGSM volume: 0.000004\n","Batch 11/69 - PGD volume: 6.201607, FGSM volume: 0.000004\n","Batch 12/69 - PGD volume: 4.585088, FGSM volume: 0.000004\n","Batch 13/69 - PGD volume: 1.555242, FGSM volume: 0.000004\n","Batch 14/69 - PGD volume: 1.289547, FGSM volume: 0.000004\n","Batch 15/69 - PGD volume: 1.111892, FGSM volume: 0.000004\n","Batch 16/69 - PGD volume: 1.227548, FGSM volume: 0.000004\n","Batch 17/69 - PGD volume: 1.326563, FGSM volume: 0.000004\n","Batch 18/69 - PGD volume: 1.618934, FGSM volume: 0.000004\n","Batch 19/69 - PGD volume: 1.660652, FGSM volume: 0.000004\n","Batch 20/69 - PGD volume: 1.641510, FGSM volume: 0.000004\n","Batch 21/69 - PGD volume: 1.704530, FGSM volume: 0.000004\n","Batch 22/69 - PGD volume: 1.730240, FGSM volume: 0.000004\n","Batch 23/69 - PGD volume: 1.518139, FGSM volume: 0.000004\n","Batch 24/69 - PGD volume: 1.517826, FGSM volume: 0.000004\n","Batch 25/69 - PGD volume: 1.565952, FGSM volume: 0.000004\n","Batch 26/69 - PGD volume: 1.540854, FGSM volume: 0.000004\n","Batch 27/69 - PGD volume: 2.059161, FGSM volume: 0.000004\n","Batch 28/69 - PGD volume: 1.796127, FGSM volume: 0.000004\n","Batch 29/69 - PGD volume: 1.652585, FGSM volume: 0.000004\n","Batch 30/69 - PGD volume: 1.202885, FGSM volume: 0.000004\n","Batch 31/69 - PGD volume: 1.654390, FGSM volume: 0.000004\n","Batch 32/69 - PGD volume: 1.129870, FGSM volume: 0.000004\n","Batch 33/69 - PGD volume: 1.299871, FGSM volume: 0.000004\n","Batch 34/69 - PGD volume: 1.470572, FGSM volume: 0.000004\n","Batch 35/69 - PGD volume: 0.855560, FGSM volume: 0.000004\n","Batch 36/69 - PGD volume: 1.096536, FGSM volume: 0.000004\n","Batch 37/69 - PGD volume: 1.451876, FGSM volume: 0.000004\n","Batch 38/69 - PGD volume: 1.070373, FGSM volume: 0.000004\n","Batch 39/69 - PGD volume: 2.008557, FGSM volume: 0.000004\n","Batch 40/69 - PGD volume: 2.309820, FGSM volume: 0.000004\n","Batch 41/69 - PGD volume: 2.414186, FGSM volume: 0.000004\n","Batch 42/69 - PGD volume: 2.440820, FGSM volume: 0.000004\n","Batch 43/69 - PGD volume: 2.450301, FGSM volume: 0.000004\n","Batch 44/69 - PGD volume: 2.408777, FGSM volume: 0.000004\n","Batch 45/69 - PGD volume: 2.146757, FGSM volume: 0.000004\n","Batch 46/69 - PGD volume: 1.646788, FGSM volume: 0.000004\n","Batch 47/69 - PGD volume: 1.693528, FGSM volume: 0.000004\n","Batch 48/69 - PGD volume: 1.636278, FGSM volume: 0.000004\n","Batch 49/69 - PGD volume: 2.753690, FGSM volume: 0.000004\n","Batch 50/69 - PGD volume: 1.833186, FGSM volume: 0.000004\n","Batch 51/69 - PGD volume: 1.753896, FGSM volume: 0.000004\n","Batch 52/69 - PGD volume: 1.757358, FGSM volume: 0.000004\n","Batch 53/69 - PGD volume: 2.183680, FGSM volume: 0.000004\n","Batch 54/69 - PGD volume: 2.115732, FGSM volume: 0.000004\n","Batch 55/69 - PGD volume: 1.877949, FGSM volume: 0.000004\n","Batch 56/69 - PGD volume: 2.578567, FGSM volume: 0.000004\n","Batch 57/69 - PGD volume: 1.401828, FGSM volume: 0.000004\n","Batch 58/69 - PGD volume: 2.690939, FGSM volume: 0.000004\n","Batch 59/69 - PGD volume: 2.353763, FGSM volume: 0.000004\n","Batch 60/69 - PGD volume: 1.505185, FGSM volume: 0.000004\n","Batch 61/69 - PGD volume: 1.624503, FGSM volume: 0.000004\n","Batch 62/69 - PGD volume: 1.422899, FGSM volume: 0.000004\n","Batch 63/69 - PGD volume: 1.145115, FGSM volume: 0.000004\n","Batch 64/69 - PGD volume: 1.603539, FGSM volume: 0.000004\n","Batch 65/69 - PGD volume: 1.767290, FGSM volume: 0.000004\n","Batch 66/69 - PGD volume: 1.813725, FGSM volume: 0.000004\n","Batch 67/69 - PGD volume: 1.829396, FGSM volume: 0.000004\n","Batch 68/69 - PGD volume: 2.013160, FGSM volume: 0.000004\n","Batch 69/69 - PGD volume: 2.009771, FGSM volume: 0.000004\n","\n","Analyzing epsilon: 1e-05\n","Batch 1/69 - PGD volume: 0.158479, FGSM volume: 0.000045\n","Batch 2/69 - PGD volume: 4.589767, FGSM volume: 0.000045\n","Batch 3/69 - PGD volume: 6.256168, FGSM volume: 0.000045\n","Batch 4/69 - PGD volume: 6.275187, FGSM volume: 0.000045\n","Batch 5/69 - PGD volume: 6.400707, FGSM volume: 0.000045\n","Batch 6/69 - PGD volume: 5.701828, FGSM volume: 0.000045\n","Batch 7/69 - PGD volume: 4.511963, FGSM volume: 0.000045\n","Batch 8/69 - PGD volume: 4.263456, FGSM volume: 0.000045\n","Batch 9/69 - PGD volume: 4.204227, FGSM volume: 0.000045\n","Batch 10/69 - PGD volume: 4.127592, FGSM volume: 0.000045\n","Batch 11/69 - PGD volume: 6.201607, FGSM volume: 0.000045\n","Batch 12/69 - PGD volume: 4.585088, FGSM volume: 0.000045\n","Batch 13/69 - PGD volume: 1.555242, FGSM volume: 0.000045\n","Batch 14/69 - PGD volume: 1.289547, FGSM volume: 0.000045\n","Batch 15/69 - PGD volume: 1.111892, FGSM volume: 0.000045\n","Batch 16/69 - PGD volume: 1.227548, FGSM volume: 0.000045\n","Batch 17/69 - PGD volume: 1.326563, FGSM volume: 0.000045\n","Batch 18/69 - PGD volume: 1.618934, FGSM volume: 0.000045\n","Batch 19/69 - PGD volume: 1.660652, FGSM volume: 0.000045\n","Batch 20/69 - PGD volume: 1.641510, FGSM volume: 0.000045\n","Batch 21/69 - PGD volume: 1.704530, FGSM volume: 0.000045\n","Batch 22/69 - PGD volume: 1.730240, FGSM volume: 0.000045\n","Batch 23/69 - PGD volume: 1.518139, FGSM volume: 0.000045\n","Batch 24/69 - PGD volume: 1.517826, FGSM volume: 0.000045\n","Batch 25/69 - PGD volume: 1.565952, FGSM volume: 0.000045\n","Batch 26/69 - PGD volume: 1.540854, FGSM volume: 0.000045\n","Batch 27/69 - PGD volume: 2.059161, FGSM volume: 0.000045\n","Batch 28/69 - PGD volume: 1.796127, FGSM volume: 0.000045\n","Batch 29/69 - PGD volume: 1.652585, FGSM volume: 0.000045\n","Batch 30/69 - PGD volume: 1.202885, FGSM volume: 0.000045\n","Batch 31/69 - PGD volume: 1.654390, FGSM volume: 0.000045\n","Batch 32/69 - PGD volume: 1.129870, FGSM volume: 0.000045\n","Batch 33/69 - PGD volume: 1.299871, FGSM volume: 0.000045\n","Batch 34/69 - PGD volume: 1.470572, FGSM volume: 0.000045\n","Batch 35/69 - PGD volume: 0.855560, FGSM volume: 0.000045\n","Batch 36/69 - PGD volume: 1.096536, FGSM volume: 0.000045\n","Batch 37/69 - PGD volume: 1.451876, FGSM volume: 0.000045\n","Batch 38/69 - PGD volume: 1.070373, FGSM volume: 0.000045\n","Batch 39/69 - PGD volume: 2.008557, FGSM volume: 0.000045\n","Batch 40/69 - PGD volume: 2.309820, FGSM volume: 0.000045\n","Batch 41/69 - PGD volume: 2.414186, FGSM volume: 0.000045\n","Batch 42/69 - PGD volume: 2.440820, FGSM volume: 0.000045\n","Batch 43/69 - PGD volume: 2.450301, FGSM volume: 0.000045\n","Batch 44/69 - PGD volume: 2.408777, FGSM volume: 0.000045\n","Batch 45/69 - PGD volume: 2.146757, FGSM volume: 0.000045\n","Batch 46/69 - PGD volume: 1.646788, FGSM volume: 0.000045\n","Batch 47/69 - PGD volume: 1.693528, FGSM volume: 0.000045\n","Batch 48/69 - PGD volume: 1.636278, FGSM volume: 0.000045\n","Batch 49/69 - PGD volume: 2.753690, FGSM volume: 0.000045\n","Batch 50/69 - PGD volume: 1.833186, FGSM volume: 0.000045\n","Batch 51/69 - PGD volume: 1.753896, FGSM volume: 0.000045\n","Batch 52/69 - PGD volume: 1.757358, FGSM volume: 0.000045\n","Batch 53/69 - PGD volume: 2.183680, FGSM volume: 0.000045\n","Batch 54/69 - PGD volume: 2.115732, FGSM volume: 0.000045\n","Batch 55/69 - PGD volume: 1.877949, FGSM volume: 0.000045\n","Batch 56/69 - PGD volume: 2.578567, FGSM volume: 0.000045\n","Batch 57/69 - PGD volume: 1.401828, FGSM volume: 0.000045\n","Batch 58/69 - PGD volume: 2.690939, FGSM volume: 0.000045\n","Batch 59/69 - PGD volume: 2.353763, FGSM volume: 0.000045\n","Batch 60/69 - PGD volume: 1.505185, FGSM volume: 0.000045\n","Batch 61/69 - PGD volume: 1.624503, FGSM volume: 0.000045\n","Batch 62/69 - PGD volume: 1.422899, FGSM volume: 0.000045\n","Batch 63/69 - PGD volume: 1.145115, FGSM volume: 0.000045\n","Batch 64/69 - PGD volume: 1.603539, FGSM volume: 0.000045\n","Batch 65/69 - PGD volume: 1.767290, FGSM volume: 0.000045\n","Batch 66/69 - PGD volume: 1.813725, FGSM volume: 0.000045\n","Batch 67/69 - PGD volume: 1.829396, FGSM volume: 0.000045\n","Batch 68/69 - PGD volume: 2.013160, FGSM volume: 0.000045\n","Batch 69/69 - PGD volume: 2.009771, FGSM volume: 0.000045\n","\n","Analyzing epsilon: 0.0001\n","Batch 1/69 - PGD volume: 0.158479, FGSM volume: 0.000447\n","Batch 2/69 - PGD volume: 4.589767, FGSM volume: 0.000447\n","Batch 3/69 - PGD volume: 6.256168, FGSM volume: 0.000447\n","Batch 4/69 - PGD volume: 6.275187, FGSM volume: 0.000447\n","Batch 5/69 - PGD volume: 6.400707, FGSM volume: 0.000447\n","Batch 6/69 - PGD volume: 5.701828, FGSM volume: 0.000447\n","Batch 7/69 - PGD volume: 4.511963, FGSM volume: 0.000447\n","Batch 8/69 - PGD volume: 4.263456, FGSM volume: 0.000447\n","Batch 9/69 - PGD volume: 4.204227, FGSM volume: 0.000447\n","Batch 10/69 - PGD volume: 4.127592, FGSM volume: 0.000447\n","Batch 11/69 - PGD volume: 6.201607, FGSM volume: 0.000447\n","Batch 12/69 - PGD volume: 4.585088, FGSM volume: 0.000447\n","Batch 13/69 - PGD volume: 1.555242, FGSM volume: 0.000447\n","Batch 14/69 - PGD volume: 1.289547, FGSM volume: 0.000447\n","Batch 15/69 - PGD volume: 1.111892, FGSM volume: 0.000447\n","Batch 16/69 - PGD volume: 1.227548, FGSM volume: 0.000447\n","Batch 17/69 - PGD volume: 1.326563, FGSM volume: 0.000447\n","Batch 18/69 - PGD volume: 1.618934, FGSM volume: 0.000447\n","Batch 19/69 - PGD volume: 1.660652, FGSM volume: 0.000447\n","Batch 20/69 - PGD volume: 1.641510, FGSM volume: 0.000447\n","Batch 21/69 - PGD volume: 1.704530, FGSM volume: 0.000447\n","Batch 22/69 - PGD volume: 1.730240, FGSM volume: 0.000447\n","Batch 23/69 - PGD volume: 1.518139, FGSM volume: 0.000447\n","Batch 24/69 - PGD volume: 1.517826, FGSM volume: 0.000447\n","Batch 25/69 - PGD volume: 1.565952, FGSM volume: 0.000447\n","Batch 26/69 - PGD volume: 1.540854, FGSM volume: 0.000447\n","Batch 27/69 - PGD volume: 2.059161, FGSM volume: 0.000446\n","Batch 28/69 - PGD volume: 1.796127, FGSM volume: 0.000447\n","Batch 29/69 - PGD volume: 1.652585, FGSM volume: 0.000446\n","Batch 30/69 - PGD volume: 1.202885, FGSM volume: 0.000447\n","Batch 31/69 - PGD volume: 1.654390, FGSM volume: 0.000447\n","Batch 32/69 - PGD volume: 1.129870, FGSM volume: 0.000447\n","Batch 33/69 - PGD volume: 1.299871, FGSM volume: 0.000447\n","Batch 34/69 - PGD volume: 1.470572, FGSM volume: 0.000447\n","Batch 35/69 - PGD volume: 0.855560, FGSM volume: 0.000447\n","Batch 36/69 - PGD volume: 1.096536, FGSM volume: 0.000447\n","Batch 37/69 - PGD volume: 1.451876, FGSM volume: 0.000447\n","Batch 38/69 - PGD volume: 1.070373, FGSM volume: 0.000447\n","Batch 39/69 - PGD volume: 2.008557, FGSM volume: 0.000447\n","Batch 40/69 - PGD volume: 2.309820, FGSM volume: 0.000447\n","Batch 41/69 - PGD volume: 2.414186, FGSM volume: 0.000447\n","Batch 42/69 - PGD volume: 2.440820, FGSM volume: 0.000447\n","Batch 43/69 - PGD volume: 2.450301, FGSM volume: 0.000446\n","Batch 44/69 - PGD volume: 2.408777, FGSM volume: 0.000447\n","Batch 45/69 - PGD volume: 2.146757, FGSM volume: 0.000447\n","Batch 46/69 - PGD volume: 1.646788, FGSM volume: 0.000447\n","Batch 47/69 - PGD volume: 1.693528, FGSM volume: 0.000447\n","Batch 48/69 - PGD volume: 1.636278, FGSM volume: 0.000447\n","Batch 49/69 - PGD volume: 2.753690, FGSM volume: 0.000447\n","Batch 50/69 - PGD volume: 1.833186, FGSM volume: 0.000447\n","Batch 51/69 - PGD volume: 1.753896, FGSM volume: 0.000447\n","Batch 52/69 - PGD volume: 1.757358, FGSM volume: 0.000447\n","Batch 53/69 - PGD volume: 2.183680, FGSM volume: 0.000447\n","Batch 54/69 - PGD volume: 2.115732, FGSM volume: 0.000447\n","Batch 55/69 - PGD volume: 1.877949, FGSM volume: 0.000447\n","Batch 56/69 - PGD volume: 2.578567, FGSM volume: 0.000447\n","Batch 57/69 - PGD volume: 1.401828, FGSM volume: 0.000447\n","Batch 58/69 - PGD volume: 2.690939, FGSM volume: 0.000447\n","Batch 59/69 - PGD volume: 2.353763, FGSM volume: 0.000447\n","Batch 60/69 - PGD volume: 1.505185, FGSM volume: 0.000447\n","Batch 61/69 - PGD volume: 1.624503, FGSM volume: 0.000447\n","Batch 62/69 - PGD volume: 1.422899, FGSM volume: 0.000447\n","Batch 63/69 - PGD volume: 1.145115, FGSM volume: 0.000447\n","Batch 64/69 - PGD volume: 1.603539, FGSM volume: 0.000447\n","Batch 65/69 - PGD volume: 1.767290, FGSM volume: 0.000447\n","Batch 66/69 - PGD volume: 1.813725, FGSM volume: 0.000447\n","Batch 67/69 - PGD volume: 1.829396, FGSM volume: 0.000447\n","Batch 68/69 - PGD volume: 2.013160, FGSM volume: 0.000447\n","Batch 69/69 - PGD volume: 2.009771, FGSM volume: 0.000447\n","\n","Analyzing epsilon: 0.001\n","Batch 1/69 - PGD volume: 0.158479, FGSM volume: 0.004382\n","Batch 2/69 - PGD volume: 4.589767, FGSM volume: 0.004448\n","Batch 3/69 - PGD volume: 6.256168, FGSM volume: 0.004466\n","Batch 4/69 - PGD volume: 6.275187, FGSM volume: 0.004464\n","Batch 5/69 - PGD volume: 6.400707, FGSM volume: 0.004470\n","Batch 6/69 - PGD volume: 5.701828, FGSM volume: 0.004470\n","Batch 7/69 - PGD volume: 4.511963, FGSM volume: 0.004467\n","Batch 8/69 - PGD volume: 4.263456, FGSM volume: 0.004467\n","Batch 9/69 - PGD volume: 4.204227, FGSM volume: 0.004470\n","Batch 10/69 - PGD volume: 4.127592, FGSM volume: 0.004470\n","Batch 11/69 - PGD volume: 6.201607, FGSM volume: 0.004467\n","Batch 12/69 - PGD volume: 4.585088, FGSM volume: 0.004465\n","Batch 13/69 - PGD volume: 1.555242, FGSM volume: 0.004467\n","Batch 14/69 - PGD volume: 1.289547, FGSM volume: 0.004466\n","Batch 15/69 - PGD volume: 1.111892, FGSM volume: 0.004467\n","Batch 16/69 - PGD volume: 1.227548, FGSM volume: 0.004468\n","Batch 17/69 - PGD volume: 1.326563, FGSM volume: 0.004457\n","Batch 18/69 - PGD volume: 1.618934, FGSM volume: 0.004460\n","Batch 19/69 - PGD volume: 1.660652, FGSM volume: 0.004467\n","Batch 20/69 - PGD volume: 1.641510, FGSM volume: 0.004468\n","Batch 21/69 - PGD volume: 1.704530, FGSM volume: 0.004456\n","Batch 22/69 - PGD volume: 1.730240, FGSM volume: 0.004435\n","Batch 23/69 - PGD volume: 1.518139, FGSM volume: 0.004456\n","Batch 24/69 - PGD volume: 1.517826, FGSM volume: 0.004449\n","Batch 25/69 - PGD volume: 1.565952, FGSM volume: 0.004437\n","Batch 26/69 - PGD volume: 1.540854, FGSM volume: 0.004459\n","Batch 27/69 - PGD volume: 2.059161, FGSM volume: 0.004448\n","Batch 28/69 - PGD volume: 1.796127, FGSM volume: 0.004427\n","Batch 29/69 - PGD volume: 1.652585, FGSM volume: 0.004407\n","Batch 30/69 - PGD volume: 1.202885, FGSM volume: 0.004469\n","Batch 31/69 - PGD volume: 1.654390, FGSM volume: 0.004467\n","Batch 32/69 - PGD volume: 1.129870, FGSM volume: 0.004469\n","Batch 33/69 - PGD volume: 1.299871, FGSM volume: 0.004469\n","Batch 34/69 - PGD volume: 1.470572, FGSM volume: 0.004470\n","Batch 35/69 - PGD volume: 0.855560, FGSM volume: 0.004467\n","Batch 36/69 - PGD volume: 1.096536, FGSM volume: 0.004453\n","Batch 37/69 - PGD volume: 1.451876, FGSM volume: 0.004456\n","Batch 38/69 - PGD volume: 1.070373, FGSM volume: 0.004468\n","Batch 39/69 - PGD volume: 2.008557, FGSM volume: 0.004468\n","Batch 40/69 - PGD volume: 2.309820, FGSM volume: 0.004468\n","Batch 41/69 - PGD volume: 2.414186, FGSM volume: 0.004468\n","Batch 42/69 - PGD volume: 2.440820, FGSM volume: 0.004466\n","Batch 43/69 - PGD volume: 2.450301, FGSM volume: 0.004456\n","Batch 44/69 - PGD volume: 2.408777, FGSM volume: 0.004463\n","Batch 45/69 - PGD volume: 2.146757, FGSM volume: 0.004446\n","Batch 46/69 - PGD volume: 1.646788, FGSM volume: 0.004453\n","Batch 47/69 - PGD volume: 1.693528, FGSM volume: 0.004450\n","Batch 48/69 - PGD volume: 1.636278, FGSM volume: 0.004432\n","Batch 49/69 - PGD volume: 2.753690, FGSM volume: 0.004437\n","Batch 50/69 - PGD volume: 1.833186, FGSM volume: 0.004420\n","Batch 51/69 - PGD volume: 1.753896, FGSM volume: 0.004454\n","Batch 52/69 - PGD volume: 1.757358, FGSM volume: 0.004446\n","Batch 53/69 - PGD volume: 2.183680, FGSM volume: 0.004458\n","Batch 54/69 - PGD volume: 2.115732, FGSM volume: 0.004453\n","Batch 55/69 - PGD volume: 1.877949, FGSM volume: 0.004399\n","Batch 56/69 - PGD volume: 2.578567, FGSM volume: 0.004469\n","Batch 57/69 - PGD volume: 1.401828, FGSM volume: 0.004469\n","Batch 58/69 - PGD volume: 2.690939, FGSM volume: 0.004470\n","Batch 59/69 - PGD volume: 2.353763, FGSM volume: 0.004470\n","Batch 60/69 - PGD volume: 1.505185, FGSM volume: 0.004471\n","Batch 61/69 - PGD volume: 1.624503, FGSM volume: 0.004467\n","Batch 62/69 - PGD volume: 1.422899, FGSM volume: 0.004466\n","Batch 63/69 - PGD volume: 1.145115, FGSM volume: 0.004462\n","Batch 64/69 - PGD volume: 1.603539, FGSM volume: 0.004455\n","Batch 65/69 - PGD volume: 1.767290, FGSM volume: 0.004453\n","Batch 66/69 - PGD volume: 1.813725, FGSM volume: 0.004462\n","Batch 67/69 - PGD volume: 1.829396, FGSM volume: 0.004454\n","Batch 68/69 - PGD volume: 2.013160, FGSM volume: 0.004448\n","Batch 69/69 - PGD volume: 2.009771, FGSM volume: 0.004444\n","\n","Analyzing epsilon: 0.01\n","Batch 1/69 - PGD volume: 0.158495, FGSM volume: 0.036118\n","Batch 2/69 - PGD volume: 4.589768, FGSM volume: 0.040937\n","Batch 3/69 - PGD volume: 6.256168, FGSM volume: 0.043050\n","Batch 4/69 - PGD volume: 6.275187, FGSM volume: 0.043081\n","Batch 5/69 - PGD volume: 6.400707, FGSM volume: 0.043379\n","Batch 6/69 - PGD volume: 5.701828, FGSM volume: 0.043502\n","Batch 7/69 - PGD volume: 4.511963, FGSM volume: 0.043834\n","Batch 8/69 - PGD volume: 4.263456, FGSM volume: 0.043815\n","Batch 9/69 - PGD volume: 4.204227, FGSM volume: 0.043782\n","Batch 10/69 - PGD volume: 4.127592, FGSM volume: 0.044061\n","Batch 11/69 - PGD volume: 6.201607, FGSM volume: 0.043028\n","Batch 12/69 - PGD volume: 4.585088, FGSM volume: 0.043264\n","Batch 13/69 - PGD volume: 1.555242, FGSM volume: 0.043053\n","Batch 14/69 - PGD volume: 1.289547, FGSM volume: 0.043423\n","Batch 15/69 - PGD volume: 1.111892, FGSM volume: 0.043365\n","Batch 16/69 - PGD volume: 1.227548, FGSM volume: 0.043932\n","Batch 17/69 - PGD volume: 1.326563, FGSM volume: 0.040395\n","Batch 18/69 - PGD volume: 1.618934, FGSM volume: 0.036010\n","Batch 19/69 - PGD volume: 1.660652, FGSM volume: 0.036112\n","Batch 20/69 - PGD volume: 1.641510, FGSM volume: 0.035866\n","Batch 21/69 - PGD volume: 1.704530, FGSM volume: 0.036814\n","Batch 22/69 - PGD volume: 1.730240, FGSM volume: 0.036303\n","Batch 23/69 - PGD volume: 1.518139, FGSM volume: 0.035693\n","Batch 24/69 - PGD volume: 1.517826, FGSM volume: 0.037928\n","Batch 25/69 - PGD volume: 1.565952, FGSM volume: 0.037550\n","Batch 26/69 - PGD volume: 1.540854, FGSM volume: 0.037866\n","Batch 27/69 - PGD volume: 2.059161, FGSM volume: 0.036800\n","Batch 28/69 - PGD volume: 1.796127, FGSM volume: 0.035652\n","Batch 29/69 - PGD volume: 1.652585, FGSM volume: 0.038583\n","Batch 30/69 - PGD volume: 1.202885, FGSM volume: 0.043421\n","Batch 31/69 - PGD volume: 1.654390, FGSM volume: 0.042599\n","Batch 32/69 - PGD volume: 1.129870, FGSM volume: 0.043155\n","Batch 33/69 - PGD volume: 1.299871, FGSM volume: 0.042484\n","Batch 34/69 - PGD volume: 1.470572, FGSM volume: 0.043947\n","Batch 35/69 - PGD volume: 0.855560, FGSM volume: 0.044090\n","Batch 36/69 - PGD volume: 1.096536, FGSM volume: 0.043833\n","Batch 37/69 - PGD volume: 1.451876, FGSM volume: 0.043566\n","Batch 38/69 - PGD volume: 1.070373, FGSM volume: 0.043847\n","Batch 39/69 - PGD volume: 2.008557, FGSM volume: 0.043537\n","Batch 40/69 - PGD volume: 2.309820, FGSM volume: 0.043243\n","Batch 41/69 - PGD volume: 2.414186, FGSM volume: 0.043831\n","Batch 42/69 - PGD volume: 2.440820, FGSM volume: 0.043480\n","Batch 43/69 - PGD volume: 2.450301, FGSM volume: 0.043387\n","Batch 44/69 - PGD volume: 2.408777, FGSM volume: 0.043470\n","Batch 45/69 - PGD volume: 2.146757, FGSM volume: 0.040933\n","Batch 46/69 - PGD volume: 1.646788, FGSM volume: 0.035926\n","Batch 47/69 - PGD volume: 1.693528, FGSM volume: 0.036150\n","Batch 48/69 - PGD volume: 1.636278, FGSM volume: 0.036545\n","Batch 49/69 - PGD volume: 2.753690, FGSM volume: 0.035500\n","Batch 50/69 - PGD volume: 1.833186, FGSM volume: 0.036119\n","Batch 51/69 - PGD volume: 1.753896, FGSM volume: 0.036425\n","Batch 52/69 - PGD volume: 1.757358, FGSM volume: 0.036629\n","Batch 53/69 - PGD volume: 2.183680, FGSM volume: 0.035942\n","Batch 54/69 - PGD volume: 2.115732, FGSM volume: 0.036432\n","Batch 55/69 - PGD volume: 1.877949, FGSM volume: 0.038164\n","Batch 56/69 - PGD volume: 2.578567, FGSM volume: 0.043559\n","Batch 57/69 - PGD volume: 1.401829, FGSM volume: 0.043511\n","Batch 58/69 - PGD volume: 2.690939, FGSM volume: 0.043775\n","Batch 59/69 - PGD volume: 2.353763, FGSM volume: 0.044087\n","Batch 60/69 - PGD volume: 1.505186, FGSM volume: 0.044143\n","Batch 61/69 - PGD volume: 1.624503, FGSM volume: 0.043442\n","Batch 62/69 - PGD volume: 1.422899, FGSM volume: 0.043402\n","Batch 63/69 - PGD volume: 1.145115, FGSM volume: 0.043696\n","Batch 64/69 - PGD volume: 1.603539, FGSM volume: 0.036760\n","Batch 65/69 - PGD volume: 1.767290, FGSM volume: 0.036934\n","Batch 66/69 - PGD volume: 1.813725, FGSM volume: 0.036571\n","Batch 67/69 - PGD volume: 1.829396, FGSM volume: 0.036487\n","Batch 68/69 - PGD volume: 2.013160, FGSM volume: 0.036178\n","Batch 69/69 - PGD volume: 2.009771, FGSM volume: 0.036402\n","\n","PGD Attack Summary by Threshold:\n","\n","PGD Analysis Results:\n","\n","Epsilon: 1e-06\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         -29.9984  48054.0000    0.4474\n","0.9000           1.4028  38694.0000    0.4600\n","0.9500          42.6307  26080.0000    0.5023\n","0.9900          42.3472   8477.0000    0.4955\n","\n","Epsilon: 1e-05\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         -29.9984  48054.0000    0.4474\n","0.9000           1.4028  38694.0000    0.4600\n","0.9500          42.6307  26080.0000    0.5023\n","0.9900          42.3472   8477.0000    0.4955\n","\n","Epsilon: 0.0001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         -29.9984  48054.0000    0.4474\n","0.9000           1.3751  38695.0000    0.4600\n","0.9500          42.6307  26081.0000    0.5023\n","0.9900          42.3472   8477.0000    0.4955\n","\n","Epsilon: 0.001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         -29.8905  48051.0000    0.4474\n","0.9000           1.3518  38693.0000    0.4600\n","0.9500          42.7207  26081.0000    0.5023\n","0.9900          42.3472   8473.0000    0.4957\n","\n","Epsilon: 0.01\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         -29.0035  48038.0000    0.4476\n","0.9000           1.2735  38669.0000    0.4603\n","0.9500          42.6637  26074.0000    0.4986\n","0.9900          42.2227   8470.0000    0.4959\n","\n","FGSM Attack Summary by Threshold:\n","\n","FGSM Analysis Results:\n","\n","Epsilon: 1e-06\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         678.0260  41777.0000    0.5051\n","0.9000         381.3380  34119.0000    0.5041\n","0.9500         260.6095  23960.0000    0.4800\n","0.9900         174.8406   9377.0000    0.4692\n","\n","Epsilon: 1e-05\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         678.1895  41750.0000    0.5054\n","0.9000         381.3784  34101.0000    0.5044\n","0.9500         260.5789  23941.0000    0.4803\n","0.9900         174.8863   9366.0000    0.4698\n","\n","Epsilon: 0.0001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         678.6517  41569.0000    0.5076\n","0.9000         381.8548  33883.0000    0.5076\n","0.9500         260.5290  23780.0000    0.4752\n","0.9900         174.7945   9285.0000    0.4739\n","\n","Epsilon: 0.001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         482.4010  40280.0000    0.4916\n","0.9000         368.9758  32373.0000    0.4912\n","0.9500         144.5080  22548.0000    0.4612\n","0.9900         186.1728   8554.0000    0.4910\n","\n","Epsilon: 0.01\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         573.7998  49392.0000    0.3989\n","0.9000          83.2108  36764.0000    0.3917\n","0.9500         -33.3680  22248.0000    0.4450\n","0.9900         185.2926   7381.0000    0.4877\n"]}]},{"cell_type":"code","source":["# \"\"\"TRADING STRATEGY AFTER ATTACK ON 1 EPSILON VALUES\"\"\"\n","# import numpy as np\n","# import pandas as pd\n","# import tensorflow as tf\n","\n","# def run_adversarial_trading_analysis(model, testX_CNN, testY_CNN, dec_test, epsilon_values, batch_size=2000):\n","#     \"\"\"Run trading strategy analysis with adversarial attacks\"\"\"\n","#     results_pgd = []\n","#     results_fgsm = []\n","#     thresholds = [0.85, 0.90, 0.95, 0.99]  # Explicit thresholds\n","\n","#     def data_set(testX_CNN, start_idx, end_idx):\n","#         \"\"\"Prepare the dataset by shifting\"\"\"\n","#         shifted_testX_CNN = tf.concat([\n","#             testX_CNN[start_idx:end_idx, 1:100, :, :],\n","#             testX_CNN[start_idx:end_idx, 99:, :, :]\n","#         ], axis=1)\n","#         return tf.cast(shifted_testX_CNN, tf.float32)\n","\n","#     def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","#         \"\"\"Apply volume constraints to the images\"\"\"\n","#         images = images.numpy()\n","#         slices = [slice(None)] * images.ndim\n","#         testX_CNN_batch = testX_CNN[start_idx:end_idx]\n","#         for idx in range(images.shape[dimension]):\n","#             slices[dimension] = idx\n","#             images[tuple(slices)] = np.maximum(\n","#                 images[tuple(slices)],\n","#                 testX_CNN_batch[tuple(slices)]\n","#             )\n","#         return tf.convert_to_tensor(images, dtype=tf.float32)\n","\n","#     def get_model_predictions(perturbed_images):\n","#         \"\"\"Get model predictions with error handling\"\"\"\n","#         try:\n","#             with tf.device('/CPU:0'):\n","#                 predictions = model(perturbed_images, training=False)\n","#                 return predictions.numpy()\n","#         except Exception as e:\n","#             print(f\"Error in model prediction: {str(e)}\")\n","#             return None\n","\n","#     def fgsm_attack(images, labels, epsilon):\n","#         \"\"\"Implement FGSM attack\"\"\"\n","#         try:\n","#             with tf.GradientTape() as tape:\n","#                 tape.watch(images)\n","#                 predictions = model(images, training=False)\n","#                 loss = tf.keras.losses.CategoricalCrossentropy()(labels, predictions)\n","\n","#             gradient = tape.gradient(loss, images)\n","#             signed_grad = tf.sign(gradient)\n","\n","#             signed_masked = signed_grad.numpy()\n","#             signed_masked[:, :99, :, :] = 0\n","#             signed_masked[:, 99:, ::2, :] = 0\n","#             signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","#             perturbed_images = images + epsilon * signed_masked\n","#             return tf.clip_by_value(perturbed_images, 0, 1)\n","#         except Exception as e:\n","#             print(f\"Error in FGSM attack: {str(e)}\")\n","#             return None\n","\n","#     def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","#       perturbed_images = tf.identity(images)\n","\n","#       for _ in range(num_iterations):\n","#           # Gradient step\n","#           with tf.GradientTape() as tape:\n","#               tape.watch(perturbed_images)\n","#               predictions = model(perturbed_images)\n","#               loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","#           gradient = tape.gradient(loss, perturbed_images)\n","#           signed_grad = tf.sign(gradient)\n","\n","#           # Apply masking to gradient\n","#           signed_masked = signed_grad.numpy()\n","#           signed_masked[:, :99, :, :] = 0\n","#           signed_masked[:, 99:, ::2, :] = 0\n","#           signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","#           # Apply gradient step\n","#           perturbed_images = perturbed_images + step_size * signed_masked\n","\n","#           # Step 1: Apply volume constraint\n","#           perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","#           # Step 2: Apply L2 norm constraint (projection step)\n","#           delta = perturbed_images - images  # Calculate current perturbation\n","\n","#           # Reshape to flatten all dimensions except batch\n","#           delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","#           # Calculate L2 norm on the flattened dimensions\n","#           norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","#           # Reshape norm for broadcasting\n","#           norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","#           # Scale perturbation\n","#           scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","#           delta = delta * scaling\n","\n","#           perturbed_images = images + delta  # Apply constrained perturbation\n","\n","#           # Step 3: Apply clipping to valid range [0,1]\n","#           perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","#           # Step 4: Re-apply volume constraint after all other constraints\n","#           # This ensures volume constraint takes precedence if there's a conflict\n","#           perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","#       return perturbed_images\n","\n","#     max_test_size = testX_CNN.shape[0]\n","#     num_batches = max_test_size // batch_size\n","\n","#     for epsilon in epsilon_values:\n","#         print(f\"\\nAnalyzing epsilon: {epsilon}\")\n","\n","#         pgd_predictions = []\n","#         fgsm_predictions = []\n","\n","#         for i in range(num_batches):\n","#             start_idx = i * batch_size\n","#             end_idx = min((i + 1) * batch_size, max_test_size)\n","\n","#             try:\n","#                 # Prepare batch data\n","#                 batch_images = data_set(testX_CNN, start_idx, end_idx)\n","#                 batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","#                 batch_labels = testY_CNN[start_idx:end_idx]\n","\n","#                 # Generate adversarial examples\n","#                 perturbed_images_pgd = pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx)\n","#                 perturbed_images_fgsm = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","#                 if perturbed_images_pgd is not None and perturbed_images_fgsm is not None:\n","#                     # Calculate perturbation volumes\n","#                     pgd_volume = np.mean(np.linalg.norm(\n","#                         (perturbed_images_pgd - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","#                         axis=1\n","#                     ))\n","#                     fgsm_volume = np.mean(np.linalg.norm(\n","#                         (perturbed_images_fgsm - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","#                         axis=1\n","#                     ))\n","#                     print(f\"Batch {i+1}/{num_batches} - PGD volume: {pgd_volume:.6f}, FGSM volume: {fgsm_volume:.6f}\")\n","\n","#                     # Get predictions\n","#                     pgd_pred = get_model_predictions(perturbed_images_pgd)\n","#                     fgsm_pred = get_model_predictions(perturbed_images_fgsm)\n","\n","#                     if pgd_pred is not None:\n","#                         pgd_predictions.append(pgd_pred)\n","#                     if fgsm_pred is not None:\n","#                         fgsm_predictions.append(fgsm_pred)\n","\n","#             except Exception as e:\n","#                 print(f\"Error processing batch {i}: {str(e)}\")\n","#                 continue\n","\n","#             tf.keras.backend.clear_session()\n","\n","#         if pgd_predictions and fgsm_predictions:\n","#             pgd_predictions = np.vstack(pgd_predictions)\n","#             fgsm_predictions = np.vstack(fgsm_predictions)\n","\n","#             # Process for each threshold\n","#             for threshold in thresholds:\n","#                 # Process PGD results\n","#                 pgd_result = implement_fi2010_strategy(\n","#                     predictions=pgd_predictions,\n","#                     dec_data=dec_test,\n","#                     prob_threshold=threshold\n","#                 )\n","#                 if pgd_result:\n","#                     pgd_result.update({\n","#                         'epsilon': epsilon,\n","#                         'threshold': threshold,\n","#                         'attack_type': 'PGD'\n","#                     })\n","#                     results_pgd.append(pgd_result)\n","\n","#                 # Process FGSM results\n","#                 fgsm_result = implement_fi2010_strategy(\n","#                     predictions=fgsm_predictions,\n","#                     dec_data=dec_test,\n","#                     prob_threshold=threshold\n","#                 )\n","#                 if fgsm_result:\n","#                     fgsm_result.update({\n","#                         'epsilon': epsilon,\n","#                         'threshold': threshold,\n","#                         'attack_type': 'FGSM'\n","#                     })\n","#                     results_fgsm.append(fgsm_result)\n","\n","#     # Create DataFrames\n","#     pgd_df = pd.DataFrame(results_pgd) if results_pgd else pd.DataFrame()\n","#     fgsm_df = pd.DataFrame(results_fgsm) if results_fgsm else pd.DataFrame()\n","\n","#     # Display detailed summaries\n","#     if not pgd_df.empty:\n","#         print(\"\\nPGD Attack Summary by Threshold:\")\n","#         summary_pgd = pgd_df.groupby(['epsilon', 'threshold'])[\n","#             ['total_profit', 'num_trades', 'win_rate']\n","#         ].mean().round(4)\n","\n","#         # Format the display\n","#         pd.set_option('display.float_format', lambda x: '%.4f' % x)\n","#         print(\"\\nPGD Analysis Results:\")\n","#         for eps in epsilon_values:\n","#             print(f\"\\nEpsilon: {eps}\")\n","#             print(summary_pgd.loc[eps])\n","\n","#     if not fgsm_df.empty:\n","#         print(\"\\nFGSM Attack Summary by Threshold:\")\n","#         summary_fgsm = fgsm_df.groupby(['epsilon', 'threshold'])[\n","#             ['total_profit', 'num_trades', 'win_rate']\n","#         ].mean().round(4)\n","\n","#         print(\"\\nFGSM Analysis Results:\")\n","#         for eps in epsilon_values:\n","#             print(f\"\\nEpsilon: {eps}\")\n","#             print(summary_fgsm.loc[eps])\n","\n","#     return pgd_df, fgsm_df\n","\n","# def implement_fi2010_strategy(predictions, dec_data, prob_threshold=0.5, k=4, alpha=0.001):\n","#     \"\"\"Implementation of the FI-2010 trading strategy\"\"\"\n","#     ask_prices = dec_data[0, :]\n","#     bid_prices = dec_data[2, :]\n","#     mid_prices = (ask_prices + bid_prices) / 2\n","\n","#     min_length = min(len(predictions), len(mid_prices) - k)\n","#     predictions = predictions[:min_length]\n","#     trades_info = []\n","#     budget = 100\n","\n","#     for i in range(k, min_length):\n","#         m_plus = np.mean(mid_prices[i+1:i+k+1])\n","#         lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","#         pred_class = np.argmax(predictions[i])\n","#         max_prob = np.max(predictions[i])\n","\n","#         if max_prob > prob_threshold and pred_class != 1:\n","#             actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","#             shares = budget / mid_prices[i]\n","\n","#             if pred_class == 2:  # Long trade\n","#                 cost = shares * mid_prices[i]\n","#                 proceeds = shares * m_plus\n","#                 profit = proceeds - cost\n","#                 trades_info.append({\n","#                     'movement': 'up',\n","#                     'profit': profit,\n","#                     'correct': actual_direction == 1\n","#                 })\n","#             elif pred_class == 0:  # Short trade\n","#                 proceeds = shares * mid_prices[i]\n","#                 cost = shares * m_plus\n","#                 profit = proceeds - cost\n","#                 trades_info.append({\n","#                     'movement': 'down',\n","#                     'profit': profit,\n","#                     'correct': actual_direction == -1\n","#                 })\n","\n","#     if trades_info:\n","#         trades_df = pd.DataFrame(trades_info)\n","#         return {\n","#             'threshold': prob_threshold,\n","#             'total_profit': trades_df['profit'].sum(),\n","#             'num_trades': len(trades_df),\n","#             'win_rate': trades_df['correct'].mean() * 100,\n","#             'avg_profit': trades_df['profit'].mean(),\n","#             'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","#             'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","#         }\n","#     return None\n","\n","# epsilon_values = [0.01]\n","# results_pgd, results_fgsm = run_adversarial_trading_analysis(\n","#     model=model,\n","#     testX_CNN=testX_CNN,\n","#     testY_CNN=testY_CNN,\n","#     dec_test=dec_test,\n","#     epsilon_values=epsilon_values,\n","#     batch_size=2000\n","# )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9g2rwIeLaXF","executionInfo":{"status":"ok","timestamp":1741396874116,"user_tz":300,"elapsed":20822,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"28ed10a5-20d8-47ce-a404-cda4f9c24791"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Analyzing epsilon: 0.01\n","Error processing batch 0: name 'images' is not defined\n","Error processing batch 1: name 'images' is not defined\n","Error processing batch 2: name 'images' is not defined\n","Error processing batch 3: name 'images' is not defined\n","Error processing batch 4: name 'images' is not defined\n","Error processing batch 5: name 'images' is not defined\n","Error processing batch 6: name 'images' is not defined\n","Error processing batch 7: name 'images' is not defined\n","Error processing batch 8: name 'images' is not defined\n","Error processing batch 9: name 'images' is not defined\n","Error processing batch 10: name 'images' is not defined\n","Error processing batch 11: name 'images' is not defined\n","Error processing batch 12: name 'images' is not defined\n","Error processing batch 13: name 'images' is not defined\n","Error processing batch 14: name 'images' is not defined\n","Error processing batch 15: name 'images' is not defined\n","Error processing batch 16: name 'images' is not defined\n","Error processing batch 17: name 'images' is not defined\n","Error processing batch 18: name 'images' is not defined\n","Error processing batch 19: name 'images' is not defined\n","Error processing batch 20: name 'images' is not defined\n","Error processing batch 21: name 'images' is not defined\n","Error processing batch 22: name 'images' is not defined\n","Error processing batch 23: name 'images' is not defined\n","Error processing batch 24: name 'images' is not defined\n","Error processing batch 25: name 'images' is not defined\n","Error processing batch 26: name 'images' is not defined\n","Error processing batch 27: name 'images' is not defined\n","Error processing batch 28: name 'images' is not defined\n","Error processing batch 29: name 'images' is not defined\n","Error processing batch 30: name 'images' is not defined\n","Error processing batch 31: name 'images' is not defined\n","Error processing batch 32: name 'images' is not defined\n","Error processing batch 33: name 'images' is not defined\n","Error processing batch 34: name 'images' is not defined\n","Error processing batch 35: name 'images' is not defined\n","Error processing batch 36: name 'images' is not defined\n","Error processing batch 37: name 'images' is not defined\n","Error processing batch 38: name 'images' is not defined\n","Error processing batch 39: name 'images' is not defined\n","Error processing batch 40: name 'images' is not defined\n","Error processing batch 41: name 'images' is not defined\n","Error processing batch 42: name 'images' is not defined\n","Error processing batch 43: name 'images' is not defined\n","Error processing batch 44: name 'images' is not defined\n","Error processing batch 45: name 'images' is not defined\n","Error processing batch 46: name 'images' is not defined\n","Error processing batch 47: name 'images' is not defined\n","Error processing batch 48: name 'images' is not defined\n","Error processing batch 49: name 'images' is not defined\n","Error processing batch 50: name 'images' is not defined\n","Error processing batch 51: name 'images' is not defined\n","Error processing batch 52: name 'images' is not defined\n","Error processing batch 53: name 'images' is not defined\n","Error processing batch 54: name 'images' is not defined\n","Error processing batch 55: name 'images' is not defined\n","Error processing batch 56: name 'images' is not defined\n","Error processing batch 57: name 'images' is not defined\n","Error processing batch 58: name 'images' is not defined\n","Error processing batch 59: name 'images' is not defined\n","Error processing batch 60: name 'images' is not defined\n","Error processing batch 61: name 'images' is not defined\n","Error processing batch 62: name 'images' is not defined\n","Error processing batch 63: name 'images' is not defined\n","Error processing batch 64: name 'images' is not defined\n","Error processing batch 65: name 'images' is not defined\n","Error processing batch 66: name 'images' is not defined\n","Error processing batch 67: name 'images' is not defined\n","Error processing batch 68: name 'images' is not defined\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2KZocKXi6EZe"},"execution_count":null,"outputs":[]}]}