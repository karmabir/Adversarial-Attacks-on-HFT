{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOz3Y2ZLexpagiG+XmTQ/Ns"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gs4343FD9TCs"},"outputs":[],"source":["import pandas as pd\n","import pickle\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","from keras import backend as K\n","from keras.models import load_model, Model\n","from keras.layers import Flatten, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.layers import LeakyReLU\n","#!pip install np_utils\n","from keras import utils\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# set random seeds\n","\n","# removed the import statement for set_session from tensorflow.compat.v1.keras.backend\n","np.random.seed(1)\n","tf.random.set_seed(2)"]},{"cell_type":"markdown","source":["## Mounting Google Drive"],"metadata":{"id":"0AAYumooZhIs"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQxFEZ_T9jgN","executionInfo":{"status":"ok","timestamp":1741400763093,"user_tz":300,"elapsed":18603,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"cdc33d3a-2210-4477-8c06-b4a29e40b6a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Importing Dataset"],"metadata":{"id":"hyDAb2_YZrLf"}},{"cell_type":"code","source":["import os\n","if not os.path.isfile('/content/drive/MyDrive/LOBCNN/data/data.zip'):\n","    !wget https://raw.githubusercontent.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/master/data/data.zip\n","    !unzip -n data.zip\n","    print('data downloaded.')\n","else:\n","    print('data already existed.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4TMutLy9lRr","executionInfo":{"status":"ok","timestamp":1741400763398,"user_tz":300,"elapsed":304,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"af32f319-76d5-40a8-879b-2edf06edb132"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data already existed.\n"]}]},{"cell_type":"markdown","source":["# Functions for pre-processing:\n"],"metadata":{"id":"6W0-mM9haw5p"}},{"cell_type":"code","source":["def prepare_x(data):\n","    df1 = data[:40, :].T\n","    return np.array(df1)\n","\n","def get_label(data):\n","    lob = data[-5:, :].T\n","    return lob\n","\n","def data_classification(X, Y, T):\n","    [N, D] = X.shape\n","    df = np.array(X)\n","    dY = np.array(Y)\n","    dataY = dY[T - 1:N]\n","    dataX = np.zeros((N - T + 1, T, D))\n","    for i in range(T, N + 1):\n","        dataX[i - T] = df[i - T:i, :]\n","    return dataX.reshape(dataX.shape + (1,)), dataY\n","\n","def prepare_x_y(data, k, T):\n","    x = prepare_x(data)\n","    y = get_label(data)\n","    x, y = data_classification(x, y, T=T)\n","    y = y[:,k] - 1\n","    y = utils.to_categorical(y, 3)\n","    return x, y"],"metadata":{"id":"5I6jYZck9rIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dec_data = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Train_Dst_NoAuction_DecPre_CF_7.txt')\n","dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n","dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n","\n","dec_test1 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_7.txt')\n","dec_test2 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_8.txt')\n","dec_test3 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_9.txt')\n","dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n","\n","k = 4 # which prediction horizon\n","T = 100 # the length of a single input\n","n_hiddens = 64\n","checkpoint_filepath = './model_tensorflow1_weights'\n","\n","trainX_CNN, trainY_CNN = prepare_x_y(dec_train, k, T)\n","valX_CNN, valY_CNN = prepare_x_y(dec_val, k, T)\n","testX_CNN, testY_CNN = prepare_x_y(dec_test, k, T)\n","\n","print(trainX_CNN.shape, trainY_CNN.shape)\n","print(valX_CNN.shape, valY_CNN.shape)\n","print(testX_CNN.shape, testY_CNN.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATO3-Jjt9tIL","executionInfo":{"status":"ok","timestamp":1741400789818,"user_tz":300,"elapsed":26203,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"96e43ff5-0b44-453a-8886-73860869c51d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(203701, 100, 40, 1) (203701, 3)\n","(50851, 100, 40, 1) (50851, 3)\n","(139488, 100, 40, 1) (139488, 3)\n"]}]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"FQ2thb30luaY"}},{"cell_type":"code","source":["\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense, Dropout, Reshape\n","\n","def create_lstm1(T, NF, number_of_lstm):\n","    input_lmd = Input(shape=(T, NF))\n","\n","    # build the LSTM layers\n","    lstm_layer = LSTM(number_of_lstm, return_sequences=True)(input_lmd)\n","    lstm_layer = LSTM(number_of_lstm, return_sequences=True)(lstm_layer)\n","\n","    # reshape for compatibility with dense layer\n","    lstm_reshape = Reshape((T * number_of_lstm,))(lstm_layer)\n","    lstm_reshape = Dropout(0.2)(lstm_reshape, training=True)\n","\n","    # build the output layer\n","    out = Dense(3, activation='softmax')(lstm_reshape)\n","\n","    model = Model(inputs=input_lmd, outputs=out)\n","    adam = keras.optimizers.Adam(learning_rate=0.0001)\n","    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Assuming trainX_CNN.shape[1] is T, trainX_CNN.shape[2] is NF, and n_hiddens is the number of LSTM units\n","lstm1 = create_lstm1(trainX_CNN.shape[1], trainX_CNN.shape[2], n_hiddens)\n","lstm1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"ZSKUAG2L9vD6","executionInfo":{"status":"ok","timestamp":1741400792160,"user_tz":300,"elapsed":1448,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"40480073-f203-460f-d173-9be386768363"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m26,880\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m33,024\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │          \u001b[38;5;34m19,203\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">26,880</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,203</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,107\u001b[0m (309.01 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,107</span> (309.01 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,107\u001b[0m (309.01 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,107</span> (309.01 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["%%time\n","lstm1.fit(trainX_CNN, trainY_CNN, validation_data=(valX_CNN, valY_CNN),epochs=50, batch_size=128, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ba-7l0kj913r","executionInfo":{"status":"ok","timestamp":1741401747393,"user_tz":300,"elapsed":955232,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"39f02cd9-4b06-4603-957e-ae470ca1df01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4216 - loss: 1.0352 - val_accuracy: 0.3700 - val_loss: 1.0920\n","Epoch 2/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4646 - loss: 1.0147 - val_accuracy: 0.3935 - val_loss: 1.0836\n","Epoch 3/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4848 - loss: 1.0042 - val_accuracy: 0.4071 - val_loss: 1.0799\n","Epoch 4/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4965 - loss: 0.9966 - val_accuracy: 0.4133 - val_loss: 1.0774\n","Epoch 5/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5068 - loss: 0.9874 - val_accuracy: 0.4182 - val_loss: 1.0750\n","Epoch 6/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5177 - loss: 0.9741 - val_accuracy: 0.4206 - val_loss: 1.0737\n","Epoch 7/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5285 - loss: 0.9605 - val_accuracy: 0.4271 - val_loss: 1.0701\n","Epoch 8/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5357 - loss: 0.9505 - val_accuracy: 0.4290 - val_loss: 1.0698\n","Epoch 9/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5403 - loss: 0.9431 - val_accuracy: 0.4335 - val_loss: 1.0667\n","Epoch 10/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5458 - loss: 0.9362 - val_accuracy: 0.4352 - val_loss: 1.0675\n","Epoch 11/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5517 - loss: 0.9298 - val_accuracy: 0.4387 - val_loss: 1.0648\n","Epoch 12/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5568 - loss: 0.9232 - val_accuracy: 0.4401 - val_loss: 1.0639\n","Epoch 13/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5609 - loss: 0.9170 - val_accuracy: 0.4411 - val_loss: 1.0628\n","Epoch 14/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5649 - loss: 0.9114 - val_accuracy: 0.4421 - val_loss: 1.0622\n","Epoch 15/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5692 - loss: 0.9046 - val_accuracy: 0.4402 - val_loss: 1.0614\n","Epoch 16/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5728 - loss: 0.8987 - val_accuracy: 0.4453 - val_loss: 1.0585\n","Epoch 17/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5785 - loss: 0.8927 - val_accuracy: 0.4481 - val_loss: 1.0591\n","Epoch 18/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5817 - loss: 0.8874 - val_accuracy: 0.4458 - val_loss: 1.0585\n","Epoch 19/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5864 - loss: 0.8820 - val_accuracy: 0.4522 - val_loss: 1.0542\n","Epoch 20/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5912 - loss: 0.8777 - val_accuracy: 0.4543 - val_loss: 1.0550\n","Epoch 21/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5944 - loss: 0.8718 - val_accuracy: 0.4559 - val_loss: 1.0550\n","Epoch 22/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5976 - loss: 0.8666 - val_accuracy: 0.4591 - val_loss: 1.0520\n","Epoch 23/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6015 - loss: 0.8620 - val_accuracy: 0.4572 - val_loss: 1.0501\n","Epoch 24/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6037 - loss: 0.8574 - val_accuracy: 0.4572 - val_loss: 1.0518\n","Epoch 25/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6080 - loss: 0.8518 - val_accuracy: 0.4628 - val_loss: 1.0474\n","Epoch 26/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6095 - loss: 0.8476 - val_accuracy: 0.4624 - val_loss: 1.0494\n","Epoch 27/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6141 - loss: 0.8430 - val_accuracy: 0.4644 - val_loss: 1.0494\n","Epoch 28/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6174 - loss: 0.8379 - val_accuracy: 0.4663 - val_loss: 1.0465\n","Epoch 29/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6186 - loss: 0.8343 - val_accuracy: 0.4671 - val_loss: 1.0456\n","Epoch 30/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6228 - loss: 0.8289 - val_accuracy: 0.4651 - val_loss: 1.0485\n","Epoch 31/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6254 - loss: 0.8243 - val_accuracy: 0.4674 - val_loss: 1.0477\n","Epoch 32/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6282 - loss: 0.8202 - val_accuracy: 0.4684 - val_loss: 1.0423\n","Epoch 33/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6312 - loss: 0.8159 - val_accuracy: 0.4683 - val_loss: 1.0443\n","Epoch 34/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6338 - loss: 0.8113 - val_accuracy: 0.4671 - val_loss: 1.0450\n","Epoch 35/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6342 - loss: 0.8077 - val_accuracy: 0.4666 - val_loss: 1.0436\n","Epoch 36/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6378 - loss: 0.8031 - val_accuracy: 0.4677 - val_loss: 1.0457\n","Epoch 37/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6389 - loss: 0.8004 - val_accuracy: 0.4640 - val_loss: 1.0537\n","Epoch 38/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6407 - loss: 0.7959 - val_accuracy: 0.4677 - val_loss: 1.0476\n","Epoch 39/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6445 - loss: 0.7919 - val_accuracy: 0.4583 - val_loss: 1.0639\n","Epoch 40/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6478 - loss: 0.7873 - val_accuracy: 0.4628 - val_loss: 1.0572\n","Epoch 41/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6494 - loss: 0.7839 - val_accuracy: 0.4609 - val_loss: 1.0596\n","Epoch 42/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6510 - loss: 0.7797 - val_accuracy: 0.4640 - val_loss: 1.0578\n","Epoch 43/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6544 - loss: 0.7763 - val_accuracy: 0.4655 - val_loss: 1.0586\n","Epoch 44/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6561 - loss: 0.7730 - val_accuracy: 0.4653 - val_loss: 1.0546\n","Epoch 45/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6585 - loss: 0.7696 - val_accuracy: 0.4587 - val_loss: 1.0629\n","Epoch 46/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6599 - loss: 0.7660 - val_accuracy: 0.4590 - val_loss: 1.0654\n","Epoch 47/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6618 - loss: 0.7635 - val_accuracy: 0.4660 - val_loss: 1.0558\n","Epoch 48/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6650 - loss: 0.7590 - val_accuracy: 0.4623 - val_loss: 1.0619\n","Epoch 49/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6652 - loss: 0.7554 - val_accuracy: 0.4695 - val_loss: 1.0489\n","Epoch 50/50\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6683 - loss: 0.7533 - val_accuracy: 0.4674 - val_loss: 1.0516\n","CPU times: user 19min 1s, sys: 59.5 s, total: 20min\n","Wall time: 15min 55s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7b9469b8dd50>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["print(accuracy_score(np.argmax(testY_CNN, axis=1), np.argmax(lstm1.predict(testX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YeR0lH39-Oi","executionInfo":{"status":"ok","timestamp":1741056075609,"user_tz":300,"elapsed":21576,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"b9b86a3a-cddd-4dd4-b086-60cb2db9abe7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n","0.486264051387933\n"]}]},{"cell_type":"code","source":["print(classification_report(np.argmax(testY_CNN, axis=1), np.argmax(lstm1.predict(testX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uAqQgUdBxHp","executionInfo":{"status":"ok","timestamp":1741056096102,"user_tz":300,"elapsed":20466,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"00c0a604-0ecf-489b-db80-54cd2446995a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.64      0.54     47915\n","           1       0.52      0.28      0.36     48050\n","           2       0.50      0.55      0.52     43523\n","\n","    accuracy                           0.49    139488\n","   macro avg       0.49      0.49      0.47    139488\n","weighted avg       0.49      0.49      0.47    139488\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve, auc\n","\n","# Get predicted probabilities for the positive class\n","y_pred_proba = lstm1.predict(testX_CNN)[:, 1]\n","\n","# Calculate precision and recall\n","precision, recall, thresholds = precision_recall_curve(testY_CNN[:, 1], y_pred_proba)\n","\n","# Calculate area under the curve\n","auc_score = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label=f'AUC = {auc_score:.2f}')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"xPbq30tiBzqI","executionInfo":{"status":"ok","timestamp":1741056117071,"user_tz":300,"elapsed":20964,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"527c909b-3c4f-4aad-d987-988b0516bcea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["print(accuracy_score(np.argmax(trainY_CNN, axis=1), np.argmax(lstm1.predict(trainX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OrCFr84jB1uQ","executionInfo":{"status":"ok","timestamp":1741056182237,"user_tz":300,"elapsed":31609,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"12d38a4a-3080-473c-f30d-bebfb4c1ba6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step\n","0.672794929823614\n"]}]},{"cell_type":"code","source":["print(classification_report(np.argmax(trainY_CNN, axis=1), np.argmax(lstm1.predict(trainX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqVCOaiRCItA","executionInfo":{"status":"ok","timestamp":1741056212597,"user_tz":300,"elapsed":30096,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"c926c2be-6297-407f-fb9b-5e35488600fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.78      0.71     84426\n","           1       0.70      0.37      0.49     36210\n","           2       0.70      0.69      0.70     83065\n","\n","    accuracy                           0.67    203701\n","   macro avg       0.68      0.62      0.63    203701\n","weighted avg       0.68      0.67      0.66    203701\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve, auc\n","\n","# Get predicted probabilities for the positive class\n","y_pred_proba = lstm1.predict(trainX_CNN)[:, 1]\n","\n","# Calculate precision and recall\n","precision, recall, thresholds = precision_recall_curve(trainY_CNN[:, 1], y_pred_proba)\n","\n","# Calculate area under the curve\n","auc_score = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label=f'AUC = {auc_score:.2f}')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"yLy98QJsCPMG","executionInfo":{"status":"ok","timestamp":1741056243439,"user_tz":300,"elapsed":30573,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"797774e0-e940-42be-f6b8-8c3733ef8669"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["\"\"\" TRADING STRATEGY BEFORE ATTACK ON TEST DATA\"\"\"\n","import numpy as np\n","import pandas as pd\n","\n","print(\"Getting predictions...\")\n","train_predictions = lstm1.predict(testX_CNN)\n","\n","# First define our strategy function\n","def implement_fi2010_strategy(predictions, dec_data, budget=100, prob_threshold=0.8, k=4, alpha=0.002):\n","    # Get average ask and bid prices\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","\n","    trades_info = []\n","\n","    for i in range(k, min_length):\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","        max_prob = np.max([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","\n","        if max_prob > prob_threshold and pred_class != 1:\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","\n","\n","            if pred_class == 2:\n","                shares = budget / mid_prices[i]\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 2],\n","                    'correct': actual_direction == 1,\n","                    'index': i\n","                })\n","            elif pred_class == 0:\n","                shares = budget / mid_prices[i]\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 0],\n","                    'correct': actual_direction == -1,\n","                    'index': i\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","\n","        print(\"\\nTrading Performance:\")\n","        print(f\"Total trades: {len(trades_df)}\")\n","        print(f\"Win rate: {(trades_df['correct'].mean() * 100):.2f}%\")\n","        print(f\"Total profit: ${trades_df['profit'].sum():.2f}\")\n","        print(f\"Average profit per trade: ${trades_df['profit'].mean():.4f}\")\n","\n","        print(\"\\nDirection Analysis:\")\n","        for direction in ['up', 'down']:\n","            mask = trades_df['movement'] == direction\n","            if mask.any():\n","                direction_df = trades_df[mask]\n","                print(f\"\\n{direction.upper()} trades:\")\n","                print(f\"Count: {len(direction_df)}\")\n","                print(f\"Win rate: {(direction_df['correct'].mean() * 100):.2f}%\")\n","                print(f\"Total profit: ${direction_df['profit'].sum():.2f}\")\n","                print(f\"Average profit: ${direction_df['profit'].mean():.4f}\")\n","\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","# Test different probability thresholds\n","thresholds = [0.8, 0.85, 0.9, 0.95, 0.99]\n","results = []\n","\n","print(\"Testing strategy with different thresholds...\")\n","for threshold in thresholds:\n","    print(f\"\\nTesting threshold: {threshold}\")\n","    result = implement_fi2010_strategy(\n","        predictions=train_predictions,\n","        dec_data=dec_test,\n","        prob_threshold=threshold,\n","        k=4,\n","        alpha=0.001\n","    )\n","    if result:\n","        results.append(result)\n","\n","# Create summary table\n","if results:\n","    results_df = pd.DataFrame(results)\n","    print(\"\\nSummary of results for different probability thresholds:\")\n","    pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))\n","    print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jsqpKbEdCVRQ","executionInfo":{"status":"ok","timestamp":1741056283277,"user_tz":300,"elapsed":38744,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"997cbcca-00f1-4332-a6ce-7e85a2bb72ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting predictions...\n","\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n","Testing strategy with different thresholds...\n","\n","Testing threshold: 0.8\n","\n","Trading Performance:\n","Total trades: 19317\n","Win rate: 0.59%\n","Total profit: $341.65\n","Average profit per trade: $0.0177\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 9514\n","Win rate: 0.62%\n","Total profit: $151.84\n","Average profit: $0.0160\n","\n","DOWN trades:\n","Count: 9803\n","Win rate: 0.56%\n","Total profit: $189.81\n","Average profit: $0.0194\n","\n","Testing threshold: 0.85\n","\n","Trading Performance:\n","Total trades: 14235\n","Win rate: 0.65%\n","Total profit: $340.69\n","Average profit per trade: $0.0239\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 7095\n","Win rate: 0.73%\n","Total profit: $163.49\n","Average profit: $0.0230\n","\n","DOWN trades:\n","Count: 7140\n","Win rate: 0.57%\n","Total profit: $177.20\n","Average profit: $0.0248\n","\n","Testing threshold: 0.9\n","\n","Trading Performance:\n","Total trades: 9586\n","Win rate: 0.65%\n","Total profit: $259.27\n","Average profit per trade: $0.0270\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 4850\n","Win rate: 0.74%\n","Total profit: $128.50\n","Average profit: $0.0265\n","\n","DOWN trades:\n","Count: 4736\n","Win rate: 0.55%\n","Total profit: $130.77\n","Average profit: $0.0276\n","\n","Testing threshold: 0.95\n","\n","Trading Performance:\n","Total trades: 5111\n","Win rate: 0.63%\n","Total profit: $131.86\n","Average profit per trade: $0.0258\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 2542\n","Win rate: 0.63%\n","Total profit: $-0.86\n","Average profit: $-0.0003\n","\n","DOWN trades:\n","Count: 2569\n","Win rate: 0.62%\n","Total profit: $132.72\n","Average profit: $0.0517\n","\n","Testing threshold: 0.99\n","\n","Trading Performance:\n","Total trades: 1263\n","Win rate: 0.71%\n","Total profit: $27.71\n","Average profit per trade: $0.0219\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 589\n","Win rate: 0.68%\n","Total profit: $0.70\n","Average profit: $0.0012\n","\n","DOWN trades:\n","Count: 674\n","Win rate: 0.74%\n","Total profit: $27.01\n","Average profit: $0.0401\n","\n","Summary of results for different probability thresholds:\n","   threshold  total_profit  num_trades  win_rate  avg_profit  long_trades  \\\n","0   0.800000    341.647641       19317  0.590154    0.017686         9514   \n","1   0.850000    340.689714       14235  0.653319    0.023933         7095   \n","2   0.900000    259.271362        9586  0.646777    0.027047         4850   \n","3   0.950000    131.857777        5111  0.626101    0.025799         2542   \n","4   0.990000     27.712635        1263  0.712589    0.021942          589   \n","\n","   short_trades  \n","0          9803  \n","1          7140  \n","2          4736  \n","3          2569  \n","4           674  \n"]}]},{"cell_type":"code","source":["\"\"\" TRADING STRATEGY BEFORE ATTACK ON TRAIN DATA\"\"\"\n","import numpy as np\n","import pandas as pd\n","\n","print(\"Getting predictions...\")\n","train_predictions = lstm1.predict(trainX_CNN)\n","\n","# First define our strategy function\n","def implement_fi2010_strategy(predictions, dec_data, budget=100, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"\n","    Implements trading strategy using the FI-2010 paper's methodology\n","\n","    Args:\n","        predictions: numpy array of model predictions (n_samples, 3)\n","        dec_data: numpy array of decoded price data\n","        budget: amount to invest per trade\n","        prob_threshold: probability threshold for trading\n","        k: prediction horizon (number of steps to look ahead)\n","        alpha: threshold for determining price movement direction\n","    \"\"\"\n","    # Get normalized ask and bid prices\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","\n","    trades_info = []\n","\n","    for i in range(k, min_length):\n","        # Calculate m+ (future average) according to paper\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","\n","        # Calculate actual price movement using paper's method\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","        max_prob = np.max([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","\n","        if max_prob > prob_threshold and pred_class != 1:  # not stable\n","            # Determine actual direction using same threshold as training\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","\n","            # Long trade (UP prediction)\n","            if pred_class == 2:\n","                shares = budget / mid_prices[i]\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 2],\n","                    'correct': actual_direction == 1,\n","                    'index': i\n","                })\n","\n","            # Short trade (DOWN prediction)\n","            elif pred_class == 0:\n","                shares = budget / mid_prices[i]\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 0],\n","                    'correct': actual_direction == -1,\n","                    'index': i\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","\n","        # Print performance metrics\n","        print(\"\\nTrading Performance:\")\n","        print(f\"Total trades: {len(trades_df)}\")\n","        print(f\"Win rate: {(trades_df['correct'].mean() * 100):.2f}%\")\n","        print(f\"Total profit: ${trades_df['profit'].sum():.2f}\")\n","        print(f\"Average profit per trade: ${trades_df['profit'].mean():.4f}\")\n","\n","        print(\"\\nDirection Analysis:\")\n","        for direction in ['up', 'down']:\n","            mask = trades_df['movement'] == direction\n","            if mask.any():\n","                direction_df = trades_df[mask]\n","                print(f\"\\n{direction.upper()} trades:\")\n","                print(f\"Count: {len(direction_df)}\")\n","                print(f\"Win rate: {(direction_df['correct'].mean() * 100):.2f}%\")\n","                print(f\"Total profit: ${direction_df['profit'].sum():.2f}\")\n","                print(f\"Average profit: ${direction_df['profit'].mean():.4f}\")\n","\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","# Test different probability thresholds\n","thresholds = [0.8, 0.85, 0.9, 0.95, 0.99]\n","results = []\n","\n","print(\"Testing strategy with different thresholds...\")\n","for threshold in thresholds:\n","    print(f\"\\nTesting threshold: {threshold}\")\n","    result = implement_fi2010_strategy(\n","        predictions=train_predictions,\n","        dec_data=dec_train,\n","        prob_threshold=threshold,\n","        k=4,\n","        alpha=0.001\n","    )\n","    if result:\n","        results.append(result)\n","\n","# Create summary table\n","if results:\n","    results_df = pd.DataFrame(results)\n","    print(\"\\nSummary of results for different probability thresholds:\")\n","    pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))\n","    print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqGgwNUhCfnv","executionInfo":{"status":"ok","timestamp":1741056395034,"user_tz":300,"elapsed":56282,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"570570c8-ff70-41b8-9c7a-5b62c23e31d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting predictions...\n","\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step\n","Testing strategy with different thresholds...\n","\n","Testing threshold: 0.8\n","\n","Trading Performance:\n","Total trades: 47827\n","Win rate: 0.66%\n","Total profit: $75.34\n","Average profit per trade: $0.0016\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 23666\n","Win rate: 0.65%\n","Total profit: $22.74\n","Average profit: $0.0010\n","\n","DOWN trades:\n","Count: 24161\n","Win rate: 0.67%\n","Total profit: $52.60\n","Average profit: $0.0022\n","\n","Testing threshold: 0.85\n","\n","Trading Performance:\n","Total trades: 37397\n","Win rate: 0.64%\n","Total profit: $64.47\n","Average profit per trade: $0.0017\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 18616\n","Win rate: 0.66%\n","Total profit: $18.65\n","Average profit: $0.0010\n","\n","DOWN trades:\n","Count: 18781\n","Win rate: 0.63%\n","Total profit: $45.82\n","Average profit: $0.0024\n","\n","Testing threshold: 0.9\n","\n","Trading Performance:\n","Total trades: 26630\n","Win rate: 0.64%\n","Total profit: $46.60\n","Average profit per trade: $0.0017\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 13282\n","Win rate: 0.62%\n","Total profit: $10.05\n","Average profit: $0.0008\n","\n","DOWN trades:\n","Count: 13348\n","Win rate: 0.66%\n","Total profit: $36.55\n","Average profit: $0.0027\n","\n","Testing threshold: 0.95\n","\n","Trading Performance:\n","Total trades: 15187\n","Win rate: 0.64%\n","Total profit: $22.14\n","Average profit per trade: $0.0015\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 7491\n","Win rate: 0.63%\n","Total profit: $4.33\n","Average profit: $0.0006\n","\n","DOWN trades:\n","Count: 7696\n","Win rate: 0.65%\n","Total profit: $17.80\n","Average profit: $0.0023\n","\n","Testing threshold: 0.99\n","\n","Trading Performance:\n","Total trades: 4121\n","Win rate: 0.49%\n","Total profit: $5.80\n","Average profit per trade: $0.0014\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 2044\n","Win rate: 0.68%\n","Total profit: $0.14\n","Average profit: $0.0001\n","\n","DOWN trades:\n","Count: 2077\n","Win rate: 0.29%\n","Total profit: $5.65\n","Average profit: $0.0027\n","\n","Summary of results for different probability thresholds:\n","   threshold  total_profit  num_trades  win_rate  avg_profit  long_trades  \\\n","0   0.800000     75.343934       47827  0.660715    0.001575        23666   \n","1   0.850000     64.466451       37397  0.644437    0.001724        18616   \n","2   0.900000     46.598310       26630  0.642133    0.001750        13282   \n","3   0.950000     22.136859       15187  0.638704    0.001458         7491   \n","4   0.990000      5.798045        4121  0.485319    0.001407         2044   \n","\n","   short_trades  \n","0         24161  \n","1         18781  \n","2         13348  \n","3          7696  \n","4          2077  \n"]}]},{"cell_type":"code","source":["def calculate_perturbation_volume(original, perturbed):\n","    original_flat = original.reshape(original.shape[0], -1)\n","    perturbed_flat = perturbed.reshape(perturbed.shape[0], -1)\n","    perturbation = np.linalg.norm(original_flat - perturbed_flat, ord=2, axis=1)\n","    avg_perturbation = np.mean(perturbation)\n","    return avg_perturbation"],"metadata":{"id":"oZwkc3jJK-Gn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" ADVERSARIAL ATTACK ON TEST DATA ON 4 EPSILON VALUES\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import precision_score, recall_score, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Define constants\n","max_test_size = testX_CNN.shape[0]\n","batch_size = 2000\n","num_batches = max_test_size // batch_size\n","epsilon_values = [0.000001, 0.00001, 0.0001, 0.001]\n","num_iterations = 5\n","step_size = 0.01\n","\n","# Define your model\n","model = lstm1\n","\n","avg_accuracies1 = {}\n","avg_accuracies2 = {}\n","perturbed_volumes1 = {}\n","perturbed_volumes2 = {}\n","# Define dictionaries to hold precision and recall\n","avg_precision1 = {}\n","avg_recall1 = {}\n","avg_precision2 = {}\n","avg_recall2 = {}\n","# Define dictionaries to hold ROC AUC scores\n","avg_roc_auc1 = {}\n","avg_roc_auc2 = {}\n","\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","def data_set(testX_CNN, start_idx, end_idx):\n","    shifted_testX_CNN = tf.concat([testX_CNN[start_idx:end_idx, 1:100, :, :], testX_CNN[start_idx:end_idx, 99:, :, :]], axis=1)\n","    return shifted_testX_CNN\n","\n","def fgsm_attack(images, labels, epsilon):\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        predictions = model(images)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","    gradient = tape.gradient(loss, images)\n","    signed_grad = tf.sign(gradient)\n","\n","    signed_masked = signed_grad.numpy()\n","    signed_masked[:, :99, :, :] = 0\n","    signed_masked[:, 99:, ::2, :] = 0\n","    signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","    perturbed_images = images + epsilon * signed_masked\n","    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","    return perturbed_images\n","\"\"\"\n","with tf.GradientTape() as tape: automatically tracks operations for gradient calculation\n","tape.watch(images): Explicitly tells the gradient tape to watch the images tensor for gradient calculation\n","loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions):\n","Calculates the loss between the true labels and the model's predictions\n","Uses categorical cross-entropy loss because this is a classification problem\n","from_logits=False indicates that the predictions are already probabilities (softmax has been applied)\n","gradient = tape.gradient(loss, images)\n","Calculates the gradient of the loss with respect to the input images\n","This tells us how to change the input to maximize the loss (i.e., make the model more likely to misclassify)\n","signed_grad = tf.sign(gradient)\n","Applies the sign function to the gradient to get the direction of the gradient\n","signed_masked[:, :99, :, :] = 0:\n","Sets the gradients for the first 99 time steps to zero\n","This ensures we only perturb the last time step (t=99), which is what the model primarily bases its prediction on\n","Within the last time step (t=99), this sets gradients for every other feature to zero\n","The ::2 slice is accessing only even indices, which likely correspond to price data in the LOB\n","This ensures we only perturb volume data and not price data, making the attack more realistic\n","signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32):\n","Converts the masked gradient signs back to a TensorFlow tensor for further operations\n","perturbed_images = images + epsilon * signed_masked:\n","Creates adversarial examples by adding the perturbation to the original images\n","The perturbation is the sign of the gradient scaled by epsilon\n","perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","Clips the perturbed values to ensure they stay within valid range [0,1]\n","\"\"\"\n","def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","    perturbed_images = tf.identity(images)\n","\n","    for _ in range(num_iterations):\n","        # Gradient step\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","        gradient = tape.gradient(loss, perturbed_images)\n","        signed_grad = tf.sign(gradient)\n","\n","        # Apply masking to gradient\n","        signed_masked = signed_grad.numpy()\n","        signed_masked[:, :99, :, :] = 0\n","        signed_masked[:, 99:, ::2, :] = 0\n","        signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","        # Apply gradient step\n","        perturbed_images = perturbed_images + step_size * signed_masked\n","\n","        # Step 3: Apply clipping to valid range [0,1]\n","        perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","        # This ensures volume constraint takes precedence if there's a conflict\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","    return perturbed_images\n","\n","\n","def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","    images = images.numpy()\n","    slices = [slice(None)] * images.ndim\n","    testX_CNN = testX_CNN[start_idx:end_idx]\n","    for idx in range(images.shape[dimension]):\n","        slices[dimension] = idx\n","        images[tuple(slices)] = np.maximum(images[tuple(slices)], testX_CNN[tuple(slices)])\n","    images = tf.convert_to_tensor(images, dtype=tf.float32)\n","    return images\n","\n","def plot_roc_curve(y_true, y_score1, y_score2, epsilon):\n","    \"\"\"\n","    Plot ROC curve for both attacks at a specific epsilon value\n","    \"\"\"\n","    # Get number of classes\n","    n_classes = y_score1.shape[1]\n","\n","    # Compute ROC curve and ROC area for each class for PGD\n","    fpr1 = dict()\n","    tpr1 = dict()\n","    roc_auc1 = dict()\n","    for i in range(n_classes):\n","        fpr1[i], tpr1[i], _ = roc_curve(y_true[:, i], y_score1[:, i])\n","        roc_auc1[i] = auc(fpr1[i], tpr1[i])\n","\n","    # Compute ROC curve and ROC area for each class for FGSM\n","    fpr2 = dict()\n","    tpr2 = dict()\n","    roc_auc2 = dict()\n","    for i in range(n_classes):\n","        fpr2[i], tpr2[i], _ = roc_curve(y_true[:, i], y_score2[:, i])\n","        roc_auc2[i] = auc(fpr2[i], tpr2[i])\n","\n","    # Calculate macro average ROC curve and ROC area\n","    all_fpr1 = np.unique(np.concatenate([fpr1[i] for i in range(n_classes)]))\n","    all_fpr2 = np.unique(np.concatenate([fpr2[i] for i in range(n_classes)]))\n","\n","    mean_tpr1 = np.zeros_like(all_fpr1)\n","    mean_tpr2 = np.zeros_like(all_fpr2)\n","    for i in range(n_classes):\n","        mean_tpr1 += np.interp(all_fpr1, fpr1[i], tpr1[i])\n","        mean_tpr2 += np.interp(all_fpr2, fpr2[i], tpr2[i])\n","\n","    mean_tpr1 /= n_classes\n","    mean_tpr2 /= n_classes\n","\n","    macro_roc_auc1 = auc(all_fpr1, mean_tpr1)\n","    macro_roc_auc2 = auc(all_fpr2, mean_tpr2)\n","\n","    # Plot ROC curve only as per the requirement\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(all_fpr1, mean_tpr1, label=f'PGD Attack - Macro-average ROC (AUC = {macro_roc_auc1:.2f})',\n","             color='blue', linestyle='solid', linewidth=2)\n","    plt.plot(all_fpr2, mean_tpr2, label=f'FGSM Attack - Macro-average ROC (AUC = {macro_roc_auc2:.2f})',\n","             color='red', linestyle='dashed', linewidth=2)\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for PGD and FGSM Attacks with ε = {epsilon}')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the figure\n","    plt.savefig(f'roc_curve_epsilon_{epsilon}.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    return macro_roc_auc1, macro_roc_auc2\n","\n","# Lists to store all prediction probabilities and true labels for ROC curves\n","all_true_labels_onehot = []\n","all_pred_probs_pgd = []\n","all_pred_probs_fgsm = []\n","\n","for epsilon in epsilon_values:\n","    print(f\"Epsilon value: {epsilon}\")\n","    total_accuracy1 = 0.0\n","    total_accuracy2 = 0.0\n","    total_perturbation1 = 0.0\n","    total_perturbation2 = 0.0\n","    all_true_labels = []\n","    all_predicted_labels1 = []\n","    all_predicted_labels2 = []\n","\n","    # For this epsilon, collect all prediction probabilities\n","    epsilon_true_labels_onehot = []\n","    epsilon_pred_probs_pgd = []\n","    epsilon_pred_probs_fgsm = []\n","\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = (i + 1) * batch_size\n","\n","        batch_images = data_set(testX_CNN, start_idx, end_idx)\n","        batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","        batch_labels = testY_CNN[start_idx:end_idx]\n","\n","        perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","        perturbed_images2 = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","        perturbation1 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images1.numpy())\n","        perturbation2 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images2.numpy())\n","\n","        total_perturbation1 += perturbation1\n","        total_perturbation2 += perturbation2\n","\n","        X_perturbed1 = perturbed_images1.numpy()\n","        X_perturbed2 = perturbed_images2.numpy()\n","\n","        # Get raw probabilities for ROC curve\n","        adversarial_probs1 = model.predict(X_perturbed1)\n","        adversarial_probs2 = model.predict(X_perturbed2)\n","\n","        # Get predicted labels\n","        adversarial_predictions1 = np.argmax(adversarial_probs1, axis=1)\n","        adversarial_predictions2 = np.argmax(adversarial_probs2, axis=1)\n","\n","        # Collect data for ROC curve\n","        epsilon_true_labels_onehot.append(batch_labels)\n","        epsilon_pred_probs_pgd.append(adversarial_probs1)\n","        epsilon_pred_probs_fgsm.append(adversarial_probs2)\n","\n","        # Append results for precision and recall calculation\n","        true_labels_batch = np.argmax(batch_labels, axis=1)\n","        all_true_labels.extend(true_labels_batch)\n","        all_predicted_labels1.extend(adversarial_predictions1)\n","        all_predicted_labels2.extend(adversarial_predictions2)\n","\n","        accuracy1 = accuracy_score(true_labels_batch, adversarial_predictions1)\n","        accuracy2 = accuracy_score(true_labels_batch, adversarial_predictions2)\n","        total_accuracy1 += accuracy1\n","        total_accuracy2 += accuracy2\n","\n","    average_accuracy1 = total_accuracy1 / num_batches\n","    average_accuracy2 = total_accuracy2 / num_batches\n","    avg_perturbation1 = total_perturbation1 / num_batches\n","    avg_perturbation2 = total_perturbation2 / num_batches\n","\n","    # Concatenate all batches for this epsilon\n","    epsilon_true_labels_onehot = np.vstack(epsilon_true_labels_onehot)\n","    epsilon_pred_probs_pgd = np.vstack(epsilon_pred_probs_pgd)\n","    epsilon_pred_probs_fgsm = np.vstack(epsilon_pred_probs_fgsm)\n","\n","    # Calculate and plot ROC curve\n","    roc_auc1, roc_auc2 = plot_roc_curve(\n","        epsilon_true_labels_onehot,\n","        epsilon_pred_probs_pgd,\n","        epsilon_pred_probs_fgsm,\n","        epsilon\n","    )\n","\n","    avg_roc_auc1[epsilon] = roc_auc1\n","    avg_roc_auc2[epsilon] = roc_auc2\n","\n","    # Calculate precision and recall\n","    precision1 = precision_score(all_true_labels, all_predicted_labels1, average='macro')\n","    recall1 = recall_score(all_true_labels, all_predicted_labels1, average='macro')\n","    precision2 = precision_score(all_true_labels, all_predicted_labels2, average='macro')\n","    recall2 = recall_score(all_true_labels, all_predicted_labels2, average='macro')\n","\n","    avg_precision1[epsilon] = precision1\n","    avg_recall1[epsilon] = recall1\n","    avg_precision2[epsilon] = precision2\n","    avg_recall2[epsilon] = recall2\n","\n","    # Generate classification reports\n","    pgd_report = classification_report(all_true_labels, all_predicted_labels1, output_dict=True)\n","    fgsm_report = classification_report(all_true_labels, all_predicted_labels2, output_dict=True)\n","\n","    print(f\"Average accuracy of PGD attack for epsilon value {epsilon}: {average_accuracy1}\")\n","    avg_accuracies1[epsilon] = average_accuracy1\n","    print(f\"Average accuracy of FGSM attack for epsilon value {epsilon}: {average_accuracy2}\")\n","    avg_accuracies2[epsilon] = average_accuracy2\n","    print(f\"Average perturbation volume for PGD attack with epsilon {epsilon}: {avg_perturbation1}\")\n","    perturbed_volumes1[epsilon] = avg_perturbation1\n","    print(f\"Average perturbation volume for FGSM attack with epsilon {epsilon}: {avg_perturbation2}\")\n","    perturbed_volumes2[epsilon] = avg_perturbation2\n","\n","    # Print precision and recall\n","    print(f\"Average precision of PGD attack for epsilon value {epsilon}: {precision1}\")\n","    print(f\"Average recall of PGD attack for epsilon value {epsilon}: {recall1}\")\n","    print(f\"Average precision of FGSM attack for epsilon value {epsilon}: {precision2}\")\n","    print(f\"Average recall of FGSM attack for epsilon value {epsilon}: {recall2}\")\n","\n","    # Print ROC AUC\n","    print(f\"ROC AUC of PGD attack for epsilon value {epsilon}: {roc_auc1}\")\n","    print(f\"ROC AUC of FGSM attack for epsilon value {epsilon}: {roc_auc2}\")\n","\n","    # Print classification reports\n","    print(f\"\\nClassification Report for PGD Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels1))\n","\n","    print(f\"\\nClassification Report for FGSM Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels2))\n","\n","    # Clean up\n","    tf.keras.backend.clear_session()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apVhPYKsC2n2","executionInfo":{"status":"ok","timestamp":1741403220363,"user_tz":300,"elapsed":1177450,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"69f1427b-0715-4821-95a6-a52285275550"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon value: 1e-06\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Average accuracy of PGD attack for epsilon value 1e-06: 0.39852898550724636\n","Average accuracy of FGSM attack for epsilon value 1e-06: 0.4846956521739132\n","Average perturbation volume for PGD attack with epsilon 1e-06: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 1e-06: 4.4710442402308965e-06\n","Average precision of PGD attack for epsilon value 1e-06: 0.4035047791978091\n","Average recall of PGD attack for epsilon value 1e-06: 0.40016902953711614\n","Average precision of FGSM attack for epsilon value 1e-06: 0.49804046909254546\n","Average recall of FGSM attack for epsilon value 1e-06: 0.48617462665150074\n","ROC AUC of PGD attack for epsilon value 1e-06: 0.5754485415318792\n","ROC AUC of FGSM attack for epsilon value 1e-06: 0.687713654275628\n","\n","Classification Report for PGD Attack (ε = 1e-06):\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.57      0.47     47512\n","           1       0.42      0.17      0.24     47269\n","           2       0.39      0.47      0.42     43219\n","\n","    accuracy                           0.40    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.40      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1e-06):\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.68      0.55     47512\n","           1       0.54      0.23      0.32     47269\n","           2       0.50      0.55      0.52     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.50      0.49      0.46    138000\n","weighted avg       0.50      0.48      0.46    138000\n","\n","Epsilon value: 1e-05\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Average accuracy of PGD attack for epsilon value 1e-05: 0.39852898550724636\n","Average accuracy of FGSM attack for epsilon value 1e-05: 0.4846449275362321\n","Average perturbation volume for PGD attack with epsilon 1e-05: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 1e-05: 4.4720572117037826e-05\n","Average precision of PGD attack for epsilon value 1e-05: 0.4035047791978091\n","Average recall of PGD attack for epsilon value 1e-05: 0.40016902953711614\n","Average precision of FGSM attack for epsilon value 1e-05: 0.4979941103522891\n","Average recall of FGSM attack for epsilon value 1e-05: 0.48612338952735107\n","ROC AUC of PGD attack for epsilon value 1e-05: 0.5754484644036596\n","ROC AUC of FGSM attack for epsilon value 1e-05: 0.6876640872097272\n","\n","Classification Report for PGD Attack (ε = 1e-05):\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.57      0.47     47512\n","           1       0.42      0.17      0.24     47269\n","           2       0.39      0.47      0.42     43219\n","\n","    accuracy                           0.40    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.40      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1e-05):\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.68      0.55     47512\n","           1       0.54      0.23      0.32     47269\n","           2       0.50      0.55      0.52     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.50      0.49      0.46    138000\n","weighted avg       0.50      0.48      0.46    138000\n","\n","Epsilon value: 0.0001\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Average accuracy of PGD attack for epsilon value 0.0001: 0.39852898550724636\n","Average accuracy of FGSM attack for epsilon value 0.0001: 0.4840942028985509\n","Average perturbation volume for PGD attack with epsilon 0.0001: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 0.0001: 0.0004470535757296813\n","Average precision of PGD attack for epsilon value 0.0001: 0.4035047791978091\n","Average recall of PGD attack for epsilon value 0.0001: 0.40016902953711614\n","Average precision of FGSM attack for epsilon value 0.0001: 0.4974829950919353\n","Average recall of FGSM attack for epsilon value 0.0001: 0.4855708339814548\n","ROC AUC of PGD attack for epsilon value 0.0001: 0.5754477073697292\n","ROC AUC of FGSM attack for epsilon value 0.0001: 0.6871728175859302\n","\n","Classification Report for PGD Attack (ε = 0.0001):\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.57      0.47     47512\n","           1       0.42      0.17      0.24     47269\n","           2       0.39      0.47      0.42     43219\n","\n","    accuracy                           0.40    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.40      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.0001):\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.68      0.55     47512\n","           1       0.54      0.23      0.32     47269\n","           2       0.50      0.55      0.52     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.50      0.49      0.46    138000\n","weighted avg       0.50      0.48      0.46    138000\n","\n","Epsilon value: 0.001\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Average accuracy of PGD attack for epsilon value 0.001: 0.39849999999999997\n","Average accuracy of FGSM attack for epsilon value 0.001: 0.47868840579710165\n","Average perturbation volume for PGD attack with epsilon 0.001: 2.2640041762935943\n","Average perturbation volume for FGSM attack with epsilon 0.001: 0.004455580976724193\n","Average precision of PGD attack for epsilon value 0.001: 0.4034810592751641\n","Average recall of PGD attack for epsilon value 0.001: 0.40013887579393653\n","Average precision of FGSM attack for epsilon value 0.001: 0.4923274836326437\n","Average recall of FGSM attack for epsilon value 0.001: 0.48014008702712846\n","ROC AUC of PGD attack for epsilon value 0.001: 0.5754396418893393\n","ROC AUC of FGSM attack for epsilon value 0.001: 0.6822812874828073\n","\n","Classification Report for PGD Attack (ε = 0.001):\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.57      0.47     47512\n","           1       0.42      0.17      0.24     47269\n","           2       0.39      0.47      0.42     43219\n","\n","    accuracy                           0.40    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.40      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.001):\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.67      0.54     47512\n","           1       0.53      0.22      0.32     47269\n","           2       0.49      0.54      0.51     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.49      0.48      0.46    138000\n","weighted avg       0.49      0.48      0.46    138000\n","\n"]}]},{"cell_type":"code","source":["\"\"\" ADVERSARIAL ATTACK ON TEST DATA ON 1 EPSILON VALUES\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import precision_score, recall_score, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Define constants\n","max_test_size = testX_CNN.shape[0]\n","batch_size = 2000\n","num_batches = max_test_size // batch_size\n","epsilon_values = [0.01]\n","num_iterations = 5\n","step_size = 0.01\n","\n","# Define your model\n","model = lstm1\n","\n","avg_accuracies1 = {}\n","avg_accuracies2 = {}\n","perturbed_volumes1 = {}\n","perturbed_volumes2 = {}\n","# Define dictionaries to hold precision and recall\n","avg_precision1 = {}\n","avg_recall1 = {}\n","avg_precision2 = {}\n","avg_recall2 = {}\n","# Define dictionaries to hold ROC AUC scores\n","avg_roc_auc1 = {}\n","avg_roc_auc2 = {}\n","\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","def data_set(testX_CNN, start_idx, end_idx):\n","    shifted_testX_CNN = tf.concat([testX_CNN[start_idx:end_idx, 1:100, :, :], testX_CNN[start_idx:end_idx, 99:, :, :]], axis=1)\n","    return shifted_testX_CNN\n","\n","def fgsm_attack(images, labels, epsilon):\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        predictions = model(images)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","    gradient = tape.gradient(loss, images)\n","    signed_grad = tf.sign(gradient)\n","\n","    signed_masked = signed_grad.numpy()\n","    signed_masked[:, :99, :, :] = 0\n","    signed_masked[:, 99:, ::2, :] = 0\n","    signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","    perturbed_images = images + epsilon * signed_masked\n","    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","    return perturbed_images\n","\n","def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","    perturbed_images = tf.identity(images)\n","\n","    for _ in range(num_iterations):\n","        # Gradient step\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","        gradient = tape.gradient(loss, perturbed_images)\n","        signed_grad = tf.sign(gradient)\n","\n","        # Apply masking to gradient\n","        signed_masked = signed_grad.numpy()\n","        signed_masked[:, :99, :, :] = 0\n","        signed_masked[:, 99:, ::2, :] = 0\n","        signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","        # Apply gradient step\n","        perturbed_images = perturbed_images + step_size * signed_masked\n","\n","        # Apply volume constraint\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","    return perturbed_images\n","\n","def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","    images = images.numpy()\n","    slices = [slice(None)] * images.ndim\n","    testX_CNN = testX_CNN[start_idx:end_idx]\n","    for idx in range(images.shape[dimension]):\n","        slices[dimension] = idx\n","        images[tuple(slices)] = np.maximum(images[tuple(slices)], testX_CNN[tuple(slices)])\n","    images = tf.convert_to_tensor(images, dtype=tf.float32)\n","    return images\n","\n","def plot_roc_curve(y_true, y_score1, y_score2, epsilon):\n","    \"\"\"\n","    Plot ROC curve for both attacks at a specific epsilon value\n","    \"\"\"\n","    # Get number of classes\n","    n_classes = y_score1.shape[1]\n","\n","    # Compute ROC curve and ROC area for each class for PGD\n","    fpr1 = dict()\n","    tpr1 = dict()\n","    roc_auc1 = dict()\n","    for i in range(n_classes):\n","        fpr1[i], tpr1[i], _ = roc_curve(y_true[:, i], y_score1[:, i])\n","        roc_auc1[i] = auc(fpr1[i], tpr1[i])\n","\n","    # Compute ROC curve and ROC area for each class for FGSM\n","    fpr2 = dict()\n","    tpr2 = dict()\n","    roc_auc2 = dict()\n","    for i in range(n_classes):\n","        fpr2[i], tpr2[i], _ = roc_curve(y_true[:, i], y_score2[:, i])\n","        roc_auc2[i] = auc(fpr2[i], tpr2[i])\n","\n","    # Calculate macro average ROC curve and ROC area\n","    all_fpr1 = np.unique(np.concatenate([fpr1[i] for i in range(n_classes)]))\n","    all_fpr2 = np.unique(np.concatenate([fpr2[i] for i in range(n_classes)]))\n","\n","    mean_tpr1 = np.zeros_like(all_fpr1)\n","    mean_tpr2 = np.zeros_like(all_fpr2)\n","    for i in range(n_classes):\n","        mean_tpr1 += np.interp(all_fpr1, fpr1[i], tpr1[i])\n","        mean_tpr2 += np.interp(all_fpr2, fpr2[i], tpr2[i])\n","\n","    mean_tpr1 /= n_classes\n","    mean_tpr2 /= n_classes\n","\n","    macro_roc_auc1 = auc(all_fpr1, mean_tpr1)\n","    macro_roc_auc2 = auc(all_fpr2, mean_tpr2)\n","\n","    # Plot ROC curve only as per the requirement\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(all_fpr1, mean_tpr1, label=f'PGD Attack - Macro-average ROC (AUC = {macro_roc_auc1:.2f})',\n","             color='blue', linestyle='solid', linewidth=2)\n","    plt.plot(all_fpr2, mean_tpr2, label=f'FGSM Attack - Macro-average ROC (AUC = {macro_roc_auc2:.2f})',\n","             color='red', linestyle='dashed', linewidth=2)\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for PGD and FGSM Attacks with ε = {epsilon}')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the figure\n","    plt.savefig(f'roc_curve_epsilon_{epsilon}.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    return macro_roc_auc1, macro_roc_auc2\n","\n","# Lists to store all prediction probabilities and true labels for ROC curves\n","all_true_labels_onehot = []\n","all_pred_probs_pgd = []\n","all_pred_probs_fgsm = []\n","\n","for epsilon in epsilon_values:\n","    print(f\"Epsilon value: {epsilon}\")\n","    total_accuracy1 = 0.0\n","    total_accuracy2 = 0.0\n","    total_perturbation1 = 0.0\n","    total_perturbation2 = 0.0\n","    all_true_labels = []\n","    all_predicted_labels1 = []\n","    all_predicted_labels2 = []\n","\n","    # For this epsilon, collect all prediction probabilities\n","    epsilon_true_labels_onehot = []\n","    epsilon_pred_probs_pgd = []\n","    epsilon_pred_probs_fgsm = []\n","\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = (i + 1) * batch_size\n","\n","        batch_images = data_set(testX_CNN, start_idx, end_idx)\n","        batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","        batch_labels = testY_CNN[start_idx:end_idx]\n","\n","        perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","        perturbed_images2 = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","        perturbation1 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images1.numpy())\n","        perturbation2 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images2.numpy())\n","\n","        total_perturbation1 += perturbation1\n","        total_perturbation2 += perturbation2\n","\n","        X_perturbed1 = perturbed_images1.numpy()\n","        X_perturbed2 = perturbed_images2.numpy()\n","\n","        # Get raw probabilities for ROC curve\n","        adversarial_probs1 = model.predict(X_perturbed1)\n","        adversarial_probs2 = model.predict(X_perturbed2)\n","\n","        # Get predicted labels\n","        adversarial_predictions1 = np.argmax(adversarial_probs1, axis=1)\n","        adversarial_predictions2 = np.argmax(adversarial_probs2, axis=1)\n","\n","        # Collect data for ROC curve\n","        epsilon_true_labels_onehot.append(batch_labels)\n","        epsilon_pred_probs_pgd.append(adversarial_probs1)\n","        epsilon_pred_probs_fgsm.append(adversarial_probs2)\n","\n","        # Append results for precision and recall calculation\n","        true_labels_batch = np.argmax(batch_labels, axis=1)\n","        all_true_labels.extend(true_labels_batch)\n","        all_predicted_labels1.extend(adversarial_predictions1)\n","        all_predicted_labels2.extend(adversarial_predictions2)\n","\n","        accuracy1 = accuracy_score(true_labels_batch, adversarial_predictions1)\n","        accuracy2 = accuracy_score(true_labels_batch, adversarial_predictions2)\n","        total_accuracy1 += accuracy1\n","        total_accuracy2 += accuracy2\n","\n","    average_accuracy1 = total_accuracy1 / num_batches\n","    average_accuracy2 = total_accuracy2 / num_batches\n","    avg_perturbation1 = total_perturbation1 / num_batches\n","    avg_perturbation2 = total_perturbation2 / num_batches\n","\n","    # Concatenate all batches for this epsilon\n","    epsilon_true_labels_onehot = np.vstack(epsilon_true_labels_onehot)\n","    epsilon_pred_probs_pgd = np.vstack(epsilon_pred_probs_pgd)\n","    epsilon_pred_probs_fgsm = np.vstack(epsilon_pred_probs_fgsm)\n","\n","    # Calculate and plot ROC curve\n","    roc_auc1, roc_auc2 = plot_roc_curve(\n","        epsilon_true_labels_onehot,\n","        epsilon_pred_probs_pgd,\n","        epsilon_pred_probs_fgsm,\n","        epsilon\n","    )\n","\n","    avg_roc_auc1[epsilon] = roc_auc1\n","    avg_roc_auc2[epsilon] = roc_auc2\n","\n","    # Calculate precision and recall\n","    precision1 = precision_score(all_true_labels, all_predicted_labels1, average='macro')\n","    recall1 = recall_score(all_true_labels, all_predicted_labels1, average='macro')\n","    precision2 = precision_score(all_true_labels, all_predicted_labels2, average='macro')\n","    recall2 = recall_score(all_true_labels, all_predicted_labels2, average='macro')\n","\n","    avg_precision1[epsilon] = precision1\n","    avg_recall1[epsilon] = recall1\n","    avg_precision2[epsilon] = precision2\n","    avg_recall2[epsilon] = recall2\n","\n","    # Generate classification reports\n","    pgd_report = classification_report(all_true_labels, all_predicted_labels1, output_dict=True)\n","    fgsm_report = classification_report(all_true_labels, all_predicted_labels2, output_dict=True)\n","\n","    print(f\"Average accuracy of PGD attack for epsilon value {epsilon}: {average_accuracy1}\")\n","    avg_accuracies1[epsilon] = average_accuracy1\n","    print(f\"Average accuracy of FGSM attack for epsilon value {epsilon}: {average_accuracy2}\")\n","    avg_accuracies2[epsilon] = average_accuracy2\n","    print(f\"Average perturbation volume for PGD attack with epsilon {epsilon}: {avg_perturbation1}\")\n","    perturbed_volumes1[epsilon] = avg_perturbation1\n","    print(f\"Average perturbation volume for FGSM attack with epsilon {epsilon}: {avg_perturbation2}\")\n","    perturbed_volumes2[epsilon] = avg_perturbation2\n","\n","    # Print precision and recall\n","    print(f\"Average precision of PGD attack for epsilon value {epsilon}: {precision1}\")\n","    print(f\"Average recall of PGD attack for epsilon value {epsilon}: {recall1}\")\n","    print(f\"Average precision of FGSM attack for epsilon value {epsilon}: {precision2}\")\n","    print(f\"Average recall of FGSM attack for epsilon value {epsilon}: {recall2}\")\n","\n","    # Print ROC AUC\n","    print(f\"ROC AUC of PGD attack for epsilon value {epsilon}: {roc_auc1}\")\n","    print(f\"ROC AUC of FGSM attack for epsilon value {epsilon}: {roc_auc2}\")\n","\n","    # Print classification reports\n","    print(f\"\\nClassification Report for PGD Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels1))\n","\n","    print(f\"\\nClassification Report for FGSM Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels2))\n","\n","    # Clean up\n","    tf.keras.backend.clear_session()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gduL8QXfSrE","executionInfo":{"status":"ok","timestamp":1741403511984,"user_tz":300,"elapsed":291609,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"96481ff6-0028-49e4-fe3a-c23da423913d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon value: 0.01\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Average accuracy of PGD attack for epsilon value 0.01: 0.39841304347826073\n","Average accuracy of FGSM attack for epsilon value 0.01: 0.43261594202898557\n","Average perturbation volume for PGD attack with epsilon 0.01: 2.2640044263739516\n","Average perturbation volume for FGSM attack with epsilon 0.01: 0.04052977992788605\n","Average precision of PGD attack for epsilon value 0.01: 0.40340644490605887\n","Average recall of PGD attack for epsilon value 0.01: 0.4000518629267282\n","Average precision of FGSM attack for epsilon value 0.01: 0.44907623770002664\n","Average recall of FGSM attack for epsilon value 0.01: 0.43362785426756884\n","ROC AUC of PGD attack for epsilon value 0.01: 0.5753562072598435\n","ROC AUC of FGSM attack for epsilon value 0.01: 0.6413333185798946\n","\n","Classification Report for PGD Attack (ε = 0.01):\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.57      0.47     47512\n","           1       0.42      0.17      0.24     47269\n","           2       0.39      0.47      0.42     43219\n","\n","    accuracy                           0.40    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.40      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.01):\n","              precision    recall  f1-score   support\n","\n","           0       0.41      0.62      0.50     47512\n","           1       0.50      0.20      0.29     47269\n","           2       0.43      0.48      0.46     43219\n","\n","    accuracy                           0.43    138000\n","   macro avg       0.45      0.43      0.41    138000\n","weighted avg       0.45      0.43      0.41    138000\n","\n"]}]},{"cell_type":"code","source":["\"\"\" ADVERSARIAL ATTACK ON TEST DATA ON 3 EPSILON VALUES\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import precision_score, recall_score, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Define constants\n","max_test_size = testX_CNN.shape[0]\n","batch_size = 2000\n","num_batches = max_test_size // batch_size\n","epsilon_values = [0.1, 1, 10]\n","num_iterations = 5\n","step_size = 0.01\n","\n","# Define your model\n","model = lstm1\n","\n","avg_accuracies1 = {}\n","avg_accuracies2 = {}\n","perturbed_volumes1 = {}\n","perturbed_volumes2 = {}\n","# Define dictionaries to hold precision and recall\n","avg_precision1 = {}\n","avg_recall1 = {}\n","avg_precision2 = {}\n","avg_recall2 = {}\n","# Define dictionaries to hold ROC AUC scores\n","avg_roc_auc1 = {}\n","avg_roc_auc2 = {}\n","\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","def data_set(testX_CNN, start_idx, end_idx):\n","    shifted_testX_CNN = tf.concat([testX_CNN[start_idx:end_idx, 1:100, :, :], testX_CNN[start_idx:end_idx, 99:, :, :]], axis=1)\n","    return shifted_testX_CNN\n","\n","def fgsm_attack(images, labels, epsilon):\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        predictions = model(images)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","    gradient = tape.gradient(loss, images)\n","    signed_grad = tf.sign(gradient)\n","\n","    signed_masked = signed_grad.numpy()\n","    signed_masked[:, :99, :, :] = 0\n","    signed_masked[:, 99:, ::2, :] = 0\n","    signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","    perturbed_images = images + epsilon * signed_masked\n","    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","    return perturbed_images\n","\n","def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","    perturbed_images = tf.identity(images)\n","\n","    for _ in range(num_iterations):\n","        # Gradient step\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","        gradient = tape.gradient(loss, perturbed_images)\n","        signed_grad = tf.sign(gradient)\n","\n","        # Apply masking to gradient\n","        signed_masked = signed_grad.numpy()\n","        signed_masked[:, :99, :, :] = 0\n","        signed_masked[:, 99:, ::2, :] = 0\n","        signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","        # Apply gradient step\n","        perturbed_images = perturbed_images + step_size * signed_masked\n","\n","        # Step 1: Apply volume constraint\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","        # Step 2: Apply L2 norm constraint (projection step)\n","        delta = perturbed_images - images  # Calculate current perturbation\n","\n","        # Reshape to flatten all dimensions except batch\n","        delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","        # Calculate L2 norm on the flattened dimensions\n","        norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","        # Reshape norm for broadcasting\n","        norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","        # Scale perturbation\n","        scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","        delta = delta * scaling\n","\n","        perturbed_images = images + delta  # Apply constrained perturbation\n","\n","        # Step 3: Apply clipping to valid range [0,1]\n","        perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","        # Step 4: Re-apply volume constraint after all other constraints\n","        # This ensures volume constraint takes precedence if there's a conflict\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","    return perturbed_images\n","\n","def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","    images = images.numpy()\n","    slices = [slice(None)] * images.ndim\n","    testX_CNN = testX_CNN[start_idx:end_idx]\n","    for idx in range(images.shape[dimension]):\n","        slices[dimension] = idx\n","        images[tuple(slices)] = np.maximum(images[tuple(slices)], testX_CNN[tuple(slices)])\n","    images = tf.convert_to_tensor(images, dtype=tf.float32)\n","    return images\n","\n","def plot_roc_curve(y_true, y_score1, y_score2, epsilon):\n","    \"\"\"\n","    Plot ROC curve for both attacks at a specific epsilon value\n","    \"\"\"\n","    # Get number of classes\n","    n_classes = y_score1.shape[1]\n","\n","    # Compute ROC curve and ROC area for each class for PGD\n","    fpr1 = dict()\n","    tpr1 = dict()\n","    roc_auc1 = dict()\n","    for i in range(n_classes):\n","        fpr1[i], tpr1[i], _ = roc_curve(y_true[:, i], y_score1[:, i])\n","        roc_auc1[i] = auc(fpr1[i], tpr1[i])\n","\n","    # Compute ROC curve and ROC area for each class for FGSM\n","    fpr2 = dict()\n","    tpr2 = dict()\n","    roc_auc2 = dict()\n","    for i in range(n_classes):\n","        fpr2[i], tpr2[i], _ = roc_curve(y_true[:, i], y_score2[:, i])\n","        roc_auc2[i] = auc(fpr2[i], tpr2[i])\n","\n","    # Calculate macro average ROC curve and ROC area\n","    all_fpr1 = np.unique(np.concatenate([fpr1[i] for i in range(n_classes)]))\n","    all_fpr2 = np.unique(np.concatenate([fpr2[i] for i in range(n_classes)]))\n","\n","    mean_tpr1 = np.zeros_like(all_fpr1)\n","    mean_tpr2 = np.zeros_like(all_fpr2)\n","    for i in range(n_classes):\n","        mean_tpr1 += np.interp(all_fpr1, fpr1[i], tpr1[i])\n","        mean_tpr2 += np.interp(all_fpr2, fpr2[i], tpr2[i])\n","\n","    mean_tpr1 /= n_classes\n","    mean_tpr2 /= n_classes\n","\n","    macro_roc_auc1 = auc(all_fpr1, mean_tpr1)\n","    macro_roc_auc2 = auc(all_fpr2, mean_tpr2)\n","\n","    # Plot ROC curve only as per the requirement\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(all_fpr1, mean_tpr1, label=f'PGD Attack - Macro-average ROC (AUC = {macro_roc_auc1:.2f})',\n","             color='blue', linestyle='solid', linewidth=2)\n","    plt.plot(all_fpr2, mean_tpr2, label=f'FGSM Attack - Macro-average ROC (AUC = {macro_roc_auc2:.2f})',\n","             color='red', linestyle='dashed', linewidth=2)\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for PGD and FGSM Attacks with ε = {epsilon}')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the figure\n","    plt.savefig(f'roc_curve_epsilon_{epsilon}.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    return macro_roc_auc1, macro_roc_auc2\n","\n","# Lists to store all prediction probabilities and true labels for ROC curves\n","all_true_labels_onehot = []\n","all_pred_probs_pgd = []\n","all_pred_probs_fgsm = []\n","\n","for epsilon in epsilon_values:\n","    print(f\"Epsilon value: {epsilon}\")\n","    total_accuracy1 = 0.0\n","    total_accuracy2 = 0.0\n","    total_perturbation1 = 0.0\n","    total_perturbation2 = 0.0\n","    all_true_labels = []\n","    all_predicted_labels1 = []\n","    all_predicted_labels2 = []\n","\n","    # For this epsilon, collect all prediction probabilities\n","    epsilon_true_labels_onehot = []\n","    epsilon_pred_probs_pgd = []\n","    epsilon_pred_probs_fgsm = []\n","\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = (i + 1) * batch_size\n","\n","        batch_images = data_set(testX_CNN, start_idx, end_idx)\n","        batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","        batch_labels = testY_CNN[start_idx:end_idx]\n","\n","        perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","        perturbed_images2 = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","        perturbation1 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images1.numpy())\n","        perturbation2 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images2.numpy())\n","\n","        total_perturbation1 += perturbation1\n","        total_perturbation2 += perturbation2\n","\n","        X_perturbed1 = perturbed_images1.numpy()\n","        X_perturbed2 = perturbed_images2.numpy()\n","\n","        # Get raw probabilities for ROC curve\n","        adversarial_probs1 = model.predict(X_perturbed1)\n","        adversarial_probs2 = model.predict(X_perturbed2)\n","\n","        # Get predicted labels\n","        adversarial_predictions1 = np.argmax(adversarial_probs1, axis=1)\n","        adversarial_predictions2 = np.argmax(adversarial_probs2, axis=1)\n","\n","        # Collect data for ROC curve\n","        epsilon_true_labels_onehot.append(batch_labels)\n","        epsilon_pred_probs_pgd.append(adversarial_probs1)\n","        epsilon_pred_probs_fgsm.append(adversarial_probs2)\n","\n","        # Append results for precision and recall calculation\n","        true_labels_batch = np.argmax(batch_labels, axis=1)\n","        all_true_labels.extend(true_labels_batch)\n","        all_predicted_labels1.extend(adversarial_predictions1)\n","        all_predicted_labels2.extend(adversarial_predictions2)\n","\n","        accuracy1 = accuracy_score(true_labels_batch, adversarial_predictions1)\n","        accuracy2 = accuracy_score(true_labels_batch, adversarial_predictions2)\n","        total_accuracy1 += accuracy1\n","        total_accuracy2 += accuracy2\n","\n","    average_accuracy1 = total_accuracy1 / num_batches\n","    average_accuracy2 = total_accuracy2 / num_batches\n","    avg_perturbation1 = total_perturbation1 / num_batches\n","    avg_perturbation2 = total_perturbation2 / num_batches\n","\n","    # Concatenate all batches for this epsilon\n","    epsilon_true_labels_onehot = np.vstack(epsilon_true_labels_onehot)\n","    epsilon_pred_probs_pgd = np.vstack(epsilon_pred_probs_pgd)\n","    epsilon_pred_probs_fgsm = np.vstack(epsilon_pred_probs_fgsm)\n","\n","    # Calculate and plot ROC curve\n","    roc_auc1, roc_auc2 = plot_roc_curve(\n","        epsilon_true_labels_onehot,\n","        epsilon_pred_probs_pgd,\n","        epsilon_pred_probs_fgsm,\n","        epsilon\n","    )\n","\n","    avg_roc_auc1[epsilon] = roc_auc1\n","    avg_roc_auc2[epsilon] = roc_auc2\n","\n","    # Calculate precision and recall\n","    precision1 = precision_score(all_true_labels, all_predicted_labels1, average='macro')\n","    recall1 = recall_score(all_true_labels, all_predicted_labels1, average='macro')\n","    precision2 = precision_score(all_true_labels, all_predicted_labels2, average='macro')\n","    recall2 = recall_score(all_true_labels, all_predicted_labels2, average='macro')\n","\n","    avg_precision1[epsilon] = precision1\n","    avg_recall1[epsilon] = recall1\n","    avg_precision2[epsilon] = precision2\n","    avg_recall2[epsilon] = recall2\n","\n","    # Generate classification reports\n","    pgd_report = classification_report(all_true_labels, all_predicted_labels1, output_dict=True)\n","    fgsm_report = classification_report(all_true_labels, all_predicted_labels2, output_dict=True)\n","\n","    print(f\"Average accuracy of PGD attack for epsilon value {epsilon}: {average_accuracy1}\")\n","    avg_accuracies1[epsilon] = average_accuracy1\n","    print(f\"Average accuracy of FGSM attack for epsilon value {epsilon}: {average_accuracy2}\")\n","    avg_accuracies2[epsilon] = average_accuracy2\n","    print(f\"Average perturbation volume for PGD attack with epsilon {epsilon}: {avg_perturbation1}\")\n","    perturbed_volumes1[epsilon] = avg_perturbation1\n","    print(f\"Average perturbation volume for FGSM attack with epsilon {epsilon}: {avg_perturbation2}\")\n","    perturbed_volumes2[epsilon] = avg_perturbation2\n","\n","    # Print precision and recall\n","    print(f\"Average precision of PGD attack for epsilon value {epsilon}: {precision1}\")\n","    print(f\"Average recall of PGD attack for epsilon value {epsilon}: {recall1}\")\n","    print(f\"Average precision of FGSM attack for epsilon value {epsilon}: {precision2}\")\n","    print(f\"Average recall of FGSM attack for epsilon value {epsilon}: {recall2}\")\n","\n","    # Print ROC AUC\n","    print(f\"ROC AUC of PGD attack for epsilon value {epsilon}: {roc_auc1}\")\n","    print(f\"ROC AUC of FGSM attack for epsilon value {epsilon}: {roc_auc2}\")\n","\n","    # Print classification reports\n","    print(f\"\\nClassification Report for PGD Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels1))\n","\n","    print(f\"\\nClassification Report for FGSM Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels2))\n","\n","    # Clean up\n","    tf.keras.backend.clear_session()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgyUs8rdDPiH","executionInfo":{"status":"ok","timestamp":1741404387328,"user_tz":300,"elapsed":875337,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"a9fdc203-de81-4582-a5f6-ff52e45ed030"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon value: 0.1\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Average accuracy of PGD attack for epsilon value 0.1: 0.3967753623188404\n","Average accuracy of FGSM attack for epsilon value 0.1: 0.19221014492753627\n","Average perturbation volume for PGD attack with epsilon 0.1: 2.2641183459672374\n","Average perturbation volume for FGSM attack with epsilon 0.1: 0.3302751550639885\n","Average precision of PGD attack for epsilon value 0.1: 0.402058463812037\n","Average recall of PGD attack for epsilon value 0.1: 0.39839966162896484\n","Average precision of FGSM attack for epsilon value 0.1: 0.24636281557111403\n","Average recall of FGSM attack for epsilon value 0.1: 0.19162958356594703\n","ROC AUC of PGD attack for epsilon value 0.1: 0.5741231980787833\n","ROC AUC of FGSM attack for epsilon value 0.1: 0.40896216866630863\n","\n","Classification Report for PGD Attack (ε = 0.1):\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.56      0.47     47512\n","           1       0.42      0.17      0.24     47269\n","           2       0.39      0.46      0.42     43219\n","\n","    accuracy                           0.40    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.40      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.1):\n","              precision    recall  f1-score   support\n","\n","           0       0.19      0.29      0.23     47512\n","           1       0.40      0.10      0.16     47269\n","           2       0.15      0.18      0.16     43219\n","\n","    accuracy                           0.19    138000\n","   macro avg       0.25      0.19      0.19    138000\n","weighted avg       0.25      0.19      0.19    138000\n","\n","Epsilon value: 1\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Average accuracy of PGD attack for epsilon value 1: 0.36842753623188407\n","Average accuracy of FGSM attack for epsilon value 1: 0.016065217391304346\n","Average perturbation volume for PGD attack with epsilon 1: 2.267539433163145\n","Average perturbation volume for FGSM attack with epsilon 1: 3.111777768618819\n","Average precision of PGD attack for epsilon value 1: 0.37782020636990565\n","Average recall of PGD attack for epsilon value 1: 0.3696441241634212\n","Average precision of FGSM attack for epsilon value 1: 0.1478999120662555\n","Average recall of FGSM attack for epsilon value 1: 0.01587617068240571\n","ROC AUC of PGD attack for epsilon value 1: 0.5484098998955291\n","ROC AUC of FGSM attack for epsilon value 1: 0.26248919463093034\n","\n","Classification Report for PGD Attack (ε = 1):\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.53      0.43     47512\n","           1       0.41      0.16      0.23     47269\n","           2       0.35      0.42      0.38     43219\n","\n","    accuracy                           0.37    138000\n","   macro avg       0.38      0.37      0.35    138000\n","weighted avg       0.38      0.37      0.35    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1):\n","              precision    recall  f1-score   support\n","\n","           0       0.01      0.01      0.01     47512\n","           1       0.43      0.03      0.05     47269\n","           2       0.01      0.01      0.01     43219\n","\n","    accuracy                           0.02    138000\n","   macro avg       0.15      0.02      0.02    138000\n","weighted avg       0.15      0.02      0.02    138000\n","\n","Epsilon value: 10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Average accuracy of PGD attack for epsilon value 10: 0.3107753623188405\n","Average accuracy of FGSM attack for epsilon value 10: 0.015565217391304342\n","Average perturbation volume for PGD attack with epsilon 10: 2.274768571490827\n","Average perturbation volume for FGSM attack with epsilon 10: 3.111126160276109\n","Average precision of PGD attack for epsilon value 10: 0.32446339577680866\n","Average recall of PGD attack for epsilon value 10: 0.3114221616097747\n","Average precision of FGSM attack for epsilon value 10: 0.1437731473396607\n","Average recall of FGSM attack for epsilon value 10: 0.015393438951167416\n","ROC AUC of PGD attack for epsilon value 10: 0.48734913361709914\n","ROC AUC of FGSM attack for epsilon value 10: 0.26254517001496047\n","\n","Classification Report for PGD Attack (ε = 10):\n","              precision    recall  f1-score   support\n","\n","           0       0.31      0.46      0.37     47512\n","           1       0.37      0.14      0.20     47269\n","           2       0.29      0.34      0.31     43219\n","\n","    accuracy                           0.31    138000\n","   macro avg       0.32      0.31      0.29    138000\n","weighted avg       0.33      0.31      0.29    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 10):\n","              precision    recall  f1-score   support\n","\n","           0       0.01      0.01      0.01     47512\n","           1       0.42      0.03      0.05     47269\n","           2       0.01      0.01      0.01     43219\n","\n","    accuracy                           0.02    138000\n","   macro avg       0.14      0.02      0.02    138000\n","weighted avg       0.15      0.02      0.02    138000\n","\n"]}]},{"cell_type":"code","source":["\"\"\"TRADING STRATEGY AFTER ATTACK ON 4 EPSILON VALUES\"\"\"\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","def run_adversarial_trading_analysis(model, testX_CNN, testY_CNN, dec_test, epsilon_values, batch_size=2000):\n","    \"\"\"Run trading strategy analysis with adversarial attacks\"\"\"\n","    results_pgd = []\n","    results_fgsm = []\n","    thresholds = [0.85, 0.90, 0.95, 0.99]  # Explicit thresholds\n","\n","    # Define constants needed for PGD attack\n","    num_iterations = 5\n","    step_size = 0.01\n","\n","    def data_set(testX_CNN, start_idx, end_idx):\n","        \"\"\"Prepare the dataset by shifting\"\"\"\n","        shifted_testX_CNN = tf.concat([\n","            testX_CNN[start_idx:end_idx, 1:100, :, :],\n","            testX_CNN[start_idx:end_idx, 99:, :, :]\n","        ], axis=1)\n","        return tf.cast(shifted_testX_CNN, tf.float32)\n","\n","    def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","        \"\"\"Apply volume constraints to the images\"\"\"\n","        images = images.numpy()\n","        slices = [slice(None)] * images.ndim\n","        testX_CNN_batch = testX_CNN[start_idx:end_idx]\n","        for idx in range(images.shape[dimension]):\n","            slices[dimension] = idx\n","            images[tuple(slices)] = np.maximum(\n","                images[tuple(slices)],\n","                testX_CNN_batch[tuple(slices)]\n","            )\n","        return tf.convert_to_tensor(images, dtype=tf.float32)\n","\n","    def get_model_predictions(perturbed_images):\n","        \"\"\"Get model predictions with error handling\"\"\"\n","        try:\n","            with tf.device('/CPU:0'):\n","                predictions = model(perturbed_images, training=False)\n","                return predictions.numpy()\n","        except Exception as e:\n","            print(f\"Error in model prediction: {str(e)}\")\n","            return None\n","\n","    def fgsm_attack(images, labels, epsilon):\n","        \"\"\"Implement FGSM attack\"\"\"\n","        try:\n","            with tf.GradientTape() as tape:\n","                tape.watch(images)\n","                predictions = model(images, training=False)\n","                loss = tf.keras.losses.CategoricalCrossentropy()(labels, predictions)\n","\n","            gradient = tape.gradient(loss, images)\n","            signed_grad = tf.sign(gradient)\n","\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            perturbed_images = images + epsilon * signed_masked\n","            return tf.clip_by_value(perturbed_images, 0, 1)\n","        except Exception as e:\n","            print(f\"Error in FGSM attack: {str(e)}\")\n","            return None\n","\n","    def pgd_attack(images, labels, epsilon, test_data, start_idx, end_idx):\n","        \"\"\"Implement PGD attack with volume constraint\"\"\"\n","        perturbed_images = tf.identity(images)\n","\n","        for _ in range(num_iterations):\n","            # Gradient step\n","            with tf.GradientTape() as tape:\n","                tape.watch(perturbed_images)\n","                predictions = model(perturbed_images, training=False)\n","                loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","            gradient = tape.gradient(loss, perturbed_images)\n","            signed_grad = tf.sign(gradient)\n","\n","            # Apply masking to gradient\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            # Apply gradient step\n","            perturbed_images = perturbed_images + step_size * signed_masked\n","\n","            # Step 1: Apply volume constraint\n","            perturbed_images = volume_constraint(perturbed_images, test_data, 2, start_idx, end_idx)\n","\n","            # Step 2: Apply L2 norm constraint (projection step)\n","            delta = perturbed_images - images  # Calculate current perturbation\n","\n","            # Reshape to flatten all dimensions except batch\n","            delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","            # Calculate L2 norm on the flattened dimensions\n","            norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","            # Reshape norm for broadcasting\n","            norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","            # Scale perturbation\n","            scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","            delta = delta * scaling\n","\n","            perturbed_images = images + delta  # Apply constrained perturbation\n","\n","            # Step 3: Apply clipping to valid range [0,1]\n","            perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","            # Step 4: Re-apply volume constraint after all other constraints\n","            # This ensures volume constraint takes precedence if there's a conflict\n","            perturbed_images = volume_constraint(perturbed_images, test_data, 2, start_idx, end_idx)\n","\n","        return perturbed_images\n","\n","    max_test_size = testX_CNN.shape[0]\n","    num_batches = max_test_size // batch_size\n","\n","    for epsilon in epsilon_values:\n","        print(f\"\\nAnalyzing epsilon: {epsilon}\")\n","\n","        pgd_predictions = []\n","        fgsm_predictions = []\n","\n","        for i in range(num_batches):\n","            start_idx = i * batch_size\n","            end_idx = min((i + 1) * batch_size, max_test_size)\n","\n","            try:\n","                # Prepare batch data\n","                batch_images = data_set(testX_CNN, start_idx, end_idx)\n","                batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","                batch_labels = testY_CNN[start_idx:end_idx]\n","\n","                # Generate adversarial examples\n","                perturbed_images_pgd = pgd_attack(batch_images, batch_labels, epsilon, testX_CNN, start_idx, end_idx)\n","                perturbed_images_fgsm = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","                if perturbed_images_pgd is not None and perturbed_images_fgsm is not None:\n","                    # Calculate perturbation volumes\n","                    pgd_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_pgd - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    fgsm_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_fgsm - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    print(f\"Batch {i+1}/{num_batches} - PGD volume: {pgd_volume:.6f}, FGSM volume: {fgsm_volume:.6f}\")\n","\n","                    # Get predictions\n","                    pgd_pred = get_model_predictions(perturbed_images_pgd)\n","                    fgsm_pred = get_model_predictions(perturbed_images_fgsm)\n","\n","                    if pgd_pred is not None:\n","                        pgd_predictions.append(pgd_pred)\n","                    if fgsm_pred is not None:\n","                        fgsm_predictions.append(fgsm_pred)\n","\n","            except Exception as e:\n","                print(f\"Error processing batch {i}: {str(e)}\")\n","                continue\n","\n","            tf.keras.backend.clear_session()\n","\n","        if pgd_predictions and fgsm_predictions:\n","            pgd_predictions = np.vstack(pgd_predictions)\n","            fgsm_predictions = np.vstack(fgsm_predictions)\n","\n","            # Process for each threshold\n","            for threshold in thresholds:\n","                # Process PGD results\n","                pgd_result = implement_fi2010_strategy(\n","                    predictions=pgd_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if pgd_result:\n","                    pgd_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'PGD'\n","                    })\n","                    results_pgd.append(pgd_result)\n","\n","                # Process FGSM results\n","                fgsm_result = implement_fi2010_strategy(\n","                    predictions=fgsm_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if fgsm_result:\n","                    fgsm_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'FGSM'\n","                    })\n","                    results_fgsm.append(fgsm_result)\n","\n","    # Create DataFrames\n","    pgd_df = pd.DataFrame(results_pgd) if results_pgd else pd.DataFrame()\n","    fgsm_df = pd.DataFrame(results_fgsm) if results_fgsm else pd.DataFrame()\n","\n","    # Display detailed summaries\n","    if not pgd_df.empty:\n","        print(\"\\nPGD Attack Summary by Threshold:\")\n","        summary_pgd = pgd_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        # Format the display\n","        pd.set_option('display.float_format', lambda x: '%.4f' % x)\n","        print(\"\\nPGD Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_pgd.loc[eps])\n","\n","    if not fgsm_df.empty:\n","        print(\"\\nFGSM Attack Summary by Threshold:\")\n","        summary_fgsm = fgsm_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        print(\"\\nFGSM Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_fgsm.loc[eps])\n","\n","    return pgd_df, fgsm_df\n","\n","def implement_fi2010_strategy(predictions, dec_data, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"Implementation of the FI-2010 trading strategy\"\"\"\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","    trades_info = []\n","    budget = 100\n","\n","    for i in range(k, min_length):\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax(predictions[i])\n","        max_prob = np.max(predictions[i])\n","\n","        if max_prob > prob_threshold and pred_class != 1:\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","            shares = budget / mid_prices[i]\n","\n","            if pred_class == 2:  # Long trade\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'profit': profit,\n","                    'correct': actual_direction == 1\n","                })\n","            elif pred_class == 0:  # Short trade\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'profit': profit,\n","                    'correct': actual_direction == -1\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","epsilon_values = [0.000001, 0.00001, 0.0001, 0.001]\n","results_pgd, results_fgsm = run_adversarial_trading_analysis(\n","    model=lstm1,\n","    testX_CNN=testX_CNN,\n","    testY_CNN=testY_CNN,\n","    dec_test=dec_test,\n","    epsilon_values=epsilon_values,\n","    batch_size=2000\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jeh2-JpEOZr7","executionInfo":{"status":"ok","timestamp":1741406114824,"user_tz":300,"elapsed":1060371,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"2ce9c7a8-035f-4a51-ed88-06bdb018c176"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Analyzing epsilon: 1e-06\n","Batch 1/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 2/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 3/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 4/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 5/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 6/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 7/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 8/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 9/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 10/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 11/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 12/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 13/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 14/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 15/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 16/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 17/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 18/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 19/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 20/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 21/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 22/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 23/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 24/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 25/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 26/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 27/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 28/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 29/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 30/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 31/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 32/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 33/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 34/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 35/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 36/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 37/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 38/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 39/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 40/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 41/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 42/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 43/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 44/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 45/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 46/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 47/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 48/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 49/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 50/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 51/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 52/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 53/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 54/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 55/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 56/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 57/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 58/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 59/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 60/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 61/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 62/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 63/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 64/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 65/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 66/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 67/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 68/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 69/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","\n","Analyzing epsilon: 1e-05\n","Batch 1/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 2/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 3/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 4/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 5/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 6/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 7/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 8/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 9/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 10/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 11/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 12/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 13/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 14/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 15/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 16/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 17/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 18/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 19/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 20/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 21/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 22/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 23/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 24/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 25/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 26/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 27/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 28/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 29/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 30/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 31/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 32/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 33/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 34/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 35/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 36/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 37/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 38/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 39/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 40/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 41/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 42/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 43/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 44/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 45/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 46/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 47/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 48/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 49/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 50/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 51/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 52/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 53/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 54/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 55/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 56/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 57/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 58/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 59/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 60/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 61/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 62/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 63/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 64/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 65/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 66/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 67/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 68/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 69/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","\n","Analyzing epsilon: 0.0001\n","Batch 1/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 2/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 3/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 4/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 5/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 6/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 7/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 8/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 9/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 10/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 11/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 12/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 13/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 14/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 15/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 16/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 17/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 18/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 19/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 20/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 21/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 22/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 23/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 24/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 25/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 26/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 27/69 - PGD volume: 0.000100, FGSM volume: 0.000446\n","Batch 28/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 29/69 - PGD volume: 0.000100, FGSM volume: 0.000446\n","Batch 30/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 31/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 32/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 33/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 34/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 35/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 36/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 37/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 38/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 39/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 40/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 41/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 42/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 43/69 - PGD volume: 0.000100, FGSM volume: 0.000446\n","Batch 44/69 - PGD volume: 0.000100, FGSM volume: 0.000446\n","Batch 45/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 46/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 47/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 48/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 49/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 50/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 51/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 52/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 53/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 54/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 55/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 56/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 57/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 58/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 59/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 60/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 61/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 62/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 63/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 64/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 65/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 66/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 67/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 68/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 69/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","\n","Analyzing epsilon: 0.001\n","Batch 1/69 - PGD volume: 0.001000, FGSM volume: 0.004379\n","Batch 2/69 - PGD volume: 0.001000, FGSM volume: 0.004449\n","Batch 3/69 - PGD volume: 0.001000, FGSM volume: 0.004467\n","Batch 4/69 - PGD volume: 0.001000, FGSM volume: 0.004464\n","Batch 5/69 - PGD volume: 0.001000, FGSM volume: 0.004472\n","Batch 6/69 - PGD volume: 0.001000, FGSM volume: 0.004471\n","Batch 7/69 - PGD volume: 0.001000, FGSM volume: 0.004468\n","Batch 8/69 - PGD volume: 0.001000, FGSM volume: 0.004467\n","Batch 9/69 - PGD volume: 0.001000, FGSM volume: 0.004468\n","Batch 10/69 - PGD volume: 0.001000, FGSM volume: 0.004471\n","Batch 11/69 - PGD volume: 0.001000, FGSM volume: 0.004464\n","Batch 12/69 - PGD volume: 0.001000, FGSM volume: 0.004464\n","Batch 13/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 14/69 - PGD volume: 0.001000, FGSM volume: 0.004464\n","Batch 15/69 - PGD volume: 0.001000, FGSM volume: 0.004464\n","Batch 16/69 - PGD volume: 0.001000, FGSM volume: 0.004467\n","Batch 17/69 - PGD volume: 0.001000, FGSM volume: 0.004454\n","Batch 18/69 - PGD volume: 0.001000, FGSM volume: 0.004460\n","Batch 19/69 - PGD volume: 0.001000, FGSM volume: 0.004462\n","Batch 20/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 21/69 - PGD volume: 0.001000, FGSM volume: 0.004456\n","Batch 22/69 - PGD volume: 0.001000, FGSM volume: 0.004431\n","Batch 23/69 - PGD volume: 0.001000, FGSM volume: 0.004452\n","Batch 24/69 - PGD volume: 0.001000, FGSM volume: 0.004446\n","Batch 25/69 - PGD volume: 0.001000, FGSM volume: 0.004439\n","Batch 26/69 - PGD volume: 0.001000, FGSM volume: 0.004457\n","Batch 27/69 - PGD volume: 0.001000, FGSM volume: 0.004450\n","Batch 28/69 - PGD volume: 0.001000, FGSM volume: 0.004431\n","Batch 29/69 - PGD volume: 0.001000, FGSM volume: 0.004409\n","Batch 30/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 31/69 - PGD volume: 0.001000, FGSM volume: 0.004467\n","Batch 32/69 - PGD volume: 0.001000, FGSM volume: 0.004467\n","Batch 33/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 34/69 - PGD volume: 0.001000, FGSM volume: 0.004468\n","Batch 35/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 36/69 - PGD volume: 0.001000, FGSM volume: 0.004455\n","Batch 37/69 - PGD volume: 0.001000, FGSM volume: 0.004453\n","Batch 38/69 - PGD volume: 0.001000, FGSM volume: 0.004468\n","Batch 39/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 40/69 - PGD volume: 0.001000, FGSM volume: 0.004465\n","Batch 41/69 - PGD volume: 0.001000, FGSM volume: 0.004470\n","Batch 42/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 43/69 - PGD volume: 0.001000, FGSM volume: 0.004453\n","Batch 44/69 - PGD volume: 0.001000, FGSM volume: 0.004456\n","Batch 45/69 - PGD volume: 0.001000, FGSM volume: 0.004447\n","Batch 46/69 - PGD volume: 0.001000, FGSM volume: 0.004452\n","Batch 47/69 - PGD volume: 0.001000, FGSM volume: 0.004452\n","Batch 48/69 - PGD volume: 0.001000, FGSM volume: 0.004432\n","Batch 49/69 - PGD volume: 0.001000, FGSM volume: 0.004436\n","Batch 50/69 - PGD volume: 0.001000, FGSM volume: 0.004422\n","Batch 51/69 - PGD volume: 0.001000, FGSM volume: 0.004453\n","Batch 52/69 - PGD volume: 0.001000, FGSM volume: 0.004442\n","Batch 53/69 - PGD volume: 0.001000, FGSM volume: 0.004457\n","Batch 54/69 - PGD volume: 0.001000, FGSM volume: 0.004452\n","Batch 55/69 - PGD volume: 0.001000, FGSM volume: 0.004403\n","Batch 56/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 57/69 - PGD volume: 0.001000, FGSM volume: 0.004468\n","Batch 58/69 - PGD volume: 0.001000, FGSM volume: 0.004470\n","Batch 59/69 - PGD volume: 0.001000, FGSM volume: 0.004470\n","Batch 60/69 - PGD volume: 0.001000, FGSM volume: 0.004471\n","Batch 61/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 62/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 63/69 - PGD volume: 0.001000, FGSM volume: 0.004461\n","Batch 64/69 - PGD volume: 0.001000, FGSM volume: 0.004453\n","Batch 65/69 - PGD volume: 0.001000, FGSM volume: 0.004455\n","Batch 66/69 - PGD volume: 0.001000, FGSM volume: 0.004458\n","Batch 67/69 - PGD volume: 0.001000, FGSM volume: 0.004452\n","Batch 68/69 - PGD volume: 0.001000, FGSM volume: 0.004445\n","Batch 69/69 - PGD volume: 0.001000, FGSM volume: 0.004444\n","\n","PGD Attack Summary by Threshold:\n","\n","PGD Analysis Results:\n","\n","Epsilon: 1e-06\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.4482  15864.0000    0.5295\n","0.9000         198.1471  10552.0000    0.5970\n","0.9500         142.1723   5484.0000    0.6200\n","0.9900         136.2092   1258.0000    0.7154\n","\n","Epsilon: 1e-05\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.4482  15864.0000    0.5295\n","0.9000         198.1471  10552.0000    0.5970\n","0.9500         142.1723   5483.0000    0.6201\n","0.9900         136.2092   1258.0000    0.7154\n","\n","Epsilon: 0.0001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.4842  15864.0000    0.5295\n","0.9000         198.1988  10552.0000    0.5970\n","0.9500         142.1723   5483.0000    0.6201\n","0.9900         136.2092   1257.0000    0.7160\n","\n","Epsilon: 0.001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.2735  15854.0000    0.5235\n","0.9000         198.0155  10531.0000    0.5887\n","0.9500         142.1311   5479.0000    0.6206\n","0.9900         136.1992   1255.0000    0.7171\n","\n","FGSM Attack Summary by Threshold:\n","\n","FGSM Analysis Results:\n","\n","Epsilon: 1e-06\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.4411  15865.0000    0.5295\n","0.9000         198.1471  10551.0000    0.5971\n","0.9500         142.1723   5484.0000    0.6200\n","0.9900         136.2092   1258.0000    0.7154\n","\n","Epsilon: 1e-05\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.4482  15865.0000    0.5295\n","0.9000         198.1471  10552.0000    0.5970\n","0.9500         142.1723   5483.0000    0.6201\n","0.9900         136.2092   1257.0000    0.7160\n","\n","Epsilon: 0.0001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.3313  15856.0000    0.5235\n","0.9000         198.1039  10537.0000    0.5884\n","0.9500         142.1931   5478.0000    0.6207\n","0.9900         136.1992   1256.0000    0.7166\n","\n","Epsilon: 0.001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.4891  15747.0000    0.5207\n","0.9000         211.1410  10462.0000    0.5926\n","0.9500         142.2698   5431.0000    0.6260\n","0.9900         136.1318   1242.0000    0.6441\n"]}]},{"cell_type":"code","source":["\"\"\"TRADING STRATEGY AFTER ATTACK ON 4 EPSILON VALUES\"\"\"\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","def run_adversarial_trading_analysis(model, testX_CNN, testY_CNN, dec_test, epsilon_values, batch_size=2000):\n","    \"\"\"Run trading strategy analysis with adversarial attacks\"\"\"\n","    results_pgd = []\n","    results_fgsm = []\n","    thresholds = [0.85, 0.90, 0.95, 0.99]  # Explicit thresholds\n","\n","    # Define constants needed for PGD attack\n","    num_iterations = 5\n","    step_size = 0.01\n","\n","    def data_set(testX_CNN, start_idx, end_idx):\n","        \"\"\"Prepare the dataset by shifting\"\"\"\n","        shifted_testX_CNN = tf.concat([\n","            testX_CNN[start_idx:end_idx, 1:100, :, :],\n","            testX_CNN[start_idx:end_idx, 99:, :, :]\n","        ], axis=1)\n","        return tf.cast(shifted_testX_CNN, tf.float32)\n","\n","    def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","        \"\"\"Apply volume constraints to the images\"\"\"\n","        images = images.numpy()\n","        slices = [slice(None)] * images.ndim\n","        testX_CNN_batch = testX_CNN[start_idx:end_idx]\n","        for idx in range(images.shape[dimension]):\n","            slices[dimension] = idx\n","            images[tuple(slices)] = np.maximum(\n","                images[tuple(slices)],\n","                testX_CNN_batch[tuple(slices)]\n","            )\n","        return tf.convert_to_tensor(images, dtype=tf.float32)\n","\n","    def get_model_predictions(perturbed_images):\n","        \"\"\"Get model predictions with error handling\"\"\"\n","        try:\n","            with tf.device('/CPU:0'):\n","                predictions = model(perturbed_images, training=False)\n","                return predictions.numpy()\n","        except Exception as e:\n","            print(f\"Error in model prediction: {str(e)}\")\n","            return None\n","\n","    def fgsm_attack(images, labels, epsilon):\n","        \"\"\"Implement FGSM attack\"\"\"\n","        try:\n","            with tf.GradientTape() as tape:\n","                tape.watch(images)\n","                predictions = model(images, training=False)\n","                loss = tf.keras.losses.CategoricalCrossentropy()(labels, predictions)\n","\n","            gradient = tape.gradient(loss, images)\n","            signed_grad = tf.sign(gradient)\n","\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            perturbed_images = images + epsilon * signed_masked\n","            return tf.clip_by_value(perturbed_images, 0, 1)\n","        except Exception as e:\n","            print(f\"Error in FGSM attack: {str(e)}\")\n","            return None\n","\n","    def pgd_attack(images, labels, epsilon, test_data, start_idx, end_idx):\n","        \"\"\"Implement PGD attack with volume constraint\"\"\"\n","        perturbed_images = tf.identity(images)\n","\n","        for _ in range(num_iterations):\n","            # Gradient step\n","            with tf.GradientTape() as tape:\n","                tape.watch(perturbed_images)\n","                predictions = model(perturbed_images, training=False)\n","                loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","            gradient = tape.gradient(loss, perturbed_images)\n","            signed_grad = tf.sign(gradient)\n","\n","            # Apply masking to gradient\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            # Apply gradient step\n","            perturbed_images = perturbed_images + step_size * signed_masked\n","            perturbed_images = volume_constraint(perturbed_images, test_data, 2, start_idx, end_idx)\n","\n","        return perturbed_images\n","\n","    max_test_size = testX_CNN.shape[0]\n","    num_batches = max_test_size // batch_size\n","\n","    for epsilon in epsilon_values:\n","        print(f\"\\nAnalyzing epsilon: {epsilon}\")\n","\n","        pgd_predictions = []\n","        fgsm_predictions = []\n","\n","        for i in range(num_batches):\n","            start_idx = i * batch_size\n","            end_idx = min((i + 1) * batch_size, max_test_size)\n","\n","            try:\n","                # Prepare batch data\n","                batch_images = data_set(testX_CNN, start_idx, end_idx)\n","                batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","                batch_labels = testY_CNN[start_idx:end_idx]\n","\n","                # Generate adversarial examples\n","                perturbed_images_pgd = pgd_attack(batch_images, batch_labels, epsilon, testX_CNN, start_idx, end_idx)\n","                perturbed_images_fgsm = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","                if perturbed_images_pgd is not None and perturbed_images_fgsm is not None:\n","                    # Calculate perturbation volumes\n","                    pgd_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_pgd - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    fgsm_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_fgsm - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    print(f\"Batch {i+1}/{num_batches} - PGD volume: {pgd_volume:.6f}, FGSM volume: {fgsm_volume:.6f}\")\n","\n","                    # Get predictions\n","                    pgd_pred = get_model_predictions(perturbed_images_pgd)\n","                    fgsm_pred = get_model_predictions(perturbed_images_fgsm)\n","\n","                    if pgd_pred is not None:\n","                        pgd_predictions.append(pgd_pred)\n","                    if fgsm_pred is not None:\n","                        fgsm_predictions.append(fgsm_pred)\n","\n","            except Exception as e:\n","                print(f\"Error processing batch {i}: {str(e)}\")\n","                continue\n","\n","            tf.keras.backend.clear_session()\n","\n","        if pgd_predictions and fgsm_predictions:\n","            pgd_predictions = np.vstack(pgd_predictions)\n","            fgsm_predictions = np.vstack(fgsm_predictions)\n","\n","            # Process for each threshold\n","            for threshold in thresholds:\n","                # Process PGD results\n","                pgd_result = implement_fi2010_strategy(\n","                    predictions=pgd_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if pgd_result:\n","                    pgd_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'PGD'\n","                    })\n","                    results_pgd.append(pgd_result)\n","\n","                # Process FGSM results\n","                fgsm_result = implement_fi2010_strategy(\n","                    predictions=fgsm_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if fgsm_result:\n","                    fgsm_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'FGSM'\n","                    })\n","                    results_fgsm.append(fgsm_result)\n","\n","    # Create DataFrames\n","    pgd_df = pd.DataFrame(results_pgd) if results_pgd else pd.DataFrame()\n","    fgsm_df = pd.DataFrame(results_fgsm) if results_fgsm else pd.DataFrame()\n","\n","    # Display detailed summaries\n","    if not pgd_df.empty:\n","        print(\"\\nPGD Attack Summary by Threshold:\")\n","        summary_pgd = pgd_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        # Format the display\n","        pd.set_option('display.float_format', lambda x: '%.4f' % x)\n","        print(\"\\nPGD Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_pgd.loc[eps])\n","\n","    if not fgsm_df.empty:\n","        print(\"\\nFGSM Attack Summary by Threshold:\")\n","        summary_fgsm = fgsm_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        print(\"\\nFGSM Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_fgsm.loc[eps])\n","\n","    return pgd_df, fgsm_df\n","\n","def implement_fi2010_strategy(predictions, dec_data, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"Implementation of the FI-2010 trading strategy\"\"\"\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","    trades_info = []\n","    budget = 100\n","\n","    for i in range(k, min_length):\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax(predictions[i])\n","        max_prob = np.max(predictions[i])\n","\n","        if max_prob > prob_threshold and pred_class != 1:\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","            shares = budget / mid_prices[i]\n","\n","            if pred_class == 2:  # Long trade\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'profit': profit,\n","                    'correct': actual_direction == 1\n","                })\n","            elif pred_class == 0:  # Short trade\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'profit': profit,\n","                    'correct': actual_direction == -1\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","\n","epsilon_values = [0.01, 0.1, 1, 10]\n","results_pgd, results_fgsm = run_adversarial_trading_analysis(\n","    model=lstm1,\n","    testX_CNN=testX_CNN,\n","    testY_CNN=testY_CNN,\n","    dec_test=dec_test,\n","    epsilon_values=epsilon_values,\n","    batch_size=2000\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_FQtf31IPDMN","executionInfo":{"status":"ok","timestamp":1741407194214,"user_tz":300,"elapsed":1064315,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"92a6fb9a-25d8-43c6-efbb-7e39055fe197"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Analyzing epsilon: 0.01\n","Batch 1/69 - PGD volume: 0.010000, FGSM volume: 0.036342\n","Batch 2/69 - PGD volume: 0.010000, FGSM volume: 0.041033\n","Batch 3/69 - PGD volume: 0.010000, FGSM volume: 0.043224\n","Batch 4/69 - PGD volume: 0.010000, FGSM volume: 0.043019\n","Batch 5/69 - PGD volume: 0.010000, FGSM volume: 0.043311\n","Batch 6/69 - PGD volume: 0.010000, FGSM volume: 0.043550\n","Batch 7/69 - PGD volume: 0.010000, FGSM volume: 0.043877\n","Batch 8/69 - PGD volume: 0.010000, FGSM volume: 0.043716\n","Batch 9/69 - PGD volume: 0.010000, FGSM volume: 0.043738\n","Batch 10/69 - PGD volume: 0.010000, FGSM volume: 0.044075\n","Batch 11/69 - PGD volume: 0.010000, FGSM volume: 0.042978\n","Batch 12/69 - PGD volume: 0.010000, FGSM volume: 0.043240\n","Batch 13/69 - PGD volume: 0.010000, FGSM volume: 0.042860\n","Batch 14/69 - PGD volume: 0.010000, FGSM volume: 0.043305\n","Batch 15/69 - PGD volume: 0.010000, FGSM volume: 0.043280\n","Batch 16/69 - PGD volume: 0.010000, FGSM volume: 0.043839\n","Batch 17/69 - PGD volume: 0.010000, FGSM volume: 0.040293\n","Batch 18/69 - PGD volume: 0.010000, FGSM volume: 0.036332\n","Batch 19/69 - PGD volume: 0.010000, FGSM volume: 0.036295\n","Batch 20/69 - PGD volume: 0.010000, FGSM volume: 0.035942\n","Batch 21/69 - PGD volume: 0.010000, FGSM volume: 0.037249\n","Batch 22/69 - PGD volume: 0.010000, FGSM volume: 0.036427\n","Batch 23/69 - PGD volume: 0.010000, FGSM volume: 0.036117\n","Batch 24/69 - PGD volume: 0.010000, FGSM volume: 0.037788\n","Batch 25/69 - PGD volume: 0.010000, FGSM volume: 0.037742\n","Batch 26/69 - PGD volume: 0.010000, FGSM volume: 0.037770\n","Batch 27/69 - PGD volume: 0.010000, FGSM volume: 0.037037\n","Batch 28/69 - PGD volume: 0.010000, FGSM volume: 0.035888\n","Batch 29/69 - PGD volume: 0.010000, FGSM volume: 0.038751\n","Batch 30/69 - PGD volume: 0.010000, FGSM volume: 0.043444\n","Batch 31/69 - PGD volume: 0.010000, FGSM volume: 0.042700\n","Batch 32/69 - PGD volume: 0.010000, FGSM volume: 0.043129\n","Batch 33/69 - PGD volume: 0.010000, FGSM volume: 0.042624\n","Batch 34/69 - PGD volume: 0.010000, FGSM volume: 0.043936\n","Batch 35/69 - PGD volume: 0.010000, FGSM volume: 0.043968\n","Batch 36/69 - PGD volume: 0.010000, FGSM volume: 0.043907\n","Batch 37/69 - PGD volume: 0.010000, FGSM volume: 0.043495\n","Batch 38/69 - PGD volume: 0.010000, FGSM volume: 0.043793\n","Batch 39/69 - PGD volume: 0.010000, FGSM volume: 0.043560\n","Batch 40/69 - PGD volume: 0.010000, FGSM volume: 0.043253\n","Batch 41/69 - PGD volume: 0.010000, FGSM volume: 0.043642\n","Batch 42/69 - PGD volume: 0.010000, FGSM volume: 0.043656\n","Batch 43/69 - PGD volume: 0.010000, FGSM volume: 0.043284\n","Batch 44/69 - PGD volume: 0.010000, FGSM volume: 0.043339\n","Batch 45/69 - PGD volume: 0.010000, FGSM volume: 0.041084\n","Batch 46/69 - PGD volume: 0.010000, FGSM volume: 0.036227\n","Batch 47/69 - PGD volume: 0.010000, FGSM volume: 0.036413\n","Batch 48/69 - PGD volume: 0.010000, FGSM volume: 0.036904\n","Batch 49/69 - PGD volume: 0.010000, FGSM volume: 0.035883\n","Batch 50/69 - PGD volume: 0.010000, FGSM volume: 0.036525\n","Batch 51/69 - PGD volume: 0.010000, FGSM volume: 0.036623\n","Batch 52/69 - PGD volume: 0.010000, FGSM volume: 0.036954\n","Batch 53/69 - PGD volume: 0.010000, FGSM volume: 0.036244\n","Batch 54/69 - PGD volume: 0.010000, FGSM volume: 0.036590\n","Batch 55/69 - PGD volume: 0.010000, FGSM volume: 0.038364\n","Batch 56/69 - PGD volume: 0.010000, FGSM volume: 0.043535\n","Batch 57/69 - PGD volume: 0.010000, FGSM volume: 0.043562\n","Batch 58/69 - PGD volume: 0.010000, FGSM volume: 0.043793\n","Batch 59/69 - PGD volume: 0.010000, FGSM volume: 0.044064\n","Batch 60/69 - PGD volume: 0.010000, FGSM volume: 0.044189\n","Batch 61/69 - PGD volume: 0.010000, FGSM volume: 0.043578\n","Batch 62/69 - PGD volume: 0.010000, FGSM volume: 0.043511\n","Batch 63/69 - PGD volume: 0.010000, FGSM volume: 0.043654\n","Batch 64/69 - PGD volume: 0.010000, FGSM volume: 0.036391\n","Batch 65/69 - PGD volume: 0.010000, FGSM volume: 0.037035\n","Batch 66/69 - PGD volume: 0.010000, FGSM volume: 0.036480\n","Batch 67/69 - PGD volume: 0.010000, FGSM volume: 0.036769\n","Batch 68/69 - PGD volume: 0.010000, FGSM volume: 0.036257\n","Batch 69/69 - PGD volume: 0.010000, FGSM volume: 0.036659\n","\n","Analyzing epsilon: 0.1\n","Batch 1/69 - PGD volume: 0.100000, FGSM volume: 0.313888\n","Batch 2/69 - PGD volume: 0.100000, FGSM volume: 0.333991\n","Batch 3/69 - PGD volume: 0.100000, FGSM volume: 0.338700\n","Batch 4/69 - PGD volume: 0.100000, FGSM volume: 0.342346\n","Batch 5/69 - PGD volume: 0.100000, FGSM volume: 0.335156\n","Batch 6/69 - PGD volume: 0.100000, FGSM volume: 0.338567\n","Batch 7/69 - PGD volume: 0.100000, FGSM volume: 0.344333\n","Batch 8/69 - PGD volume: 0.100000, FGSM volume: 0.340054\n","Batch 9/69 - PGD volume: 0.100000, FGSM volume: 0.340704\n","Batch 10/69 - PGD volume: 0.100000, FGSM volume: 0.342763\n","Batch 11/69 - PGD volume: 0.100000, FGSM volume: 0.333083\n","Batch 12/69 - PGD volume: 0.100000, FGSM volume: 0.335524\n","Batch 13/69 - PGD volume: 0.100000, FGSM volume: 0.328169\n","Batch 14/69 - PGD volume: 0.100000, FGSM volume: 0.336952\n","Batch 15/69 - PGD volume: 0.100000, FGSM volume: 0.334755\n","Batch 16/69 - PGD volume: 0.100000, FGSM volume: 0.334547\n","Batch 17/69 - PGD volume: 0.100000, FGSM volume: 0.323204\n","Batch 18/69 - PGD volume: 0.100000, FGSM volume: 0.318910\n","Batch 19/69 - PGD volume: 0.100000, FGSM volume: 0.316348\n","Batch 20/69 - PGD volume: 0.100000, FGSM volume: 0.318480\n","Batch 21/69 - PGD volume: 0.100000, FGSM volume: 0.323021\n","Batch 22/69 - PGD volume: 0.100000, FGSM volume: 0.318896\n","Batch 23/69 - PGD volume: 0.100000, FGSM volume: 0.319258\n","Batch 24/69 - PGD volume: 0.100000, FGSM volume: 0.318972\n","Batch 25/69 - PGD volume: 0.100000, FGSM volume: 0.320665\n","Batch 26/69 - PGD volume: 0.100000, FGSM volume: 0.320124\n","Batch 27/69 - PGD volume: 0.100000, FGSM volume: 0.321132\n","Batch 28/69 - PGD volume: 0.100000, FGSM volume: 0.318124\n","Batch 29/69 - PGD volume: 0.100000, FGSM volume: 0.326934\n","Batch 30/69 - PGD volume: 0.100000, FGSM volume: 0.342120\n","Batch 31/69 - PGD volume: 0.100000, FGSM volume: 0.338213\n","Batch 32/69 - PGD volume: 0.100000, FGSM volume: 0.336837\n","Batch 33/69 - PGD volume: 0.100000, FGSM volume: 0.337460\n","Batch 34/69 - PGD volume: 0.100000, FGSM volume: 0.339021\n","Batch 35/69 - PGD volume: 0.100000, FGSM volume: 0.343594\n","Batch 36/69 - PGD volume: 0.100000, FGSM volume: 0.345223\n","Batch 37/69 - PGD volume: 0.100000, FGSM volume: 0.342922\n","Batch 38/69 - PGD volume: 0.100000, FGSM volume: 0.336303\n","Batch 39/69 - PGD volume: 0.100000, FGSM volume: 0.341944\n","Batch 40/69 - PGD volume: 0.100000, FGSM volume: 0.338359\n","Batch 41/69 - PGD volume: 0.100000, FGSM volume: 0.338362\n","Batch 42/69 - PGD volume: 0.100000, FGSM volume: 0.339396\n","Batch 43/69 - PGD volume: 0.100000, FGSM volume: 0.338820\n","Batch 44/69 - PGD volume: 0.100000, FGSM volume: 0.336080\n","Batch 45/69 - PGD volume: 0.100000, FGSM volume: 0.330879\n","Batch 46/69 - PGD volume: 0.100000, FGSM volume: 0.320046\n","Batch 47/69 - PGD volume: 0.100000, FGSM volume: 0.318610\n","Batch 48/69 - PGD volume: 0.100000, FGSM volume: 0.318948\n","Batch 49/69 - PGD volume: 0.100000, FGSM volume: 0.319463\n","Batch 50/69 - PGD volume: 0.100000, FGSM volume: 0.322417\n","Batch 51/69 - PGD volume: 0.100000, FGSM volume: 0.319592\n","Batch 52/69 - PGD volume: 0.100000, FGSM volume: 0.323928\n","Batch 53/69 - PGD volume: 0.100000, FGSM volume: 0.319469\n","Batch 54/69 - PGD volume: 0.100000, FGSM volume: 0.318980\n","Batch 55/69 - PGD volume: 0.100000, FGSM volume: 0.320582\n","Batch 56/69 - PGD volume: 0.100000, FGSM volume: 0.339430\n","Batch 57/69 - PGD volume: 0.100000, FGSM volume: 0.345530\n","Batch 58/69 - PGD volume: 0.100000, FGSM volume: 0.348366\n","Batch 59/69 - PGD volume: 0.100000, FGSM volume: 0.344201\n","Batch 60/69 - PGD volume: 0.100000, FGSM volume: 0.354400\n","Batch 61/69 - PGD volume: 0.100000, FGSM volume: 0.334951\n","Batch 62/69 - PGD volume: 0.100000, FGSM volume: 0.336031\n","Batch 63/69 - PGD volume: 0.100000, FGSM volume: 0.332594\n","Batch 64/69 - PGD volume: 0.100000, FGSM volume: 0.314543\n","Batch 65/69 - PGD volume: 0.100000, FGSM volume: 0.318571\n","Batch 66/69 - PGD volume: 0.100000, FGSM volume: 0.315907\n","Batch 67/69 - PGD volume: 0.100000, FGSM volume: 0.319028\n","Batch 68/69 - PGD volume: 0.100000, FGSM volume: 0.319503\n","Batch 69/69 - PGD volume: 0.100000, FGSM volume: 0.316577\n","\n","Analyzing epsilon: 1\n","Batch 1/69 - PGD volume: 0.156753, FGSM volume: 3.114046\n","Batch 2/69 - PGD volume: 0.156911, FGSM volume: 3.072906\n","Batch 3/69 - PGD volume: 0.157842, FGSM volume: 3.086113\n","Batch 4/69 - PGD volume: 0.157932, FGSM volume: 3.079908\n","Batch 5/69 - PGD volume: 0.157321, FGSM volume: 3.081107\n","Batch 6/69 - PGD volume: 0.157061, FGSM volume: 3.071853\n","Batch 7/69 - PGD volume: 0.157118, FGSM volume: 3.047619\n","Batch 8/69 - PGD volume: 0.157678, FGSM volume: 3.073350\n","Batch 9/69 - PGD volume: 0.156780, FGSM volume: 3.066442\n","Batch 10/69 - PGD volume: 0.157839, FGSM volume: 3.078752\n","Batch 11/69 - PGD volume: 0.158215, FGSM volume: 3.097337\n","Batch 12/69 - PGD volume: 0.158660, FGSM volume: 3.104633\n","Batch 13/69 - PGD volume: 0.155778, FGSM volume: 3.058929\n","Batch 14/69 - PGD volume: 0.158471, FGSM volume: 3.106671\n","Batch 15/69 - PGD volume: 0.158034, FGSM volume: 3.105186\n","Batch 16/69 - PGD volume: 0.158959, FGSM volume: 3.121763\n","Batch 17/69 - PGD volume: 0.156626, FGSM volume: 3.092326\n","Batch 18/69 - PGD volume: 0.158394, FGSM volume: 3.162253\n","Batch 19/69 - PGD volume: 0.156161, FGSM volume: 3.139780\n","Batch 20/69 - PGD volume: 0.156102, FGSM volume: 3.164906\n","Batch 21/69 - PGD volume: 0.158171, FGSM volume: 3.202420\n","Batch 22/69 - PGD volume: 0.157099, FGSM volume: 3.163519\n","Batch 23/69 - PGD volume: 0.156862, FGSM volume: 3.171399\n","Batch 24/69 - PGD volume: 0.156652, FGSM volume: 3.154103\n","Batch 25/69 - PGD volume: 0.157940, FGSM volume: 3.174036\n","Batch 26/69 - PGD volume: 0.156882, FGSM volume: 3.163788\n","Batch 27/69 - PGD volume: 0.157315, FGSM volume: 3.186251\n","Batch 28/69 - PGD volume: 0.158082, FGSM volume: 3.158421\n","Batch 29/69 - PGD volume: 0.158653, FGSM volume: 3.123480\n","Batch 30/69 - PGD volume: 0.158149, FGSM volume: 3.072832\n","Batch 31/69 - PGD volume: 0.159252, FGSM volume: 3.112999\n","Batch 32/69 - PGD volume: 0.158149, FGSM volume: 3.090416\n","Batch 33/69 - PGD volume: 0.157953, FGSM volume: 3.090789\n","Batch 34/69 - PGD volume: 0.157956, FGSM volume: 3.073530\n","Batch 35/69 - PGD volume: 0.158278, FGSM volume: 3.070379\n","Batch 36/69 - PGD volume: 0.158373, FGSM volume: 3.089037\n","Batch 37/69 - PGD volume: 0.158082, FGSM volume: 3.079071\n","Batch 38/69 - PGD volume: 0.157919, FGSM volume: 3.080396\n","Batch 39/69 - PGD volume: 0.156975, FGSM volume: 3.050581\n","Batch 40/69 - PGD volume: 0.158060, FGSM volume: 3.095143\n","Batch 41/69 - PGD volume: 0.157201, FGSM volume: 3.092792\n","Batch 42/69 - PGD volume: 0.158708, FGSM volume: 3.102569\n","Batch 43/69 - PGD volume: 0.157923, FGSM volume: 3.098156\n","Batch 44/69 - PGD volume: 0.157711, FGSM volume: 3.090482\n","Batch 45/69 - PGD volume: 0.158105, FGSM volume: 3.116993\n","Batch 46/69 - PGD volume: 0.159131, FGSM volume: 3.174717\n","Batch 47/69 - PGD volume: 0.158060, FGSM volume: 3.160091\n","Batch 48/69 - PGD volume: 0.156906, FGSM volume: 3.162508\n","Batch 49/69 - PGD volume: 0.157740, FGSM volume: 3.171205\n","Batch 50/69 - PGD volume: 0.159448, FGSM volume: 3.199676\n","Batch 51/69 - PGD volume: 0.157809, FGSM volume: 3.166770\n","Batch 52/69 - PGD volume: 0.159027, FGSM volume: 3.212652\n","Batch 53/69 - PGD volume: 0.155456, FGSM volume: 3.171040\n","Batch 54/69 - PGD volume: 0.158017, FGSM volume: 3.162129\n","Batch 55/69 - PGD volume: 0.156795, FGSM volume: 3.099363\n","Batch 56/69 - PGD volume: 0.157270, FGSM volume: 3.059296\n","Batch 57/69 - PGD volume: 0.157974, FGSM volume: 3.060936\n","Batch 58/69 - PGD volume: 0.157135, FGSM volume: 3.051447\n","Batch 59/69 - PGD volume: 0.157023, FGSM volume: 3.042101\n","Batch 60/69 - PGD volume: 0.157936, FGSM volume: 3.047028\n","Batch 61/69 - PGD volume: 0.157032, FGSM volume: 3.062531\n","Batch 62/69 - PGD volume: 0.158024, FGSM volume: 3.082594\n","Batch 63/69 - PGD volume: 0.156432, FGSM volume: 3.066476\n","Batch 64/69 - PGD volume: 0.155414, FGSM volume: 3.098600\n","Batch 65/69 - PGD volume: 0.157746, FGSM volume: 3.154652\n","Batch 66/69 - PGD volume: 0.156598, FGSM volume: 3.124390\n","Batch 67/69 - PGD volume: 0.157269, FGSM volume: 3.163013\n","Batch 68/69 - PGD volume: 0.156789, FGSM volume: 3.173988\n","Batch 69/69 - PGD volume: 0.155899, FGSM volume: 3.137770\n","\n","Analyzing epsilon: 10\n","Batch 1/69 - PGD volume: 0.156753, FGSM volume: 3.114046\n","Batch 2/69 - PGD volume: 0.156911, FGSM volume: 3.072906\n","Batch 3/69 - PGD volume: 0.157842, FGSM volume: 3.086113\n","Batch 4/69 - PGD volume: 0.157932, FGSM volume: 3.079908\n","Batch 5/69 - PGD volume: 0.157321, FGSM volume: 3.081107\n","Batch 6/69 - PGD volume: 0.157061, FGSM volume: 3.071853\n","Batch 7/69 - PGD volume: 0.157118, FGSM volume: 3.047619\n","Batch 8/69 - PGD volume: 0.157678, FGSM volume: 3.073350\n","Batch 9/69 - PGD volume: 0.156780, FGSM volume: 3.066442\n","Batch 10/69 - PGD volume: 0.157839, FGSM volume: 3.078752\n","Batch 11/69 - PGD volume: 0.158215, FGSM volume: 3.097337\n","Batch 12/69 - PGD volume: 0.158660, FGSM volume: 3.104633\n","Batch 13/69 - PGD volume: 0.155778, FGSM volume: 3.058929\n","Batch 14/69 - PGD volume: 0.158471, FGSM volume: 3.106671\n","Batch 15/69 - PGD volume: 0.158034, FGSM volume: 3.105186\n","Batch 16/69 - PGD volume: 0.158959, FGSM volume: 3.121763\n","Batch 17/69 - PGD volume: 0.156626, FGSM volume: 3.092326\n","Batch 18/69 - PGD volume: 0.158394, FGSM volume: 3.162253\n","Batch 19/69 - PGD volume: 0.156161, FGSM volume: 3.139780\n","Batch 20/69 - PGD volume: 0.156102, FGSM volume: 3.164906\n","Batch 21/69 - PGD volume: 0.158171, FGSM volume: 3.202420\n","Batch 22/69 - PGD volume: 0.157099, FGSM volume: 3.163519\n","Batch 23/69 - PGD volume: 0.156862, FGSM volume: 3.171399\n","Batch 24/69 - PGD volume: 0.156652, FGSM volume: 3.154103\n","Batch 25/69 - PGD volume: 0.157940, FGSM volume: 3.174036\n","Batch 26/69 - PGD volume: 0.156882, FGSM volume: 3.163788\n","Batch 27/69 - PGD volume: 0.157315, FGSM volume: 3.186251\n","Batch 28/69 - PGD volume: 0.158082, FGSM volume: 3.158421\n","Batch 29/69 - PGD volume: 0.158653, FGSM volume: 3.123480\n","Batch 30/69 - PGD volume: 0.158149, FGSM volume: 3.072832\n","Batch 31/69 - PGD volume: 0.159252, FGSM volume: 3.112999\n","Batch 32/69 - PGD volume: 0.158149, FGSM volume: 3.090416\n","Batch 33/69 - PGD volume: 0.157953, FGSM volume: 3.090789\n","Batch 34/69 - PGD volume: 0.157956, FGSM volume: 3.073530\n","Batch 35/69 - PGD volume: 0.158278, FGSM volume: 3.070379\n","Batch 36/69 - PGD volume: 0.158373, FGSM volume: 3.089037\n","Batch 37/69 - PGD volume: 0.158082, FGSM volume: 3.079071\n","Batch 38/69 - PGD volume: 0.157919, FGSM volume: 3.080396\n","Batch 39/69 - PGD volume: 0.156975, FGSM volume: 3.050581\n","Batch 40/69 - PGD volume: 0.158060, FGSM volume: 3.095143\n","Batch 41/69 - PGD volume: 0.157201, FGSM volume: 3.092792\n","Batch 42/69 - PGD volume: 0.158708, FGSM volume: 3.102569\n","Batch 43/69 - PGD volume: 0.157923, FGSM volume: 3.098156\n","Batch 44/69 - PGD volume: 0.157711, FGSM volume: 3.090482\n","Batch 45/69 - PGD volume: 0.158105, FGSM volume: 3.116993\n","Batch 46/69 - PGD volume: 0.159131, FGSM volume: 3.174717\n","Batch 47/69 - PGD volume: 0.158060, FGSM volume: 3.160091\n","Batch 48/69 - PGD volume: 0.156906, FGSM volume: 3.162508\n","Batch 49/69 - PGD volume: 0.157740, FGSM volume: 3.171205\n","Batch 50/69 - PGD volume: 0.159448, FGSM volume: 3.199676\n","Batch 51/69 - PGD volume: 0.157809, FGSM volume: 3.166770\n","Batch 52/69 - PGD volume: 0.159027, FGSM volume: 3.212652\n","Batch 53/69 - PGD volume: 0.155456, FGSM volume: 3.171040\n","Batch 54/69 - PGD volume: 0.158017, FGSM volume: 3.162129\n","Batch 55/69 - PGD volume: 0.156795, FGSM volume: 3.099363\n","Batch 56/69 - PGD volume: 0.157270, FGSM volume: 3.059296\n","Batch 57/69 - PGD volume: 0.157974, FGSM volume: 3.060936\n","Batch 58/69 - PGD volume: 0.157135, FGSM volume: 3.051447\n","Batch 59/69 - PGD volume: 0.157023, FGSM volume: 3.042101\n","Batch 60/69 - PGD volume: 0.157936, FGSM volume: 3.047028\n","Batch 61/69 - PGD volume: 0.157032, FGSM volume: 3.062531\n","Batch 62/69 - PGD volume: 0.158024, FGSM volume: 3.082594\n","Batch 63/69 - PGD volume: 0.156432, FGSM volume: 3.066476\n","Batch 64/69 - PGD volume: 0.155414, FGSM volume: 3.098600\n","Batch 65/69 - PGD volume: 0.157746, FGSM volume: 3.154652\n","Batch 66/69 - PGD volume: 0.156598, FGSM volume: 3.124390\n","Batch 67/69 - PGD volume: 0.157269, FGSM volume: 3.163013\n","Batch 68/69 - PGD volume: 0.156789, FGSM volume: 3.173988\n","Batch 69/69 - PGD volume: 0.155899, FGSM volume: 3.137770\n","\n","PGD Attack Summary by Threshold:\n","\n","PGD Analysis Results:\n","\n","Epsilon: 0.01\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         183.5071  15692.0000    0.5289\n","0.9000         211.2517  10407.0000    0.5958\n","0.9500         142.1007   5402.0000    0.6294\n","0.9900         136.1861   1230.0000    0.6504\n","\n","Epsilon: 0.1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         186.9129  15172.0000    0.4548\n","0.9000         160.7971   9610.0000    0.5307\n","0.9500         136.2076   4783.0000    0.5854\n","0.9900         136.3254    996.0000    0.8032\n","\n","Epsilon: 1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         131.8152  15816.0000    0.4173\n","0.9000         119.1483   9737.0000    0.4211\n","0.9500         136.1326   4539.0000    0.5728\n","0.9900         135.8867    897.0000    0.8919\n","\n","Epsilon: 10\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         131.8152  15816.0000    0.4173\n","0.9000         119.1483   9737.0000    0.4211\n","0.9500         136.1326   4539.0000    0.5728\n","0.9900         135.8867    897.0000    0.8919\n","\n","FGSM Attack Summary by Threshold:\n","\n","FGSM Analysis Results:\n","\n","Epsilon: 0.01\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         159.4650  15154.0000    0.5015\n","0.9000         210.7582   9842.0000    0.5792\n","0.9500         135.6894   5013.0000    0.5984\n","0.9900         135.8504   1087.0000    0.7360\n","\n","Epsilon: 0.1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         195.0848  24734.0000    0.3275\n","0.9000         114.2052  14289.0000    0.3149\n","0.9500         114.3242   5677.0000    0.3171\n","0.9900          68.6404    644.0000    0.3106\n","\n","Epsilon: 1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500        -933.8847 115740.0000    0.3992\n","0.9000       -1041.1103 103626.0000    0.4092\n","0.9500         220.8593  74677.0000    0.4165\n","0.9900          58.7032  15679.0000    0.3125\n","\n","Epsilon: 10\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500        -933.8847 115740.0000    0.3992\n","0.9000       -1041.1103 103626.0000    0.4092\n","0.9500         220.8593  74677.0000    0.4165\n","0.9900          58.7032  15679.0000    0.3125\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3kymkYFQPci-"},"execution_count":null,"outputs":[]}]}