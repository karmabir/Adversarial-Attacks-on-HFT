{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyN1qlOvvDe/BWLfiDMO3qgL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"wHga8P3MV2Nh","executionInfo":{"status":"ok","timestamp":1741407380889,"user_tz":300,"elapsed":3991,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}}},"outputs":[],"source":["import pandas as pd\n","import pickle\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","from keras import backend as K\n","from keras.models import load_model, Model\n","from keras.layers import Flatten, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.layers import LeakyReLU\n","#!pip install np_utils\n","from keras import utils\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# set random seeds\n","\n","# removed the import statement for set_session from tensorflow.compat.v1.keras.backend\n","np.random.seed(1)\n","tf.random.set_seed(2)\n","\n","# limit gpu usage for keras with tensorflow 1\n","# config = tf.compat.v1.ConfigProto()\n","# config.gpu_options.allow_growth = True\n","# set_session(tf.compat.v1.Session(config=config))\n","\n","# If you need to use set_session, try this instead:\n","# from tensorflow.python.keras.backend import set_session"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9yYeWZfWIxB","executionInfo":{"status":"ok","timestamp":1741407395577,"user_tz":300,"elapsed":14683,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"4c8a9ff1-e4b0-4ac6-8385-43da49ea9ac9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","if not os.path.isfile('/content/drive/MyDrive/LOBCNN/data/data.zip'):\n","    !wget https://raw.githubusercontent.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/master/data/data.zip\n","    !unzip -n data.zip\n","    print('data downloaded.')\n","else:\n","    print('data already existed.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2mHh6jYWOH_","executionInfo":{"status":"ok","timestamp":1741407395650,"user_tz":300,"elapsed":70,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"60aeb39c-b3e5-4312-889a-89758deb4310"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["data already existed.\n"]}]},{"cell_type":"code","source":["def prepare_x(data):\n","    df1 = data[:40, :].T\n","    return np.array(df1)\n","\n","def get_label(data):\n","    lob = data[-5:, :].T\n","    return lob\n","\n","def data_classification(X, Y, T):\n","    [N, D] = X.shape\n","    df = np.array(X)\n","    dY = np.array(Y)\n","    dataY = dY[T - 1:N]\n","    dataX = np.zeros((N - T + 1, T, D))\n","    for i in range(T, N + 1):\n","        dataX[i - T] = df[i - T:i, :]\n","    return dataX.reshape(dataX.shape + (1,)), dataY\n","\n","def prepare_x_y(data, k, T):\n","    x = prepare_x(data)\n","    y = get_label(data)\n","    x, y = data_classification(x, y, T=T)\n","    y = y[:,k] - 1\n","    y = utils.to_categorical(y, 3)\n","    return x, y"],"metadata":{"id":"psYqqTVDWSRu","executionInfo":{"status":"ok","timestamp":1741407395717,"user_tz":300,"elapsed":62,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dec_data = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Train_Dst_NoAuction_DecPre_CF_7.txt')\n","dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n","dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n","\n","dec_test1 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_7.txt')\n","dec_test2 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_8.txt')\n","dec_test3 = np.loadtxt('/content/drive/MyDrive/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books-master/data/data.zip (Unzipped Files)/Test_Dst_NoAuction_DecPre_CF_9.txt')\n","dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n","\n","k = 4 # which prediction horizon\n","T = 100 # the length of a single input\n","n_hiddens = 64\n","checkpoint_filepath = './model_tensorflow1_weights'\n","\n","trainX_CNN, trainY_CNN = prepare_x_y(dec_train, k, T)\n","valX_CNN, valY_CNN = prepare_x_y(dec_val, k, T)\n","testX_CNN, testY_CNN = prepare_x_y(dec_test, k, T)\n","\n","print(trainX_CNN.shape, trainY_CNN.shape)\n","print(valX_CNN.shape, valY_CNN.shape)\n","print(testX_CNN.shape, testY_CNN.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jx_NLoMwWTtY","executionInfo":{"status":"ok","timestamp":1741407415217,"user_tz":300,"elapsed":19498,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"feb7f2f8-72dd-4c07-8469-fe13a5f55e09"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(203701, 100, 40, 1) (203701, 3)\n","(50851, 100, 40, 1) (50851, 3)\n","(139488, 100, 40, 1) (139488, 3)\n"]}]},{"cell_type":"code","source":["from keras.models import Model\n","from keras.layers import Input, LSTM, Dense, Dropout\n","\n","def create_lstm2(T, NF, number_of_lstm):\n","    input_lmd = Input(shape=(T, NF))\n","\n","    # build the LSTM layer\n","    lstm_layer = LSTM(64)(input_lmd)\n","\n","    # apply dropout\n","    lstm_layer = Dropout(0.5)(lstm_layer, training=True)\n","\n","    # build the output layer\n","    out = Dense(3, activation='softmax')(lstm_layer)\n","\n","    model = Model(inputs=input_lmd, outputs=out)\n","    adam = keras.optimizers.Adam(learning_rate=0.00005) # Changed lr to learning_rate\n","    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Assuming trainX_CNN.shape[1] is T, trainX_CNN.shape[2] is NF, and n_hiddens is the number of LSTM units\n","lstm2 = create_lstm2(trainX_CNN.shape[1], trainX_CNN.shape[2], 64)\n","lstm2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"id":"NbujziZTWV6v","executionInfo":{"status":"ok","timestamp":1741407417585,"user_tz":300,"elapsed":1556,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"b0f38de1-3f35-41e5-f459-4454e0ff5064"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m26,880\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m195\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">26,880</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,075\u001b[0m (105.76 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,075</span> (105.76 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,075\u001b[0m (105.76 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,075</span> (105.76 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["%%time\n","\n","lstm2.fit(trainX_CNN, trainY_CNN, validation_data=(valX_CNN, valY_CNN),epochs=200, batch_size=128, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BSzrq4RWe1h","executionInfo":{"status":"ok","timestamp":1741409900775,"user_tz":300,"elapsed":2483159,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"51aec5e9-7922-46ae-9e96-c4a5d02e90b9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4107 - loss: 1.0538 - val_accuracy: 0.3723 - val_loss: 1.0897\n","Epoch 2/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4327 - loss: 1.0279 - val_accuracy: 0.3761 - val_loss: 1.0896\n","Epoch 3/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4450 - loss: 1.0224 - val_accuracy: 0.3704 - val_loss: 1.0882\n","Epoch 4/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4541 - loss: 1.0173 - val_accuracy: 0.3725 - val_loss: 1.0879\n","Epoch 5/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4660 - loss: 1.0120 - val_accuracy: 0.3726 - val_loss: 1.0882\n","Epoch 6/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4724 - loss: 1.0079 - val_accuracy: 0.3746 - val_loss: 1.0876\n","Epoch 7/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4796 - loss: 1.0046 - val_accuracy: 0.3842 - val_loss: 1.0872\n","Epoch 8/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4857 - loss: 1.0003 - val_accuracy: 0.3931 - val_loss: 1.0841\n","Epoch 9/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4912 - loss: 0.9972 - val_accuracy: 0.3961 - val_loss: 1.0837\n","Epoch 10/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4962 - loss: 0.9936 - val_accuracy: 0.3988 - val_loss: 1.0830\n","Epoch 11/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4995 - loss: 0.9907 - val_accuracy: 0.3993 - val_loss: 1.0830\n","Epoch 12/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5018 - loss: 0.9880 - val_accuracy: 0.3987 - val_loss: 1.0820\n","Epoch 13/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5049 - loss: 0.9850 - val_accuracy: 0.3966 - val_loss: 1.0830\n","Epoch 14/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5073 - loss: 0.9818 - val_accuracy: 0.3988 - val_loss: 1.0817\n","Epoch 15/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5093 - loss: 0.9796 - val_accuracy: 0.4011 - val_loss: 1.0811\n","Epoch 16/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5140 - loss: 0.9758 - val_accuracy: 0.3981 - val_loss: 1.0810\n","Epoch 17/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5150 - loss: 0.9732 - val_accuracy: 0.4034 - val_loss: 1.0787\n","Epoch 18/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5204 - loss: 0.9697 - val_accuracy: 0.4100 - val_loss: 1.0780\n","Epoch 19/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5205 - loss: 0.9671 - val_accuracy: 0.3995 - val_loss: 1.0814\n","Epoch 20/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5233 - loss: 0.9642 - val_accuracy: 0.4134 - val_loss: 1.0761\n","Epoch 21/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5263 - loss: 0.9618 - val_accuracy: 0.4107 - val_loss: 1.0754\n","Epoch 22/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5278 - loss: 0.9599 - val_accuracy: 0.4188 - val_loss: 1.0732\n","Epoch 23/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5315 - loss: 0.9563 - val_accuracy: 0.4128 - val_loss: 1.0738\n","Epoch 24/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5325 - loss: 0.9540 - val_accuracy: 0.4217 - val_loss: 1.0706\n","Epoch 25/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5350 - loss: 0.9513 - val_accuracy: 0.4145 - val_loss: 1.0741\n","Epoch 26/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5373 - loss: 0.9496 - val_accuracy: 0.4271 - val_loss: 1.0678\n","Epoch 27/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5376 - loss: 0.9476 - val_accuracy: 0.4112 - val_loss: 1.0757\n","Epoch 28/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5389 - loss: 0.9450 - val_accuracy: 0.4155 - val_loss: 1.0732\n","Epoch 29/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5411 - loss: 0.9438 - val_accuracy: 0.4086 - val_loss: 1.0754\n","Epoch 30/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5433 - loss: 0.9418 - val_accuracy: 0.4178 - val_loss: 1.0717\n","Epoch 31/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5441 - loss: 0.9402 - val_accuracy: 0.4246 - val_loss: 1.0690\n","Epoch 32/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5451 - loss: 0.9388 - val_accuracy: 0.4269 - val_loss: 1.0664\n","Epoch 33/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5468 - loss: 0.9370 - val_accuracy: 0.4200 - val_loss: 1.0704\n","Epoch 34/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5475 - loss: 0.9347 - val_accuracy: 0.4158 - val_loss: 1.0732\n","Epoch 35/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5476 - loss: 0.9334 - val_accuracy: 0.4233 - val_loss: 1.0683\n","Epoch 36/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5487 - loss: 0.9327 - val_accuracy: 0.4247 - val_loss: 1.0699\n","Epoch 37/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5495 - loss: 0.9300 - val_accuracy: 0.4238 - val_loss: 1.0696\n","Epoch 38/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5513 - loss: 0.9292 - val_accuracy: 0.4244 - val_loss: 1.0655\n","Epoch 39/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5530 - loss: 0.9275 - val_accuracy: 0.4350 - val_loss: 1.0632\n","Epoch 40/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5536 - loss: 0.9258 - val_accuracy: 0.4221 - val_loss: 1.0667\n","Epoch 41/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5541 - loss: 0.9247 - val_accuracy: 0.4295 - val_loss: 1.0620\n","Epoch 42/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5563 - loss: 0.9231 - val_accuracy: 0.4279 - val_loss: 1.0649\n","Epoch 43/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5568 - loss: 0.9219 - val_accuracy: 0.4293 - val_loss: 1.0623\n","Epoch 44/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5579 - loss: 0.9198 - val_accuracy: 0.4378 - val_loss: 1.0616\n","Epoch 45/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5587 - loss: 0.9183 - val_accuracy: 0.4295 - val_loss: 1.0622\n","Epoch 46/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5607 - loss: 0.9163 - val_accuracy: 0.4436 - val_loss: 1.0567\n","Epoch 47/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5609 - loss: 0.9148 - val_accuracy: 0.4408 - val_loss: 1.0584\n","Epoch 48/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5623 - loss: 0.9143 - val_accuracy: 0.4382 - val_loss: 1.0579\n","Epoch 49/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5638 - loss: 0.9126 - val_accuracy: 0.4390 - val_loss: 1.0592\n","Epoch 50/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5640 - loss: 0.9121 - val_accuracy: 0.4248 - val_loss: 1.0625\n","Epoch 51/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5648 - loss: 0.9109 - val_accuracy: 0.4284 - val_loss: 1.0617\n","Epoch 52/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5657 - loss: 0.9096 - val_accuracy: 0.4318 - val_loss: 1.0588\n","Epoch 53/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5664 - loss: 0.9078 - val_accuracy: 0.4276 - val_loss: 1.0610\n","Epoch 54/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5680 - loss: 0.9067 - val_accuracy: 0.4414 - val_loss: 1.0554\n","Epoch 55/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5692 - loss: 0.9046 - val_accuracy: 0.4376 - val_loss: 1.0575\n","Epoch 56/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5683 - loss: 0.9048 - val_accuracy: 0.4366 - val_loss: 1.0593\n","Epoch 57/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5713 - loss: 0.9029 - val_accuracy: 0.4461 - val_loss: 1.0559\n","Epoch 58/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5713 - loss: 0.9026 - val_accuracy: 0.4426 - val_loss: 1.0559\n","Epoch 59/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5731 - loss: 0.9009 - val_accuracy: 0.4414 - val_loss: 1.0561\n","Epoch 60/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5726 - loss: 0.9007 - val_accuracy: 0.4487 - val_loss: 1.0546\n","Epoch 61/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5739 - loss: 0.8983 - val_accuracy: 0.4397 - val_loss: 1.0562\n","Epoch 62/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5734 - loss: 0.8987 - val_accuracy: 0.4520 - val_loss: 1.0519\n","Epoch 63/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5745 - loss: 0.8968 - val_accuracy: 0.4462 - val_loss: 1.0559\n","Epoch 64/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5744 - loss: 0.8961 - val_accuracy: 0.4454 - val_loss: 1.0555\n","Epoch 65/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5779 - loss: 0.8954 - val_accuracy: 0.4510 - val_loss: 1.0524\n","Epoch 66/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5772 - loss: 0.8947 - val_accuracy: 0.4388 - val_loss: 1.0566\n","Epoch 67/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5763 - loss: 0.8944 - val_accuracy: 0.4479 - val_loss: 1.0528\n","Epoch 68/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5770 - loss: 0.8922 - val_accuracy: 0.4530 - val_loss: 1.0536\n","Epoch 69/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5796 - loss: 0.8912 - val_accuracy: 0.4449 - val_loss: 1.0549\n","Epoch 70/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5797 - loss: 0.8910 - val_accuracy: 0.4497 - val_loss: 1.0537\n","Epoch 71/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5803 - loss: 0.8892 - val_accuracy: 0.4493 - val_loss: 1.0535\n","Epoch 72/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5814 - loss: 0.8897 - val_accuracy: 0.4561 - val_loss: 1.0500\n","Epoch 73/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5804 - loss: 0.8872 - val_accuracy: 0.4541 - val_loss: 1.0510\n","Epoch 74/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5814 - loss: 0.8870 - val_accuracy: 0.4541 - val_loss: 1.0508\n","Epoch 75/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5828 - loss: 0.8863 - val_accuracy: 0.4549 - val_loss: 1.0511\n","Epoch 76/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5830 - loss: 0.8858 - val_accuracy: 0.4530 - val_loss: 1.0555\n","Epoch 77/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5824 - loss: 0.8866 - val_accuracy: 0.4554 - val_loss: 1.0508\n","Epoch 78/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5833 - loss: 0.8851 - val_accuracy: 0.4519 - val_loss: 1.0505\n","Epoch 79/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5845 - loss: 0.8839 - val_accuracy: 0.4499 - val_loss: 1.0516\n","Epoch 80/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5850 - loss: 0.8821 - val_accuracy: 0.4537 - val_loss: 1.0518\n","Epoch 81/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5870 - loss: 0.8819 - val_accuracy: 0.4570 - val_loss: 1.0491\n","Epoch 82/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5863 - loss: 0.8807 - val_accuracy: 0.4536 - val_loss: 1.0558\n","Epoch 83/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5870 - loss: 0.8806 - val_accuracy: 0.4636 - val_loss: 1.0471\n","Epoch 84/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5874 - loss: 0.8796 - val_accuracy: 0.4628 - val_loss: 1.0474\n","Epoch 85/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5876 - loss: 0.8797 - val_accuracy: 0.4565 - val_loss: 1.0511\n","Epoch 86/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5893 - loss: 0.8785 - val_accuracy: 0.4660 - val_loss: 1.0463\n","Epoch 87/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5903 - loss: 0.8770 - val_accuracy: 0.4594 - val_loss: 1.0499\n","Epoch 88/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5905 - loss: 0.8760 - val_accuracy: 0.4605 - val_loss: 1.0503\n","Epoch 89/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5901 - loss: 0.8766 - val_accuracy: 0.4583 - val_loss: 1.0498\n","Epoch 90/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5916 - loss: 0.8746 - val_accuracy: 0.4589 - val_loss: 1.0501\n","Epoch 91/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5915 - loss: 0.8732 - val_accuracy: 0.4572 - val_loss: 1.0506\n","Epoch 92/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5925 - loss: 0.8734 - val_accuracy: 0.4578 - val_loss: 1.0505\n","Epoch 93/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5941 - loss: 0.8727 - val_accuracy: 0.4624 - val_loss: 1.0475\n","Epoch 94/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5935 - loss: 0.8710 - val_accuracy: 0.4611 - val_loss: 1.0499\n","Epoch 95/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5934 - loss: 0.8713 - val_accuracy: 0.4586 - val_loss: 1.0489\n","Epoch 96/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5941 - loss: 0.8706 - val_accuracy: 0.4564 - val_loss: 1.0506\n","Epoch 97/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5953 - loss: 0.8705 - val_accuracy: 0.4544 - val_loss: 1.0527\n","Epoch 98/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5949 - loss: 0.8695 - val_accuracy: 0.4592 - val_loss: 1.0495\n","Epoch 99/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5944 - loss: 0.8685 - val_accuracy: 0.4622 - val_loss: 1.0493\n","Epoch 100/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5975 - loss: 0.8678 - val_accuracy: 0.4594 - val_loss: 1.0505\n","Epoch 101/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5981 - loss: 0.8675 - val_accuracy: 0.4609 - val_loss: 1.0517\n","Epoch 102/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5983 - loss: 0.8656 - val_accuracy: 0.4584 - val_loss: 1.0503\n","Epoch 103/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5970 - loss: 0.8656 - val_accuracy: 0.4540 - val_loss: 1.0530\n","Epoch 104/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6001 - loss: 0.8641 - val_accuracy: 0.4546 - val_loss: 1.0592\n","Epoch 105/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5987 - loss: 0.8651 - val_accuracy: 0.4584 - val_loss: 1.0505\n","Epoch 106/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6009 - loss: 0.8627 - val_accuracy: 0.4575 - val_loss: 1.0498\n","Epoch 107/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5998 - loss: 0.8632 - val_accuracy: 0.4551 - val_loss: 1.0593\n","Epoch 108/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6024 - loss: 0.8610 - val_accuracy: 0.4580 - val_loss: 1.0565\n","Epoch 109/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.6020 - loss: 0.8616 - val_accuracy: 0.4510 - val_loss: 1.0647\n","Epoch 110/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6025 - loss: 0.8618 - val_accuracy: 0.4616 - val_loss: 1.0503\n","Epoch 111/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6029 - loss: 0.8617 - val_accuracy: 0.4503 - val_loss: 1.0598\n","Epoch 112/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6040 - loss: 0.8591 - val_accuracy: 0.4568 - val_loss: 1.0546\n","Epoch 113/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6041 - loss: 0.8588 - val_accuracy: 0.4514 - val_loss: 1.0612\n","Epoch 114/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6046 - loss: 0.8574 - val_accuracy: 0.4648 - val_loss: 1.0487\n","Epoch 115/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6057 - loss: 0.8580 - val_accuracy: 0.4587 - val_loss: 1.0528\n","Epoch 116/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6050 - loss: 0.8565 - val_accuracy: 0.4609 - val_loss: 1.0508\n","Epoch 117/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6054 - loss: 0.8562 - val_accuracy: 0.4619 - val_loss: 1.0561\n","Epoch 118/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6050 - loss: 0.8556 - val_accuracy: 0.4628 - val_loss: 1.0515\n","Epoch 119/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6074 - loss: 0.8550 - val_accuracy: 0.4630 - val_loss: 1.0503\n","Epoch 120/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6091 - loss: 0.8549 - val_accuracy: 0.4596 - val_loss: 1.0571\n","Epoch 121/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6077 - loss: 0.8546 - val_accuracy: 0.4566 - val_loss: 1.0607\n","Epoch 122/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6083 - loss: 0.8528 - val_accuracy: 0.4586 - val_loss: 1.0575\n","Epoch 123/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6081 - loss: 0.8518 - val_accuracy: 0.4613 - val_loss: 1.0555\n","Epoch 124/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6094 - loss: 0.8527 - val_accuracy: 0.4636 - val_loss: 1.0463\n","Epoch 125/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6098 - loss: 0.8522 - val_accuracy: 0.4664 - val_loss: 1.0458\n","Epoch 126/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6089 - loss: 0.8515 - val_accuracy: 0.4605 - val_loss: 1.0482\n","Epoch 127/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6091 - loss: 0.8521 - val_accuracy: 0.4597 - val_loss: 1.0533\n","Epoch 128/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6100 - loss: 0.8501 - val_accuracy: 0.4535 - val_loss: 1.0609\n","Epoch 129/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6116 - loss: 0.8486 - val_accuracy: 0.4617 - val_loss: 1.0555\n","Epoch 130/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6123 - loss: 0.8481 - val_accuracy: 0.4619 - val_loss: 1.0576\n","Epoch 131/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6120 - loss: 0.8461 - val_accuracy: 0.4597 - val_loss: 1.0640\n","Epoch 132/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6131 - loss: 0.8463 - val_accuracy: 0.4593 - val_loss: 1.0568\n","Epoch 133/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6136 - loss: 0.8457 - val_accuracy: 0.4638 - val_loss: 1.0499\n","Epoch 134/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6141 - loss: 0.8453 - val_accuracy: 0.4617 - val_loss: 1.0537\n","Epoch 135/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6144 - loss: 0.8442 - val_accuracy: 0.4606 - val_loss: 1.0565\n","Epoch 136/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6150 - loss: 0.8440 - val_accuracy: 0.4522 - val_loss: 1.0639\n","Epoch 137/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6152 - loss: 0.8441 - val_accuracy: 0.4618 - val_loss: 1.0609\n","Epoch 138/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6152 - loss: 0.8430 - val_accuracy: 0.4593 - val_loss: 1.0519\n","Epoch 139/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6151 - loss: 0.8438 - val_accuracy: 0.4579 - val_loss: 1.0588\n","Epoch 140/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6150 - loss: 0.8431 - val_accuracy: 0.4608 - val_loss: 1.0562\n","Epoch 141/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6155 - loss: 0.8426 - val_accuracy: 0.4597 - val_loss: 1.0595\n","Epoch 142/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6170 - loss: 0.8419 - val_accuracy: 0.4555 - val_loss: 1.0616\n","Epoch 143/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6169 - loss: 0.8410 - val_accuracy: 0.4569 - val_loss: 1.0622\n","Epoch 144/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6165 - loss: 0.8438 - val_accuracy: 0.4604 - val_loss: 1.0567\n","Epoch 145/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6192 - loss: 0.8400 - val_accuracy: 0.4588 - val_loss: 1.0614\n","Epoch 146/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6178 - loss: 0.8392 - val_accuracy: 0.4537 - val_loss: 1.0638\n","Epoch 147/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6196 - loss: 0.8392 - val_accuracy: 0.4661 - val_loss: 1.0583\n","Epoch 148/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6187 - loss: 0.8377 - val_accuracy: 0.4578 - val_loss: 1.0520\n","Epoch 149/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6204 - loss: 0.8378 - val_accuracy: 0.4556 - val_loss: 1.0541\n","Epoch 150/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6190 - loss: 0.8387 - val_accuracy: 0.4627 - val_loss: 1.0598\n","Epoch 151/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6201 - loss: 0.8380 - val_accuracy: 0.4626 - val_loss: 1.0522\n","Epoch 152/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6195 - loss: 0.8377 - val_accuracy: 0.4576 - val_loss: 1.0627\n","Epoch 153/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6214 - loss: 0.8358 - val_accuracy: 0.4588 - val_loss: 1.0633\n","Epoch 154/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6223 - loss: 0.8343 - val_accuracy: 0.4636 - val_loss: 1.0544\n","Epoch 155/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6210 - loss: 0.8358 - val_accuracy: 0.4624 - val_loss: 1.0535\n","Epoch 156/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6231 - loss: 0.8339 - val_accuracy: 0.4592 - val_loss: 1.0578\n","Epoch 157/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6218 - loss: 0.8349 - val_accuracy: 0.4617 - val_loss: 1.0617\n","Epoch 158/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6222 - loss: 0.8337 - val_accuracy: 0.4610 - val_loss: 1.0581\n","Epoch 159/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.6226 - loss: 0.8343 - val_accuracy: 0.4649 - val_loss: 1.0545\n","Epoch 160/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.6231 - loss: 0.8326 - val_accuracy: 0.4645 - val_loss: 1.0559\n","Epoch 161/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6234 - loss: 0.8323 - val_accuracy: 0.4600 - val_loss: 1.0512\n","Epoch 162/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6229 - loss: 0.8320 - val_accuracy: 0.4652 - val_loss: 1.0597\n","Epoch 163/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6242 - loss: 0.8311 - val_accuracy: 0.4527 - val_loss: 1.0731\n","Epoch 164/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6234 - loss: 0.8311 - val_accuracy: 0.4597 - val_loss: 1.0602\n","Epoch 165/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6245 - loss: 0.8311 - val_accuracy: 0.4614 - val_loss: 1.0556\n","Epoch 166/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6241 - loss: 0.8294 - val_accuracy: 0.4575 - val_loss: 1.0696\n","Epoch 167/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6261 - loss: 0.8292 - val_accuracy: 0.4588 - val_loss: 1.0684\n","Epoch 168/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6261 - loss: 0.8287 - val_accuracy: 0.4618 - val_loss: 1.0598\n","Epoch 169/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6250 - loss: 0.8283 - val_accuracy: 0.4622 - val_loss: 1.0609\n","Epoch 170/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6257 - loss: 0.8280 - val_accuracy: 0.4460 - val_loss: 1.0906\n","Epoch 171/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6268 - loss: 0.8284 - val_accuracy: 0.4568 - val_loss: 1.0614\n","Epoch 172/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6267 - loss: 0.8267 - val_accuracy: 0.4538 - val_loss: 1.0735\n","Epoch 173/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6266 - loss: 0.8274 - val_accuracy: 0.4538 - val_loss: 1.0800\n","Epoch 174/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6269 - loss: 0.8283 - val_accuracy: 0.4590 - val_loss: 1.0673\n","Epoch 175/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6275 - loss: 0.8256 - val_accuracy: 0.4590 - val_loss: 1.0638\n","Epoch 176/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6287 - loss: 0.8246 - val_accuracy: 0.4628 - val_loss: 1.0526\n","Epoch 177/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6272 - loss: 0.8260 - val_accuracy: 0.4582 - val_loss: 1.0658\n","Epoch 178/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6293 - loss: 0.8249 - val_accuracy: 0.4607 - val_loss: 1.0643\n","Epoch 179/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6277 - loss: 0.8247 - val_accuracy: 0.4650 - val_loss: 1.0634\n","Epoch 180/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6288 - loss: 0.8239 - val_accuracy: 0.4435 - val_loss: 1.0922\n","Epoch 181/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6292 - loss: 0.8223 - val_accuracy: 0.4621 - val_loss: 1.0590\n","Epoch 182/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6290 - loss: 0.8229 - val_accuracy: 0.4614 - val_loss: 1.0587\n","Epoch 183/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6297 - loss: 0.8218 - val_accuracy: 0.4542 - val_loss: 1.0647\n","Epoch 184/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6297 - loss: 0.8210 - val_accuracy: 0.4585 - val_loss: 1.0641\n","Epoch 185/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6306 - loss: 0.8221 - val_accuracy: 0.4612 - val_loss: 1.0655\n","Epoch 186/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6307 - loss: 0.8208 - val_accuracy: 0.4528 - val_loss: 1.0636\n","Epoch 187/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6316 - loss: 0.8191 - val_accuracy: 0.4616 - val_loss: 1.0621\n","Epoch 188/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6320 - loss: 0.8196 - val_accuracy: 0.4584 - val_loss: 1.0656\n","Epoch 189/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6301 - loss: 0.8189 - val_accuracy: 0.4517 - val_loss: 1.0726\n","Epoch 190/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6317 - loss: 0.8210 - val_accuracy: 0.4581 - val_loss: 1.0634\n","Epoch 191/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6316 - loss: 0.8191 - val_accuracy: 0.4584 - val_loss: 1.0664\n","Epoch 192/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6313 - loss: 0.8182 - val_accuracy: 0.4613 - val_loss: 1.0635\n","Epoch 193/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6339 - loss: 0.8166 - val_accuracy: 0.4529 - val_loss: 1.0726\n","Epoch 194/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6312 - loss: 0.8192 - val_accuracy: 0.4646 - val_loss: 1.0629\n","Epoch 195/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6331 - loss: 0.8172 - val_accuracy: 0.4602 - val_loss: 1.0713\n","Epoch 196/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.8177 - val_accuracy: 0.4626 - val_loss: 1.0617\n","Epoch 197/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6347 - loss: 0.8152 - val_accuracy: 0.4582 - val_loss: 1.0752\n","Epoch 198/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6332 - loss: 0.8156 - val_accuracy: 0.4612 - val_loss: 1.0695\n","Epoch 199/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6335 - loss: 0.8153 - val_accuracy: 0.4555 - val_loss: 1.0681\n","Epoch 200/200\n","\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6342 - loss: 0.8148 - val_accuracy: 0.4626 - val_loss: 1.0661\n","CPU times: user 53min 57s, sys: 3min 32s, total: 57min 29s\n","Wall time: 41min 23s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7fafa1e778d0>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["print(accuracy_score(np.argmax(testY_CNN, axis=1), np.argmax(lstm2.predict(testX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2uRUXd8WiF3","executionInfo":{"status":"ok","timestamp":1741063994993,"user_tz":300,"elapsed":16258,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"b94006e5-ea5c-45e3-ab2a-f1056d140b89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step\n","0.48322436338609775\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve, auc\n","\n","# Get predicted probabilities for the positive class\n","y_pred_proba = lstm2.predict(testX_CNN)[:, 1]\n","\n","# Calculate precision and recall\n","precision, recall, thresholds = precision_recall_curve(testY_CNN[:, 1], y_pred_proba)\n","\n","# Calculate area under the curve\n","auc_score = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label=f'AUC = {auc_score:.2f}')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"9EELo5qde3X_","executionInfo":{"status":"ok","timestamp":1741064010430,"user_tz":300,"elapsed":15432,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"c67c96b0-a856-4fdc-e267-da05498d70d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score\n","print(classification_report(np.argmax(testY_CNN, axis=1), np.argmax(lstm2.predict(testX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"136DOGSxe-oA","executionInfo":{"status":"ok","timestamp":1741064025614,"user_tz":300,"elapsed":15179,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"cdd50fb9-c0e6-4dc4-e97a-33c750b83e8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.64      0.54     47915\n","           1       0.58      0.22      0.31     48050\n","           2       0.47      0.60      0.53     43523\n","\n","    accuracy                           0.48    139488\n","   macro avg       0.51      0.49      0.46    139488\n","weighted avg       0.51      0.48      0.46    139488\n","\n"]}]},{"cell_type":"code","source":["print(accuracy_score(np.argmax(trainY_CNN, axis=1), np.argmax(lstm2.predict(trainX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kt4CZCxufIpF","executionInfo":{"status":"ok","timestamp":1741064049421,"user_tz":300,"elapsed":23803,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"29f427f0-e9f6-47c8-f078-cd95caea397d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n","0.6372919131472109\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve, auc\n","\n","# Get predicted probabilities for the positive class\n","y_pred_proba = lstm2.predict(trainX_CNN)[:, 1]\n","\n","# Calculate precision and recall\n","precision, recall, thresholds = precision_recall_curve(trainY_CNN[:, 1], y_pred_proba)\n","\n","# Calculate area under the curve\n","auc_score = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label=f'AUC = {auc_score:.2f}')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"om5I3FeXfOHU","executionInfo":{"status":"ok","timestamp":1741064071843,"user_tz":300,"elapsed":22418,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"c77f927f-8319-4971-cc53-ebf8a8c5eec9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score\n","print(classification_report(np.argmax(trainY_CNN, axis=1), np.argmax(lstm2.predict(trainX_CNN), axis=1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cT7BWO1HfUhq","executionInfo":{"status":"ok","timestamp":1741064094424,"user_tz":300,"elapsed":22576,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"611471a2-1b58-4c5b-ea6c-c49ff4073608"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.75      0.68     84426\n","           1       0.74      0.26      0.38     36210\n","           2       0.64      0.69      0.67     83065\n","\n","    accuracy                           0.64    203701\n","   macro avg       0.67      0.57      0.58    203701\n","weighted avg       0.65      0.64      0.62    203701\n","\n"]}]},{"cell_type":"code","source":["\"\"\" TRADING STRATEGY BEFORE ATTACK ON TEST DATA\"\"\"\n","import numpy as np\n","import pandas as pd\n","\n","print(\"Getting predictions...\")\n","train_predictions = lstm2.predict(testX_CNN)\n","\n","# First define our strategy function\n","def implement_fi2010_strategy(predictions, dec_data, budget=100, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"\n","    Implements trading strategy using the FI-2010 paper's methodology\n","\n","    Args:\n","        predictions: numpy array of model predictions (n_samples, 3)\n","        dec_data: numpy array of decoded price data\n","        budget: amount to invest per trade\n","        prob_threshold: probability threshold for trading\n","        k: prediction horizon (number of steps to look ahead)\n","        alpha: threshold for determining price movement direction\n","    \"\"\"\n","    # Get normalized ask and bid prices\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","\n","    trades_info = []\n","\n","    for i in range(k, min_length):\n","        # Calculate m+ (future average) according to paper\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","\n","        # Calculate actual price movement using paper's method\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","        max_prob = np.max([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","\n","        if max_prob > prob_threshold and pred_class != 1:  # not stable\n","            # Determine actual direction using same threshold as training\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","\n","            # Long trade (UP prediction)\n","            if pred_class == 2:\n","                shares = budget / mid_prices[i]\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 2],\n","                    'correct': actual_direction == 1,\n","                    'index': i\n","                })\n","\n","            # Short trade (DOWN prediction)\n","            elif pred_class == 0:\n","                shares = budget / mid_prices[i]\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 0],\n","                    'correct': actual_direction == -1,\n","                    'index': i\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","\n","        # Print performance metrics\n","        print(\"\\nTrading Performance:\")\n","        print(f\"Total trades: {len(trades_df)}\")\n","        print(f\"Win rate: {(trades_df['correct'].mean() * 100):.2f}%\")\n","        print(f\"Total profit: ${trades_df['profit'].sum():.2f}\")\n","        print(f\"Average profit per trade: ${trades_df['profit'].mean():.4f}\")\n","\n","        print(\"\\nDirection Analysis:\")\n","        for direction in ['up', 'down']:\n","            mask = trades_df['movement'] == direction\n","            if mask.any():\n","                direction_df = trades_df[mask]\n","                print(f\"\\n{direction.upper()} trades:\")\n","                print(f\"Count: {len(direction_df)}\")\n","                print(f\"Win rate: {(direction_df['correct'].mean() * 100):.2f}%\")\n","                print(f\"Total profit: ${direction_df['profit'].sum():.2f}\")\n","                print(f\"Average profit: ${direction_df['profit'].mean():.4f}\")\n","\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","# Test different probability thresholds\n","thresholds = [0.8, 0.85, 0.9, 0.95, 0.99]\n","results = []\n","\n","print(\"Testing strategy with different thresholds...\")\n","for threshold in thresholds:\n","    print(f\"\\nTesting threshold: {threshold}\")\n","    result = implement_fi2010_strategy(\n","        predictions=train_predictions,\n","        dec_data=dec_test,\n","        prob_threshold=threshold,\n","        k=4,\n","        alpha=0.001\n","    )\n","    if result:\n","        results.append(result)\n","\n","# Create summary table\n","if results:\n","    results_df = pd.DataFrame(results)\n","    print(\"\\nSummary of results for different probability thresholds:\")\n","    pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))\n","    print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLAjVjnSfaRh","executionInfo":{"status":"ok","timestamp":1741064159021,"user_tz":300,"elapsed":33852,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"c6a55b81-0ea7-4ada-b822-afac634a2b7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting predictions...\n","\u001b[1m4359/4359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step\n","Testing strategy with different thresholds...\n","\n","Testing threshold: 0.8\n","\n","Trading Performance:\n","Total trades: 13592\n","Win rate: 0.45%\n","Total profit: $109.01\n","Average profit per trade: $0.0080\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 6217\n","Win rate: 0.55%\n","Total profit: $5.85\n","Average profit: $0.0009\n","\n","DOWN trades:\n","Count: 7375\n","Win rate: 0.37%\n","Total profit: $103.16\n","Average profit: $0.0140\n","\n","Testing threshold: 0.85\n","\n","Trading Performance:\n","Total trades: 9473\n","Win rate: 0.42%\n","Total profit: $-0.60\n","Average profit per trade: $-0.0001\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 4333\n","Win rate: 0.55%\n","Total profit: $6.02\n","Average profit: $0.0014\n","\n","DOWN trades:\n","Count: 5140\n","Win rate: 0.31%\n","Total profit: $-6.62\n","Average profit: $-0.0013\n","\n","Testing threshold: 0.9\n","\n","Trading Performance:\n","Total trades: 5959\n","Win rate: 0.40%\n","Total profit: $-1.74\n","Average profit per trade: $-0.0003\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 2718\n","Win rate: 0.55%\n","Total profit: $2.47\n","Average profit: $0.0009\n","\n","DOWN trades:\n","Count: 3241\n","Win rate: 0.28%\n","Total profit: $-4.21\n","Average profit: $-0.0013\n","\n","Testing threshold: 0.95\n","\n","Trading Performance:\n","Total trades: 2868\n","Win rate: 0.56%\n","Total profit: $-2.27\n","Average profit per trade: $-0.0008\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 1253\n","Win rate: 0.88%\n","Total profit: $1.07\n","Average profit: $0.0009\n","\n","DOWN trades:\n","Count: 1615\n","Win rate: 0.31%\n","Total profit: $-3.35\n","Average profit: $-0.0021\n","\n","Testing threshold: 0.99\n","\n","Trading Performance:\n","Total trades: 490\n","Win rate: 0.61%\n","Total profit: $-0.94\n","Average profit per trade: $-0.0019\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 196\n","Win rate: 0.00%\n","Total profit: $-0.12\n","Average profit: $-0.0006\n","\n","DOWN trades:\n","Count: 294\n","Win rate: 1.02%\n","Total profit: $-0.82\n","Average profit: $-0.0028\n","\n","Summary of results for different probability thresholds:\n","   threshold  total_profit  num_trades  win_rate  avg_profit  long_trades  \\\n","0   0.800000    109.005085       13592  0.448793    0.008020         6217   \n","1   0.850000     -0.602582        9473  0.422253   -0.000064         4333   \n","2   0.900000     -1.736131        5959  0.402752   -0.000291         2718   \n","3   0.950000     -2.274972        2868  0.557880   -0.000793         1253   \n","4   0.990000     -0.938332         490  0.612245   -0.001915          196   \n","\n","   short_trades  \n","0          7375  \n","1          5140  \n","2          3241  \n","3          1615  \n","4           294  \n"]}]},{"cell_type":"code","source":["\"\"\" TRADING STRATEGY BEFORE ATTACK ON TRAIN DATA\"\"\"\n","import numpy as np\n","import pandas as pd\n","\n","print(\"Getting predictions...\")\n","train_predictions = lstm2.predict(trainX_CNN)\n","\n","# First define our strategy function\n","def implement_fi2010_strategy(predictions, dec_data, budget=100, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"\n","    Implements trading strategy using the FI-2010 paper's methodology\n","\n","    Args:\n","        predictions: numpy array of model predictions (n_samples, 3)\n","        dec_data: numpy array of decoded price data\n","        budget: amount to invest per trade\n","        prob_threshold: probability threshold for trading\n","        k: prediction horizon (number of steps to look ahead)\n","        alpha: threshold for determining price movement direction\n","    \"\"\"\n","    # Get normalized ask and bid prices\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","\n","    trades_info = []\n","\n","    for i in range(k, min_length):\n","        # Calculate m+ (future average) according to paper\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","\n","        # Calculate actual price movement using paper's method\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","        max_prob = np.max([predictions[i, 0], predictions[i, 1], predictions[i, 2]])\n","\n","        if max_prob > prob_threshold and pred_class != 1:  # not stable\n","            # Determine actual direction using same threshold as training\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","\n","            # Long trade (UP prediction)\n","            if pred_class == 2:\n","                shares = budget / mid_prices[i]\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 2],\n","                    'correct': actual_direction == 1,\n","                    'index': i\n","                })\n","\n","            # Short trade (DOWN prediction)\n","            elif pred_class == 0:\n","                shares = budget / mid_prices[i]\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'entry_price': mid_prices[i],\n","                    'exit_price': m_plus,\n","                    'shares': shares,\n","                    'price_change': m_plus - mid_prices[i],\n","                    'price_change_pct': lt,\n","                    'cost': cost,\n","                    'proceeds': proceeds,\n","                    'profit': profit,\n","                    'prob': predictions[i, 0],\n","                    'correct': actual_direction == -1,\n","                    'index': i\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","\n","        # Print performance metrics\n","        print(\"\\nTrading Performance:\")\n","        print(f\"Total trades: {len(trades_df)}\")\n","        print(f\"Win rate: {(trades_df['correct'].mean() * 100):.2f}%\")\n","        print(f\"Total profit: ${trades_df['profit'].sum():.2f}\")\n","        print(f\"Average profit per trade: ${trades_df['profit'].mean():.4f}\")\n","\n","        print(\"\\nDirection Analysis:\")\n","        for direction in ['up', 'down']:\n","            mask = trades_df['movement'] == direction\n","            if mask.any():\n","                direction_df = trades_df[mask]\n","                print(f\"\\n{direction.upper()} trades:\")\n","                print(f\"Count: {len(direction_df)}\")\n","                print(f\"Win rate: {(direction_df['correct'].mean() * 100):.2f}%\")\n","                print(f\"Total profit: ${direction_df['profit'].sum():.2f}\")\n","                print(f\"Average profit: ${direction_df['profit'].mean():.4f}\")\n","\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","# Test different probability thresholds\n","thresholds = [0.8, 0.85, 0.9, 0.95, 0.99]\n","results = []\n","\n","print(\"Testing strategy with different thresholds...\")\n","for threshold in thresholds:\n","    print(f\"\\nTesting threshold: {threshold}\")\n","    result = implement_fi2010_strategy(\n","        predictions=train_predictions,\n","        dec_data=dec_train,\n","        prob_threshold=threshold,\n","        k=4,\n","        alpha=0.001\n","    )\n","    if result:\n","        results.append(result)\n","\n","# Create summary table\n","if results:\n","    results_df = pd.DataFrame(results)\n","    print(\"\\nSummary of results for different probability thresholds:\")\n","    pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))\n","    print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVX19zmmgjqA","executionInfo":{"status":"ok","timestamp":1741064221453,"user_tz":300,"elapsed":48446,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"63b016c0-7337-4e22-9480-b5758c4db5f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting predictions...\n","\u001b[1m6366/6366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n","Testing strategy with different thresholds...\n","\n","Testing threshold: 0.8\n","\n","Trading Performance:\n","Total trades: 33764\n","Win rate: 0.65%\n","Total profit: $176.06\n","Average profit per trade: $0.0052\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 14954\n","Win rate: 0.62%\n","Total profit: $10.66\n","Average profit: $0.0007\n","\n","DOWN trades:\n","Count: 18810\n","Win rate: 0.67%\n","Total profit: $165.40\n","Average profit: $0.0088\n","\n","Testing threshold: 0.85\n","\n","Trading Performance:\n","Total trades: 24561\n","Win rate: 0.66%\n","Total profit: $102.27\n","Average profit per trade: $0.0042\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 10770\n","Win rate: 0.68%\n","Total profit: $9.26\n","Average profit: $0.0009\n","\n","DOWN trades:\n","Count: 13791\n","Win rate: 0.65%\n","Total profit: $93.01\n","Average profit: $0.0067\n","\n","Testing threshold: 0.9\n","\n","Trading Performance:\n","Total trades: 16027\n","Win rate: 0.69%\n","Total profit: $94.56\n","Average profit per trade: $0.0059\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 6982\n","Win rate: 0.76%\n","Total profit: $8.90\n","Average profit: $0.0013\n","\n","DOWN trades:\n","Count: 9045\n","Win rate: 0.64%\n","Total profit: $85.67\n","Average profit: $0.0095\n","\n","Testing threshold: 0.95\n","\n","Trading Performance:\n","Total trades: 8051\n","Win rate: 0.56%\n","Total profit: $10.33\n","Average profit per trade: $0.0013\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 3374\n","Win rate: 0.71%\n","Total profit: $2.66\n","Average profit: $0.0008\n","\n","DOWN trades:\n","Count: 4677\n","Win rate: 0.45%\n","Total profit: $7.67\n","Average profit: $0.0016\n","\n","Testing threshold: 0.99\n","\n","Trading Performance:\n","Total trades: 1317\n","Win rate: 0.46%\n","Total profit: $4.02\n","Average profit per trade: $0.0031\n","\n","Direction Analysis:\n","\n","UP trades:\n","Count: 521\n","Win rate: 0.58%\n","Total profit: $0.77\n","Average profit: $0.0015\n","\n","DOWN trades:\n","Count: 796\n","Win rate: 0.38%\n","Total profit: $3.25\n","Average profit: $0.0041\n","\n","Summary of results for different probability thresholds:\n","   threshold  total_profit  num_trades  win_rate  avg_profit  long_trades  \\\n","0   0.800000    176.057591       33764  0.648620    0.005214        14954   \n","1   0.850000    102.266546       24561  0.659582    0.004164        10770   \n","2   0.900000     94.560685       16027  0.692581    0.005900         6982   \n","3   0.950000     10.333130        8051  0.558937    0.001283         3374   \n","4   0.990000      4.017318        1317  0.455581    0.003050          521   \n","\n","   short_trades  \n","0         18810  \n","1         13791  \n","2          9045  \n","3          4677  \n","4           796  \n"]}]},{"cell_type":"code","source":["def calculate_perturbation_volume(original, perturbed):\n","    original_flat = original.reshape(original.shape[0], -1)\n","    perturbed_flat = perturbed.reshape(perturbed.shape[0], -1)\n","    perturbation = np.linalg.norm(original_flat - perturbed_flat, ord=2, axis=1)\n","    avg_perturbation = np.mean(perturbation)\n","    return avg_perturbation"],"metadata":{"id":"d2tJwYHsgvVe","executionInfo":{"status":"ok","timestamp":1741409900826,"user_tz":300,"elapsed":3,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\"\"\" ADVERSARIAL ATTACK ON TEST DATA ON 4 EPSILON VALUES\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import precision_score, recall_score, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Define constants\n","max_test_size = testX_CNN.shape[0]\n","batch_size = 2000\n","num_batches = max_test_size // batch_size\n","epsilon_values = [0.000001, 0.00001, 0.0001, 0.001]\n","num_iterations = 5\n","step_size = 0.01\n","\n","# Define your model\n","model = lstm2\n","\n","avg_accuracies1 = {}\n","avg_accuracies2 = {}\n","perturbed_volumes1 = {}\n","perturbed_volumes2 = {}\n","# Define dictionaries to hold precision and recall\n","avg_precision1 = {}\n","avg_recall1 = {}\n","avg_precision2 = {}\n","avg_recall2 = {}\n","# Define dictionaries to hold ROC AUC scores\n","avg_roc_auc1 = {}\n","avg_roc_auc2 = {}\n","\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","def data_set(testX_CNN, start_idx, end_idx):\n","    shifted_testX_CNN = tf.concat([testX_CNN[start_idx:end_idx, 1:100, :, :], testX_CNN[start_idx:end_idx, 99:, :, :]], axis=1)\n","    return shifted_testX_CNN\n","\n","def fgsm_attack(images, labels, epsilon):\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        predictions = model(images)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","    gradient = tape.gradient(loss, images)\n","    signed_grad = tf.sign(gradient)\n","\n","    signed_masked = signed_grad.numpy()\n","    signed_masked[:, :99, :, :] = 0\n","    signed_masked[:, 99:, ::2, :] = 0\n","    signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","    perturbed_images = images + epsilon * signed_masked\n","    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","    return perturbed_images\n","\n","def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","    perturbed_images = tf.identity(images)\n","\n","    for _ in range(num_iterations):\n","        # Gradient step\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","        gradient = tape.gradient(loss, perturbed_images)\n","        signed_grad = tf.sign(gradient)\n","\n","        # Apply masking to gradient\n","        signed_masked = signed_grad.numpy()\n","        signed_masked[:, :99, :, :] = 0\n","        signed_masked[:, 99:, ::2, :] = 0\n","        signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","        # Apply gradient step\n","        perturbed_images = perturbed_images + step_size * signed_masked\n","\n","        # Step 1: Apply volume constraint\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","        # Step 2: Apply L2 norm constraint (projection step)\n","        delta = perturbed_images - images  # Calculate current perturbation\n","\n","        # Reshape to flatten all dimensions except batch\n","        delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","        # Calculate L2 norm on the flattened dimensions\n","        norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","        # Reshape norm for broadcasting\n","        norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","        # Scale perturbation\n","        scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","        delta = delta * scaling\n","\n","        perturbed_images = images + delta  # Apply constrained perturbation\n","\n","        # Step 3: Apply clipping to valid range [0,1]\n","        perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","        # Step 4: Re-apply volume constraint after all other constraints\n","        # This ensures volume constraint takes precedence if there's a conflict\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","    return perturbed_images\n","\n","def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","    images = images.numpy()\n","    slices = [slice(None)] * images.ndim\n","    testX_CNN = testX_CNN[start_idx:end_idx]\n","    for idx in range(images.shape[dimension]):\n","        slices[dimension] = idx\n","        images[tuple(slices)] = np.maximum(images[tuple(slices)], testX_CNN[tuple(slices)])\n","    images = tf.convert_to_tensor(images, dtype=tf.float32)\n","    return images\n","\n","def plot_roc_curve(y_true, y_score1, y_score2, epsilon):\n","    \"\"\"\n","    Plot ROC curve for both attacks at a specific epsilon value\n","    \"\"\"\n","    # Get number of classes\n","    n_classes = y_score1.shape[1]\n","\n","    # Compute ROC curve and ROC area for each class for PGD\n","    fpr1 = dict()\n","    tpr1 = dict()\n","    roc_auc1 = dict()\n","    for i in range(n_classes):\n","        fpr1[i], tpr1[i], _ = roc_curve(y_true[:, i], y_score1[:, i])\n","        roc_auc1[i] = auc(fpr1[i], tpr1[i])\n","\n","    # Compute ROC curve and ROC area for each class for FGSM\n","    fpr2 = dict()\n","    tpr2 = dict()\n","    roc_auc2 = dict()\n","    for i in range(n_classes):\n","        fpr2[i], tpr2[i], _ = roc_curve(y_true[:, i], y_score2[:, i])\n","        roc_auc2[i] = auc(fpr2[i], tpr2[i])\n","\n","    # Calculate macro average ROC curve and ROC area\n","    all_fpr1 = np.unique(np.concatenate([fpr1[i] for i in range(n_classes)]))\n","    all_fpr2 = np.unique(np.concatenate([fpr2[i] for i in range(n_classes)]))\n","\n","    mean_tpr1 = np.zeros_like(all_fpr1)\n","    mean_tpr2 = np.zeros_like(all_fpr2)\n","    for i in range(n_classes):\n","        mean_tpr1 += np.interp(all_fpr1, fpr1[i], tpr1[i])\n","        mean_tpr2 += np.interp(all_fpr2, fpr2[i], tpr2[i])\n","\n","    mean_tpr1 /= n_classes\n","    mean_tpr2 /= n_classes\n","\n","    macro_roc_auc1 = auc(all_fpr1, mean_tpr1)\n","    macro_roc_auc2 = auc(all_fpr2, mean_tpr2)\n","\n","    # Plot ROC curve only as per the requirement\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(all_fpr1, mean_tpr1, label=f'PGD Attack - Macro-average ROC (AUC = {macro_roc_auc1:.2f})',\n","             color='blue', linestyle='solid', linewidth=2)\n","    plt.plot(all_fpr2, mean_tpr2, label=f'FGSM Attack - Macro-average ROC (AUC = {macro_roc_auc2:.2f})',\n","             color='red', linestyle='dashed', linewidth=2)\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for PGD and FGSM Attacks with ε = {epsilon}')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the figure\n","    plt.savefig(f'roc_curve_epsilon_{epsilon}.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    return macro_roc_auc1, macro_roc_auc2\n","\n","# Lists to store all prediction probabilities and true labels for ROC curves\n","all_true_labels_onehot = []\n","all_pred_probs_pgd = []\n","all_pred_probs_fgsm = []\n","\n","for epsilon in epsilon_values:\n","    print(f\"Epsilon value: {epsilon}\")\n","    total_accuracy1 = 0.0\n","    total_accuracy2 = 0.0\n","    total_perturbation1 = 0.0\n","    total_perturbation2 = 0.0\n","    all_true_labels = []\n","    all_predicted_labels1 = []\n","    all_predicted_labels2 = []\n","\n","    # For this epsilon, collect all prediction probabilities\n","    epsilon_true_labels_onehot = []\n","    epsilon_pred_probs_pgd = []\n","    epsilon_pred_probs_fgsm = []\n","\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = (i + 1) * batch_size\n","\n","        batch_images = data_set(testX_CNN, start_idx, end_idx)\n","        batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","        batch_labels = testY_CNN[start_idx:end_idx]\n","\n","        perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","        perturbed_images2 = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","        perturbation1 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images1.numpy())\n","        perturbation2 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images2.numpy())\n","\n","        total_perturbation1 += perturbation1\n","        total_perturbation2 += perturbation2\n","\n","        X_perturbed1 = perturbed_images1.numpy()\n","        X_perturbed2 = perturbed_images2.numpy()\n","\n","        # Get raw probabilities for ROC curve\n","        adversarial_probs1 = model.predict(X_perturbed1)\n","        adversarial_probs2 = model.predict(X_perturbed2)\n","\n","        # Get predicted labels\n","        adversarial_predictions1 = np.argmax(adversarial_probs1, axis=1)\n","        adversarial_predictions2 = np.argmax(adversarial_probs2, axis=1)\n","\n","        # Collect data for ROC curve\n","        epsilon_true_labels_onehot.append(batch_labels)\n","        epsilon_pred_probs_pgd.append(adversarial_probs1)\n","        epsilon_pred_probs_fgsm.append(adversarial_probs2)\n","\n","        # Append results for precision and recall calculation\n","        true_labels_batch = np.argmax(batch_labels, axis=1)\n","        all_true_labels.extend(true_labels_batch)\n","        all_predicted_labels1.extend(adversarial_predictions1)\n","        all_predicted_labels2.extend(adversarial_predictions2)\n","\n","        accuracy1 = accuracy_score(true_labels_batch, adversarial_predictions1)\n","        accuracy2 = accuracy_score(true_labels_batch, adversarial_predictions2)\n","        total_accuracy1 += accuracy1\n","        total_accuracy2 += accuracy2\n","\n","    average_accuracy1 = total_accuracy1 / num_batches\n","    average_accuracy2 = total_accuracy2 / num_batches\n","    avg_perturbation1 = total_perturbation1 / num_batches\n","    avg_perturbation2 = total_perturbation2 / num_batches\n","\n","    # Concatenate all batches for this epsilon\n","    epsilon_true_labels_onehot = np.vstack(epsilon_true_labels_onehot)\n","    epsilon_pred_probs_pgd = np.vstack(epsilon_pred_probs_pgd)\n","    epsilon_pred_probs_fgsm = np.vstack(epsilon_pred_probs_fgsm)\n","\n","    # Calculate and plot ROC curve\n","    roc_auc1, roc_auc2 = plot_roc_curve(\n","        epsilon_true_labels_onehot,\n","        epsilon_pred_probs_pgd,\n","        epsilon_pred_probs_fgsm,\n","        epsilon\n","    )\n","\n","    avg_roc_auc1[epsilon] = roc_auc1\n","    avg_roc_auc2[epsilon] = roc_auc2\n","\n","    # Calculate precision and recall\n","    precision1 = precision_score(all_true_labels, all_predicted_labels1, average='macro')\n","    recall1 = recall_score(all_true_labels, all_predicted_labels1, average='macro')\n","    precision2 = precision_score(all_true_labels, all_predicted_labels2, average='macro')\n","    recall2 = recall_score(all_true_labels, all_predicted_labels2, average='macro')\n","\n","    avg_precision1[epsilon] = precision1\n","    avg_recall1[epsilon] = recall1\n","    avg_precision2[epsilon] = precision2\n","    avg_recall2[epsilon] = recall2\n","\n","    # Generate classification reports\n","    pgd_report = classification_report(all_true_labels, all_predicted_labels1, output_dict=True)\n","    fgsm_report = classification_report(all_true_labels, all_predicted_labels2, output_dict=True)\n","\n","    print(f\"Average accuracy of PGD attack for epsilon value {epsilon}: {average_accuracy1}\")\n","    avg_accuracies1[epsilon] = average_accuracy1\n","    print(f\"Average accuracy of FGSM attack for epsilon value {epsilon}: {average_accuracy2}\")\n","    avg_accuracies2[epsilon] = average_accuracy2\n","    print(f\"Average perturbation volume for PGD attack with epsilon {epsilon}: {avg_perturbation1}\")\n","    perturbed_volumes1[epsilon] = avg_perturbation1\n","    print(f\"Average perturbation volume for FGSM attack with epsilon {epsilon}: {avg_perturbation2}\")\n","    perturbed_volumes2[epsilon] = avg_perturbation2\n","\n","    # Print precision and recall\n","    print(f\"Average precision of PGD attack for epsilon value {epsilon}: {precision1}\")\n","    print(f\"Average recall of PGD attack for epsilon value {epsilon}: {recall1}\")\n","    print(f\"Average precision of FGSM attack for epsilon value {epsilon}: {precision2}\")\n","    print(f\"Average recall of FGSM attack for epsilon value {epsilon}: {recall2}\")\n","\n","    # Print ROC AUC\n","    print(f\"ROC AUC of PGD attack for epsilon value {epsilon}: {roc_auc1}\")\n","    print(f\"ROC AUC of FGSM attack for epsilon value {epsilon}: {roc_auc2}\")\n","\n","    # Print classification reports\n","    print(f\"\\nClassification Report for PGD Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels1))\n","\n","    print(f\"\\nClassification Report for FGSM Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels2))\n","\n","    # Clean up\n","    tf.keras.backend.clear_session()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44gLbei-g84P","executionInfo":{"status":"ok","timestamp":1741411190817,"user_tz":300,"elapsed":1023653,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"92f4f4d9-dc91-4059-f571-e8a36cd34806"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon value: 1e-06\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","Average accuracy of PGD attack for epsilon value 1e-06: 0.3944927536231883\n","Average accuracy of FGSM attack for epsilon value 1e-06: 0.47523188405797107\n","Average perturbation volume for PGD attack with epsilon 1e-06: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 1e-06: 4.471044826789074e-06\n","Average precision of PGD attack for epsilon value 1e-06: 0.39851611208925736\n","Average recall of PGD attack for epsilon value 1e-06: 0.39522706282008385\n","Average precision of FGSM attack for epsilon value 1e-06: 0.4789169417950507\n","Average recall of FGSM attack for epsilon value 1e-06: 0.476833462590648\n","ROC AUC of PGD attack for epsilon value 1e-06: 0.5695952633381847\n","ROC AUC of FGSM attack for epsilon value 1e-06: 0.6749141497220932\n","\n","Classification Report for PGD Attack (ε = 1e-06):\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.55      0.46     47512\n","           1       0.41      0.20      0.27     47269\n","           2       0.39      0.43      0.41     43219\n","\n","    accuracy                           0.39    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.39      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1e-06):\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.62      0.53     47512\n","           1       0.49      0.27      0.35     47269\n","           2       0.48      0.54      0.51     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.48      0.48      0.46    138000\n","weighted avg       0.48      0.48      0.46    138000\n","\n","Epsilon value: 1e-05\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","Average accuracy of PGD attack for epsilon value 1e-05: 0.3944927536231883\n","Average accuracy of FGSM attack for epsilon value 1e-05: 0.47521014492753627\n","Average perturbation volume for PGD attack with epsilon 1e-05: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 1e-05: 4.47205725915568e-05\n","Average precision of PGD attack for epsilon value 1e-05: 0.39851611208925736\n","Average recall of PGD attack for epsilon value 1e-05: 0.39522706282008385\n","Average precision of FGSM attack for epsilon value 1e-05: 0.4788988916061438\n","Average recall of FGSM attack for epsilon value 1e-05: 0.47681237920967795\n","ROC AUC of PGD attack for epsilon value 1e-05: 0.5695952106011463\n","ROC AUC of FGSM attack for epsilon value 1e-05: 0.6748817085410201\n","\n","Classification Report for PGD Attack (ε = 1e-05):\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.55      0.46     47512\n","           1       0.41      0.20      0.27     47269\n","           2       0.39      0.43      0.41     43219\n","\n","    accuracy                           0.39    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.39      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1e-05):\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.62      0.53     47512\n","           1       0.49      0.27      0.35     47269\n","           2       0.48      0.54      0.51     43219\n","\n","    accuracy                           0.48    138000\n","   macro avg       0.48      0.48      0.46    138000\n","weighted avg       0.48      0.48      0.46    138000\n","\n","Epsilon value: 0.0001\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","Average accuracy of PGD attack for epsilon value 0.0001: 0.3944927536231883\n","Average accuracy of FGSM attack for epsilon value 0.0001: 0.47482608695652173\n","Average perturbation volume for PGD attack with epsilon 0.0001: 2.2640041743499646\n","Average perturbation volume for FGSM attack with epsilon 0.0001: 0.0004470569623188804\n","Average precision of PGD attack for epsilon value 0.0001: 0.39851611208925736\n","Average recall of PGD attack for epsilon value 0.0001: 0.39522706282008385\n","Average precision of FGSM attack for epsilon value 0.0001: 0.47853431358580645\n","Average recall of FGSM attack for epsilon value 0.0001: 0.47642756657913915\n","ROC AUC of PGD attack for epsilon value 0.0001: 0.5695946691808869\n","ROC AUC of FGSM attack for epsilon value 0.0001: 0.6745595447638414\n","\n","Classification Report for PGD Attack (ε = 0.0001):\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.55      0.46     47512\n","           1       0.41      0.20      0.27     47269\n","           2       0.39      0.43      0.41     43219\n","\n","    accuracy                           0.39    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.39      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.0001):\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.62      0.53     47512\n","           1       0.49      0.27      0.35     47269\n","           2       0.48      0.54      0.51     43219\n","\n","    accuracy                           0.47    138000\n","   macro avg       0.48      0.48      0.46    138000\n","weighted avg       0.48      0.47      0.46    138000\n","\n","Epsilon value: 0.001\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","Average accuracy of PGD attack for epsilon value 0.001: 0.3944927536231883\n","Average accuracy of FGSM attack for epsilon value 0.001: 0.4712536231884058\n","Average perturbation volume for PGD attack with epsilon 0.001: 2.2640041762935943\n","Average perturbation volume for FGSM attack with epsilon 0.001: 0.00445514148020226\n","Average precision of PGD attack for epsilon value 0.001: 0.39851611208925736\n","Average recall of PGD attack for epsilon value 0.001: 0.39522706282008385\n","Average precision of FGSM attack for epsilon value 0.001: 0.4749938834826583\n","Average recall of FGSM attack for epsilon value 0.001: 0.4728212293865475\n","ROC AUC of PGD attack for epsilon value 0.001: 0.5695890803166264\n","ROC AUC of FGSM attack for epsilon value 0.001: 0.671354723835595\n","\n","Classification Report for PGD Attack (ε = 0.001):\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.55      0.46     47512\n","           1       0.41      0.20      0.27     47269\n","           2       0.39      0.43      0.41     43219\n","\n","    accuracy                           0.39    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.39      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.001):\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.62      0.53     47512\n","           1       0.49      0.27      0.35     47269\n","           2       0.47      0.53      0.50     43219\n","\n","    accuracy                           0.47    138000\n","   macro avg       0.47      0.47      0.46    138000\n","weighted avg       0.48      0.47      0.46    138000\n","\n"]}]},{"cell_type":"code","source":["\"\"\" ADVERSARIAL ATTACK ON TEST DATA ON 4 EPSILON VALUES\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import precision_score, recall_score, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Define constants\n","max_test_size = testX_CNN.shape[0]\n","batch_size = 2000\n","num_batches = max_test_size // batch_size\n","epsilon_values = [0.01, 0.1, 1, 10]\n","num_iterations = 5\n","step_size = 0.01\n","\n","# Define your model\n","model = lstm2\n","\n","avg_accuracies1 = {}\n","avg_accuracies2 = {}\n","perturbed_volumes1 = {}\n","perturbed_volumes2 = {}\n","# Define dictionaries to hold precision and recall\n","avg_precision1 = {}\n","avg_recall1 = {}\n","avg_precision2 = {}\n","avg_recall2 = {}\n","# Define dictionaries to hold ROC AUC scores\n","avg_roc_auc1 = {}\n","avg_roc_auc2 = {}\n","\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","def data_set(testX_CNN, start_idx, end_idx):\n","    shifted_testX_CNN = tf.concat([testX_CNN[start_idx:end_idx, 1:100, :, :], testX_CNN[start_idx:end_idx, 99:, :, :]], axis=1)\n","    return shifted_testX_CNN\n","\n","def fgsm_attack(images, labels, epsilon):\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        predictions = model(images)\n","        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","    gradient = tape.gradient(loss, images)\n","    signed_grad = tf.sign(gradient)\n","\n","    signed_masked = signed_grad.numpy()\n","    signed_masked[:, :99, :, :] = 0\n","    signed_masked[:, 99:, ::2, :] = 0\n","    signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","    perturbed_images = images + epsilon * signed_masked\n","    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","    return perturbed_images\n","\n","def pgd_attack(images, labels, epsilon, trainX_CNN, start_idx, end_idx):\n","    perturbed_images = tf.identity(images)\n","\n","    for _ in range(num_iterations):\n","        # Gradient step\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","        gradient = tape.gradient(loss, perturbed_images)\n","        signed_grad = tf.sign(gradient)\n","\n","        # Apply masking to gradient\n","        signed_masked = signed_grad.numpy()\n","        signed_masked[:, :99, :, :] = 0\n","        signed_masked[:, 99:, ::2, :] = 0\n","        signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","        # Apply gradient step\n","        perturbed_images = perturbed_images + step_size * signed_masked\n","\n","        # Step 1: Apply volume constraint\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","        # Step 2: Apply L2 norm constraint (projection step)\n","        delta = perturbed_images - images  # Calculate current perturbation\n","\n","        # Reshape to flatten all dimensions except batch\n","        delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","        # Calculate L2 norm on the flattened dimensions\n","        norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","        # Reshape norm for broadcasting\n","        norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","        # Scale perturbation\n","        scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","        delta = delta * scaling\n","\n","        perturbed_images = images + delta  # Apply constrained perturbation\n","\n","        # Step 3: Apply clipping to valid range [0,1]\n","        perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","\n","        # Step 4: Re-apply volume constraint after all other constraints\n","        # This ensures volume constraint takes precedence if there's a conflict\n","        perturbed_images = volume_constraint(perturbed_images, trainX_CNN, 2, start_idx, end_idx)\n","\n","    return perturbed_images\n","\n","def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","    images = images.numpy()\n","    slices = [slice(None)] * images.ndim\n","    testX_CNN = testX_CNN[start_idx:end_idx]\n","    for idx in range(images.shape[dimension]):\n","        slices[dimension] = idx\n","        images[tuple(slices)] = np.maximum(images[tuple(slices)], testX_CNN[tuple(slices)])\n","    images = tf.convert_to_tensor(images, dtype=tf.float32)\n","    return images\n","\n","def plot_roc_curve(y_true, y_score1, y_score2, epsilon):\n","    \"\"\"\n","    Plot ROC curve for both attacks at a specific epsilon value\n","    \"\"\"\n","    # Get number of classes\n","    n_classes = y_score1.shape[1]\n","\n","    # Compute ROC curve and ROC area for each class for PGD\n","    fpr1 = dict()\n","    tpr1 = dict()\n","    roc_auc1 = dict()\n","    for i in range(n_classes):\n","        fpr1[i], tpr1[i], _ = roc_curve(y_true[:, i], y_score1[:, i])\n","        roc_auc1[i] = auc(fpr1[i], tpr1[i])\n","\n","    # Compute ROC curve and ROC area for each class for FGSM\n","    fpr2 = dict()\n","    tpr2 = dict()\n","    roc_auc2 = dict()\n","    for i in range(n_classes):\n","        fpr2[i], tpr2[i], _ = roc_curve(y_true[:, i], y_score2[:, i])\n","        roc_auc2[i] = auc(fpr2[i], tpr2[i])\n","\n","    # Calculate macro average ROC curve and ROC area\n","    all_fpr1 = np.unique(np.concatenate([fpr1[i] for i in range(n_classes)]))\n","    all_fpr2 = np.unique(np.concatenate([fpr2[i] for i in range(n_classes)]))\n","\n","    mean_tpr1 = np.zeros_like(all_fpr1)\n","    mean_tpr2 = np.zeros_like(all_fpr2)\n","    for i in range(n_classes):\n","        mean_tpr1 += np.interp(all_fpr1, fpr1[i], tpr1[i])\n","        mean_tpr2 += np.interp(all_fpr2, fpr2[i], tpr2[i])\n","\n","    mean_tpr1 /= n_classes\n","    mean_tpr2 /= n_classes\n","\n","    macro_roc_auc1 = auc(all_fpr1, mean_tpr1)\n","    macro_roc_auc2 = auc(all_fpr2, mean_tpr2)\n","\n","    # Plot ROC curve only as per the requirement\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(all_fpr1, mean_tpr1, label=f'PGD Attack - Macro-average ROC (AUC = {macro_roc_auc1:.2f})',\n","             color='blue', linestyle='solid', linewidth=2)\n","    plt.plot(all_fpr2, mean_tpr2, label=f'FGSM Attack - Macro-average ROC (AUC = {macro_roc_auc2:.2f})',\n","             color='red', linestyle='dashed', linewidth=2)\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for PGD and FGSM Attacks with ε = {epsilon}')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the figure\n","    plt.savefig(f'roc_curve_epsilon_{epsilon}.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    return macro_roc_auc1, macro_roc_auc2\n","\n","# Lists to store all prediction probabilities and true labels for ROC curves\n","all_true_labels_onehot = []\n","all_pred_probs_pgd = []\n","all_pred_probs_fgsm = []\n","\n","for epsilon in epsilon_values:\n","    print(f\"Epsilon value: {epsilon}\")\n","    total_accuracy1 = 0.0\n","    total_accuracy2 = 0.0\n","    total_perturbation1 = 0.0\n","    total_perturbation2 = 0.0\n","    all_true_labels = []\n","    all_predicted_labels1 = []\n","    all_predicted_labels2 = []\n","\n","    # For this epsilon, collect all prediction probabilities\n","    epsilon_true_labels_onehot = []\n","    epsilon_pred_probs_pgd = []\n","    epsilon_pred_probs_fgsm = []\n","\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = (i + 1) * batch_size\n","\n","        batch_images = data_set(testX_CNN, start_idx, end_idx)\n","        batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","        batch_labels = testY_CNN[start_idx:end_idx]\n","\n","        perturbed_images1 = pgd_attack(batch_images, batch_labels, epsilon, trainX_CNN, start_idx, end_idx)\n","        perturbed_images2 = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","        perturbation1 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images1.numpy())\n","        perturbation2 = calculate_perturbation_volume(batch_images.numpy(), perturbed_images2.numpy())\n","\n","        total_perturbation1 += perturbation1\n","        total_perturbation2 += perturbation2\n","\n","        X_perturbed1 = perturbed_images1.numpy()\n","        X_perturbed2 = perturbed_images2.numpy()\n","\n","        # Get raw probabilities for ROC curve\n","        adversarial_probs1 = model.predict(X_perturbed1)\n","        adversarial_probs2 = model.predict(X_perturbed2)\n","\n","        # Get predicted labels\n","        adversarial_predictions1 = np.argmax(adversarial_probs1, axis=1)\n","        adversarial_predictions2 = np.argmax(adversarial_probs2, axis=1)\n","\n","        # Collect data for ROC curve\n","        epsilon_true_labels_onehot.append(batch_labels)\n","        epsilon_pred_probs_pgd.append(adversarial_probs1)\n","        epsilon_pred_probs_fgsm.append(adversarial_probs2)\n","\n","        # Append results for precision and recall calculation\n","        true_labels_batch = np.argmax(batch_labels, axis=1)\n","        all_true_labels.extend(true_labels_batch)\n","        all_predicted_labels1.extend(adversarial_predictions1)\n","        all_predicted_labels2.extend(adversarial_predictions2)\n","\n","        accuracy1 = accuracy_score(true_labels_batch, adversarial_predictions1)\n","        accuracy2 = accuracy_score(true_labels_batch, adversarial_predictions2)\n","        total_accuracy1 += accuracy1\n","        total_accuracy2 += accuracy2\n","\n","    average_accuracy1 = total_accuracy1 / num_batches\n","    average_accuracy2 = total_accuracy2 / num_batches\n","    avg_perturbation1 = total_perturbation1 / num_batches\n","    avg_perturbation2 = total_perturbation2 / num_batches\n","\n","    # Concatenate all batches for this epsilon\n","    epsilon_true_labels_onehot = np.vstack(epsilon_true_labels_onehot)\n","    epsilon_pred_probs_pgd = np.vstack(epsilon_pred_probs_pgd)\n","    epsilon_pred_probs_fgsm = np.vstack(epsilon_pred_probs_fgsm)\n","\n","    # Calculate and plot ROC curve\n","    roc_auc1, roc_auc2 = plot_roc_curve(\n","        epsilon_true_labels_onehot,\n","        epsilon_pred_probs_pgd,\n","        epsilon_pred_probs_fgsm,\n","        epsilon\n","    )\n","\n","    avg_roc_auc1[epsilon] = roc_auc1\n","    avg_roc_auc2[epsilon] = roc_auc2\n","\n","    # Calculate precision and recall\n","    precision1 = precision_score(all_true_labels, all_predicted_labels1, average='macro')\n","    recall1 = recall_score(all_true_labels, all_predicted_labels1, average='macro')\n","    precision2 = precision_score(all_true_labels, all_predicted_labels2, average='macro')\n","    recall2 = recall_score(all_true_labels, all_predicted_labels2, average='macro')\n","\n","    avg_precision1[epsilon] = precision1\n","    avg_recall1[epsilon] = recall1\n","    avg_precision2[epsilon] = precision2\n","    avg_recall2[epsilon] = recall2\n","\n","    # Generate classification reports\n","    pgd_report = classification_report(all_true_labels, all_predicted_labels1, output_dict=True)\n","    fgsm_report = classification_report(all_true_labels, all_predicted_labels2, output_dict=True)\n","\n","    print(f\"Average accuracy of PGD attack for epsilon value {epsilon}: {average_accuracy1}\")\n","    avg_accuracies1[epsilon] = average_accuracy1\n","    print(f\"Average accuracy of FGSM attack for epsilon value {epsilon}: {average_accuracy2}\")\n","    avg_accuracies2[epsilon] = average_accuracy2\n","    print(f\"Average perturbation volume for PGD attack with epsilon {epsilon}: {avg_perturbation1}\")\n","    perturbed_volumes1[epsilon] = avg_perturbation1\n","    print(f\"Average perturbation volume for FGSM attack with epsilon {epsilon}: {avg_perturbation2}\")\n","    perturbed_volumes2[epsilon] = avg_perturbation2\n","\n","    # Print precision and recall\n","    print(f\"Average precision of PGD attack for epsilon value {epsilon}: {precision1}\")\n","    print(f\"Average recall of PGD attack for epsilon value {epsilon}: {recall1}\")\n","    print(f\"Average precision of FGSM attack for epsilon value {epsilon}: {precision2}\")\n","    print(f\"Average recall of FGSM attack for epsilon value {epsilon}: {recall2}\")\n","\n","    # Print ROC AUC\n","    print(f\"ROC AUC of PGD attack for epsilon value {epsilon}: {roc_auc1}\")\n","    print(f\"ROC AUC of FGSM attack for epsilon value {epsilon}: {roc_auc2}\")\n","\n","    # Print classification reports\n","    print(f\"\\nClassification Report for PGD Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels1))\n","\n","    print(f\"\\nClassification Report for FGSM Attack (ε = {epsilon}):\")\n","    print(classification_report(all_true_labels, all_predicted_labels2))\n","\n","    # Clean up\n","    tf.keras.backend.clear_session()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Z7Ibgz_hD7_","executionInfo":{"status":"ok","timestamp":1741412223781,"user_tz":300,"elapsed":1032934,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"916392d4-95d2-4278-b37b-d5f1c85b36b7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon value: 0.01\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","Average accuracy of PGD attack for epsilon value 0.01: 0.39442753623188387\n","Average accuracy of FGSM attack for epsilon value 0.01: 0.4434130434782608\n","Average perturbation volume for PGD attack with epsilon 0.01: 2.264004424214363\n","Average perturbation volume for FGSM attack with epsilon 0.01: 0.040496136723221214\n","Average precision of PGD attack for epsilon value 0.01: 0.39846558820590045\n","Average recall of PGD attack for epsilon value 0.01: 0.3951617941530257\n","Average precision of FGSM attack for epsilon value 0.01: 0.4474576244758414\n","Average recall of FGSM attack for epsilon value 0.01: 0.44481317973274476\n","ROC AUC of PGD attack for epsilon value 0.01: 0.5695310280845436\n","ROC AUC of FGSM attack for epsilon value 0.01: 0.6447058623250853\n","\n","Classification Report for PGD Attack (ε = 0.01):\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.55      0.46     47512\n","           1       0.41      0.20      0.27     47269\n","           2       0.39      0.43      0.41     43219\n","\n","    accuracy                           0.39    138000\n","   macro avg       0.40      0.40      0.38    138000\n","weighted avg       0.40      0.39      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.01):\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.58      0.50     47512\n","           1       0.46      0.25      0.32     47269\n","           2       0.44      0.50      0.47     43219\n","\n","    accuracy                           0.44    138000\n","   macro avg       0.45      0.44      0.43    138000\n","weighted avg       0.45      0.44      0.43    138000\n","\n","Epsilon value: 0.1\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","Average accuracy of PGD attack for epsilon value 0.1: 0.39273913043478254\n","Average accuracy of FGSM attack for epsilon value 0.1: 0.2737101449275362\n","Average perturbation volume for PGD attack with epsilon 0.1: 2.2641099579092385\n","Average perturbation volume for FGSM attack with epsilon 0.1: 0.33051275386326556\n","Average precision of PGD attack for epsilon value 0.1: 0.3969831151932688\n","Average recall of PGD attack for epsilon value 0.1: 0.39344734982494095\n","Average precision of FGSM attack for epsilon value 0.1: 0.283403031766938\n","Average recall of FGSM attack for epsilon value 0.1: 0.2741813207305124\n","ROC AUC of PGD attack for epsilon value 0.1: 0.5686411501286704\n","ROC AUC of FGSM attack for epsilon value 0.1: 0.46777777748724036\n","\n","Classification Report for PGD Attack (ε = 0.1):\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.55      0.46     47512\n","           1       0.41      0.20      0.27     47269\n","           2       0.39      0.43      0.41     43219\n","\n","    accuracy                           0.39    138000\n","   macro avg       0.40      0.39      0.38    138000\n","weighted avg       0.40      0.39      0.38    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 0.1):\n","              precision    recall  f1-score   support\n","\n","           0       0.27      0.37      0.31     47512\n","           1       0.32      0.16      0.21     47269\n","           2       0.26      0.30      0.27     43219\n","\n","    accuracy                           0.27    138000\n","   macro avg       0.28      0.27      0.27    138000\n","weighted avg       0.28      0.27      0.27    138000\n","\n","Epsilon value: 1\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","Average accuracy of PGD attack for epsilon value 1: 0.3738550724637681\n","Average accuracy of FGSM attack for epsilon value 1: 0.009891304347826086\n","Average perturbation volume for PGD attack with epsilon 1: 2.2669582738392595\n","Average perturbation volume for FGSM attack with epsilon 1: 3.1144286618716475\n","Average precision of PGD attack for epsilon value 1: 0.3796934585500473\n","Average recall of PGD attack for epsilon value 1: 0.37439536196256434\n","Average precision of FGSM attack for epsilon value 1: 0.02160418206267804\n","Average recall of FGSM attack for epsilon value 1: 0.009813424366065082\n","ROC AUC of PGD attack for epsilon value 1: 0.5513598203510318\n","ROC AUC of FGSM attack for epsilon value 1: 0.11857505976144891\n","\n","Classification Report for PGD Attack (ε = 1):\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.53      0.43     47512\n","           1       0.40      0.20      0.26     47269\n","           2       0.37      0.40      0.38     43219\n","\n","    accuracy                           0.37    138000\n","   macro avg       0.38      0.37      0.36    138000\n","weighted avg       0.38      0.37      0.36    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 1):\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.01      0.01     47512\n","           1       0.05      0.02      0.02     47269\n","           2       0.01      0.01      0.01     43219\n","\n","    accuracy                           0.01    138000\n","   macro avg       0.02      0.01      0.01    138000\n","weighted avg       0.02      0.01      0.01    138000\n","\n","Epsilon value: 10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","Average accuracy of PGD attack for epsilon value 10: 0.3365434782608696\n","Average accuracy of FGSM attack for epsilon value 10: 0.00994202898550724\n","Average perturbation volume for PGD attack with epsilon 10: 2.2730172643626947\n","Average perturbation volume for FGSM attack with epsilon 10: 3.1144947521928428\n","Average precision of PGD attack for epsilon value 10: 0.3419453328052362\n","Average recall of PGD attack for epsilon value 10: 0.33677166405008646\n","Average precision of FGSM attack for epsilon value 10: 0.021319757125903182\n","Average recall of FGSM attack for epsilon value 10: 0.009873840825522957\n","ROC AUC of PGD attack for epsilon value 10: 0.5093648519698699\n","ROC AUC of FGSM attack for epsilon value 10: 0.118736886960189\n","\n","Classification Report for PGD Attack (ε = 10):\n","              precision    recall  f1-score   support\n","\n","           0       0.34      0.48      0.40     47512\n","           1       0.37      0.17      0.24     47269\n","           2       0.32      0.35      0.34     43219\n","\n","    accuracy                           0.34    138000\n","   macro avg       0.34      0.34      0.32    138000\n","weighted avg       0.34      0.34      0.32    138000\n","\n","\n","Classification Report for FGSM Attack (ε = 10):\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.01      0.01     47512\n","           1       0.05      0.02      0.02     47269\n","           2       0.01      0.01      0.01     43219\n","\n","    accuracy                           0.01    138000\n","   macro avg       0.02      0.01      0.01    138000\n","weighted avg       0.02      0.01      0.01    138000\n","\n"]}]},{"cell_type":"code","source":["\"\"\"TRADING STRATEGY AFTER ATTACK ON 4 EPSILON VALUES\"\"\"\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","def run_adversarial_trading_analysis(model, testX_CNN, testY_CNN, dec_test, epsilon_values, batch_size=2000):\n","    \"\"\"Run trading strategy analysis with adversarial attacks\"\"\"\n","    results_pgd = []\n","    results_fgsm = []\n","    thresholds = [0.85, 0.90, 0.95, 0.99]  # Explicit thresholds\n","\n","    def data_set(testX_CNN, start_idx, end_idx):\n","        \"\"\"Prepare the dataset by shifting\"\"\"\n","        shifted_testX_CNN = tf.concat([\n","            testX_CNN[start_idx:end_idx, 1:100, :, :],\n","            testX_CNN[start_idx:end_idx, 99:, :, :]\n","        ], axis=1)\n","        return tf.cast(shifted_testX_CNN, tf.float32)\n","\n","    def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","        \"\"\"Apply volume constraints to the images\"\"\"\n","        images = images.numpy()\n","        slices = [slice(None)] * images.ndim\n","        testX_CNN_batch = testX_CNN[start_idx:end_idx]\n","        for idx in range(images.shape[dimension]):\n","            slices[dimension] = idx\n","            images[tuple(slices)] = np.maximum(\n","                images[tuple(slices)],\n","                testX_CNN_batch[tuple(slices)]\n","            )\n","        return tf.convert_to_tensor(images, dtype=tf.float32)\n","\n","    def get_model_predictions(perturbed_images):\n","        \"\"\"Get model predictions with error handling\"\"\"\n","        try:\n","            with tf.device('/CPU:0'):\n","                predictions = model(perturbed_images, training=False)\n","                return predictions.numpy()\n","        except Exception as e:\n","            print(f\"Error in model prediction: {str(e)}\")\n","            return None\n","\n","    def fgsm_attack(images, labels, epsilon):\n","        \"\"\"Implement FGSM attack\"\"\"\n","        try:\n","            with tf.GradientTape() as tape:\n","                tape.watch(images)\n","                predictions = model(images, training=False)\n","                loss = tf.keras.losses.CategoricalCrossentropy()(labels, predictions)\n","\n","            gradient = tape.gradient(loss, images)\n","            signed_grad = tf.sign(gradient)\n","\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            perturbed_images = images + epsilon * signed_masked\n","            return tf.clip_by_value(perturbed_images, 0, 1)\n","        except Exception as e:\n","            print(f\"Error in FGSM attack: {str(e)}\")\n","            return None\n","\n","    def pgd_attack(images, labels, epsilon):\n","        perturbed_images = tf.identity(images)\n","        for _ in range(num_iterations):\n","            with tf.GradientTape() as tape:\n","                tape.watch(perturbed_images)\n","                predictions = model(perturbed_images)\n","                loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","            gradient = tape.gradient(loss, perturbed_images)\n","            signed_grad = tf.sign(gradient)\n","\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            perturbed_images = perturbed_images + step_size * signed_masked\n","\n","            # Add projection step here with fixed norm calculation:\n","            delta = perturbed_images - images  # Calculate current perturbation\n","\n","            # Reshape to flatten all dimensions except batch\n","            delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","            # Calculate L2 norm on the flattened dimensions\n","            norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","            # Reshape norm for broadcasting\n","            norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","            # Scale perturbation\n","            scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","            delta = delta * scaling\n","\n","            perturbed_images = images + delta  # Apply constrained perturbation\n","            perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","        return perturbed_images\n","\n","    max_test_size = testX_CNN.shape[0]\n","    num_batches = max_test_size // batch_size\n","\n","    for epsilon in epsilon_values:\n","        print(f\"\\nAnalyzing epsilon: {epsilon}\")\n","\n","        pgd_predictions = []\n","        fgsm_predictions = []\n","\n","        for i in range(num_batches):\n","            start_idx = i * batch_size\n","            end_idx = min((i + 1) * batch_size, max_test_size)\n","\n","            try:\n","                # Prepare batch data\n","                batch_images = data_set(testX_CNN, start_idx, end_idx)\n","                batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","                batch_labels = testY_CNN[start_idx:end_idx]\n","\n","                # Generate adversarial examples\n","                perturbed_images_pgd = pgd_attack(batch_images, batch_labels, epsilon)\n","                perturbed_images_fgsm = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","                if perturbed_images_pgd is not None and perturbed_images_fgsm is not None:\n","                    # Calculate perturbation volumes\n","                    pgd_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_pgd - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    fgsm_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_fgsm - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    print(f\"Batch {i+1}/{num_batches} - PGD volume: {pgd_volume:.6f}, FGSM volume: {fgsm_volume:.6f}\")\n","\n","                    # Get predictions\n","                    pgd_pred = get_model_predictions(perturbed_images_pgd)\n","                    fgsm_pred = get_model_predictions(perturbed_images_fgsm)\n","\n","                    if pgd_pred is not None:\n","                        pgd_predictions.append(pgd_pred)\n","                    if fgsm_pred is not None:\n","                        fgsm_predictions.append(fgsm_pred)\n","\n","            except Exception as e:\n","                print(f\"Error processing batch {i}: {str(e)}\")\n","                continue\n","\n","            tf.keras.backend.clear_session()\n","\n","        if pgd_predictions and fgsm_predictions:\n","            pgd_predictions = np.vstack(pgd_predictions)\n","            fgsm_predictions = np.vstack(fgsm_predictions)\n","\n","            # Process for each threshold\n","            for threshold in thresholds:\n","                # Process PGD results\n","                pgd_result = implement_fi2010_strategy(\n","                    predictions=pgd_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if pgd_result:\n","                    pgd_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'PGD'\n","                    })\n","                    results_pgd.append(pgd_result)\n","\n","                # Process FGSM results\n","                fgsm_result = implement_fi2010_strategy(\n","                    predictions=fgsm_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if fgsm_result:\n","                    fgsm_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'FGSM'\n","                    })\n","                    results_fgsm.append(fgsm_result)\n","\n","    # Create DataFrames\n","    pgd_df = pd.DataFrame(results_pgd) if results_pgd else pd.DataFrame()\n","    fgsm_df = pd.DataFrame(results_fgsm) if results_fgsm else pd.DataFrame()\n","\n","    # Display detailed summaries\n","    if not pgd_df.empty:\n","        print(\"\\nPGD Attack Summary by Threshold:\")\n","        summary_pgd = pgd_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        # Format the display\n","        pd.set_option('display.float_format', lambda x: '%.4f' % x)\n","        print(\"\\nPGD Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_pgd.loc[eps])\n","\n","    if not fgsm_df.empty:\n","        print(\"\\nFGSM Attack Summary by Threshold:\")\n","        summary_fgsm = fgsm_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        print(\"\\nFGSM Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_fgsm.loc[eps])\n","\n","    return pgd_df, fgsm_df\n","\n","def implement_fi2010_strategy(predictions, dec_data, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"Implementation of the FI-2010 trading strategy\"\"\"\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","    trades_info = []\n","    budget = 100\n","\n","    for i in range(k, min_length):\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax(predictions[i])\n","        max_prob = np.max(predictions[i])\n","\n","        if max_prob > prob_threshold and pred_class != 1:\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","            shares = budget / mid_prices[i]\n","\n","            if pred_class == 2:  # Long trade\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'profit': profit,\n","                    'correct': actual_direction == 1\n","                })\n","            elif pred_class == 0:  # Short trade\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'profit': profit,\n","                    'correct': actual_direction == -1\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","epsilon_values = [0.000001, 0.00001, 0.0001, 0.001]\n","results_pgd, results_fgsm = run_adversarial_trading_analysis(\n","    model=lstm2,\n","    testX_CNN=testX_CNN,\n","    testY_CNN=testY_CNN,\n","    dec_test=dec_test,\n","    epsilon_values=epsilon_values,\n","    batch_size=2000\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8sbNQ0oizgX","executionInfo":{"status":"ok","timestamp":1741412600210,"user_tz":300,"elapsed":376427,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"5ac93513-4fc3-4911-9ab7-345b438020c0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Analyzing epsilon: 1e-06\n","Batch 1/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 2/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 3/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 4/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 5/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 6/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 7/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 8/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 9/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 10/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 11/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 12/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 13/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 14/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 15/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 16/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 17/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 18/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 19/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 20/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 21/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 22/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 23/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 24/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 25/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 26/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 27/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 28/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 29/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 30/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 31/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 32/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 33/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 34/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 35/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 36/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 37/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 38/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 39/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 40/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 41/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 42/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 43/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 44/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 45/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 46/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 47/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 48/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 49/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 50/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 51/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 52/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 53/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 54/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 55/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 56/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 57/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 58/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 59/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 60/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 61/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 62/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 63/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 64/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 65/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 66/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 67/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 68/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","Batch 69/69 - PGD volume: 0.000001, FGSM volume: 0.000004\n","\n","Analyzing epsilon: 1e-05\n","Batch 1/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 2/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 3/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 4/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 5/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 6/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 7/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 8/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 9/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 10/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 11/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 12/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 13/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 14/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 15/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 16/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 17/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 18/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 19/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 20/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 21/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 22/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 23/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 24/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 25/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 26/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 27/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 28/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 29/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 30/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 31/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 32/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 33/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 34/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 35/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 36/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 37/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 38/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 39/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 40/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 41/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 42/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 43/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 44/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 45/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 46/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 47/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 48/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 49/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 50/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 51/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 52/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 53/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 54/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 55/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 56/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 57/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 58/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 59/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 60/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 61/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 62/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 63/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 64/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 65/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 66/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 67/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 68/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","Batch 69/69 - PGD volume: 0.000010, FGSM volume: 0.000045\n","\n","Analyzing epsilon: 0.0001\n","Batch 1/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 2/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 3/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 4/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 5/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 6/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 7/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 8/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 9/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 10/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 11/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 12/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 13/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 14/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 15/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 16/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 17/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 18/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 19/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 20/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 21/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 22/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 23/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 24/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 25/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 26/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 27/69 - PGD volume: 0.000100, FGSM volume: 0.000446\n","Batch 28/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 29/69 - PGD volume: 0.000100, FGSM volume: 0.000446\n","Batch 30/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 31/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 32/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 33/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 34/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 35/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 36/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 37/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 38/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 39/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 40/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 41/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 42/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 43/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 44/69 - PGD volume: 0.000100, FGSM volume: 0.000446\n","Batch 45/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 46/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 47/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 48/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 49/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 50/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 51/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 52/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 53/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 54/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 55/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 56/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 57/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 58/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 59/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 60/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 61/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 62/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 63/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 64/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 65/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 66/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 67/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 68/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","Batch 69/69 - PGD volume: 0.000100, FGSM volume: 0.000447\n","\n","Analyzing epsilon: 0.001\n","Batch 1/69 - PGD volume: 0.000997, FGSM volume: 0.004382\n","Batch 2/69 - PGD volume: 0.000999, FGSM volume: 0.004449\n","Batch 3/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 4/69 - PGD volume: 0.001000, FGSM volume: 0.004464\n","Batch 5/69 - PGD volume: 0.001000, FGSM volume: 0.004471\n","Batch 6/69 - PGD volume: 0.001000, FGSM volume: 0.004470\n","Batch 7/69 - PGD volume: 0.001000, FGSM volume: 0.004468\n","Batch 8/69 - PGD volume: 0.000999, FGSM volume: 0.004466\n","Batch 9/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 10/69 - PGD volume: 0.001000, FGSM volume: 0.004470\n","Batch 11/69 - PGD volume: 0.001000, FGSM volume: 0.004464\n","Batch 12/69 - PGD volume: 0.001000, FGSM volume: 0.004463\n","Batch 13/69 - PGD volume: 0.001000, FGSM volume: 0.004464\n","Batch 14/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 15/69 - PGD volume: 0.001000, FGSM volume: 0.004463\n","Batch 16/69 - PGD volume: 0.001000, FGSM volume: 0.004467\n","Batch 17/69 - PGD volume: 0.000999, FGSM volume: 0.004454\n","Batch 18/69 - PGD volume: 0.001000, FGSM volume: 0.004460\n","Batch 19/69 - PGD volume: 0.001000, FGSM volume: 0.004461\n","Batch 20/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 21/69 - PGD volume: 0.001000, FGSM volume: 0.004455\n","Batch 22/69 - PGD volume: 0.000998, FGSM volume: 0.004428\n","Batch 23/69 - PGD volume: 0.001000, FGSM volume: 0.004452\n","Batch 24/69 - PGD volume: 0.001000, FGSM volume: 0.004437\n","Batch 25/69 - PGD volume: 0.001000, FGSM volume: 0.004431\n","Batch 26/69 - PGD volume: 0.000998, FGSM volume: 0.004455\n","Batch 27/69 - PGD volume: 0.000996, FGSM volume: 0.004444\n","Batch 28/69 - PGD volume: 0.000997, FGSM volume: 0.004427\n","Batch 29/69 - PGD volume: 0.000996, FGSM volume: 0.004407\n","Batch 30/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 31/69 - PGD volume: 0.000999, FGSM volume: 0.004467\n","Batch 32/69 - PGD volume: 0.000999, FGSM volume: 0.004467\n","Batch 33/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 34/69 - PGD volume: 0.001000, FGSM volume: 0.004467\n","Batch 35/69 - PGD volume: 0.001000, FGSM volume: 0.004465\n","Batch 36/69 - PGD volume: 0.001000, FGSM volume: 0.004456\n","Batch 37/69 - PGD volume: 0.001000, FGSM volume: 0.004452\n","Batch 38/69 - PGD volume: 0.000999, FGSM volume: 0.004468\n","Batch 39/69 - PGD volume: 0.000999, FGSM volume: 0.004466\n","Batch 40/69 - PGD volume: 0.000999, FGSM volume: 0.004465\n","Batch 41/69 - PGD volume: 0.001000, FGSM volume: 0.004468\n","Batch 42/69 - PGD volume: 0.001000, FGSM volume: 0.004465\n","Batch 43/69 - PGD volume: 0.000997, FGSM volume: 0.004460\n","Batch 44/69 - PGD volume: 0.000998, FGSM volume: 0.004460\n","Batch 45/69 - PGD volume: 0.000998, FGSM volume: 0.004448\n","Batch 46/69 - PGD volume: 0.001000, FGSM volume: 0.004450\n","Batch 47/69 - PGD volume: 0.000999, FGSM volume: 0.004452\n","Batch 48/69 - PGD volume: 0.000997, FGSM volume: 0.004428\n","Batch 49/69 - PGD volume: 0.001000, FGSM volume: 0.004434\n","Batch 50/69 - PGD volume: 0.000997, FGSM volume: 0.004426\n","Batch 51/69 - PGD volume: 0.001000, FGSM volume: 0.004450\n","Batch 52/69 - PGD volume: 0.001000, FGSM volume: 0.004445\n","Batch 53/69 - PGD volume: 0.001000, FGSM volume: 0.004455\n","Batch 54/69 - PGD volume: 0.001000, FGSM volume: 0.004451\n","Batch 55/69 - PGD volume: 0.000999, FGSM volume: 0.004405\n","Batch 56/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 57/69 - PGD volume: 0.001000, FGSM volume: 0.004467\n","Batch 58/69 - PGD volume: 0.001000, FGSM volume: 0.004469\n","Batch 59/69 - PGD volume: 0.001000, FGSM volume: 0.004470\n","Batch 60/69 - PGD volume: 0.001000, FGSM volume: 0.004471\n","Batch 61/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 62/69 - PGD volume: 0.001000, FGSM volume: 0.004466\n","Batch 63/69 - PGD volume: 0.001000, FGSM volume: 0.004460\n","Batch 64/69 - PGD volume: 0.000999, FGSM volume: 0.004452\n","Batch 65/69 - PGD volume: 0.001000, FGSM volume: 0.004453\n","Batch 66/69 - PGD volume: 0.001000, FGSM volume: 0.004459\n","Batch 67/69 - PGD volume: 0.001000, FGSM volume: 0.004451\n","Batch 68/69 - PGD volume: 0.000999, FGSM volume: 0.004443\n","Batch 69/69 - PGD volume: 0.001000, FGSM volume: 0.004444\n","\n","PGD Attack Summary by Threshold:\n","\n","PGD Analysis Results:\n","\n","Epsilon: 1e-06\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         106.1638  12158.0000    0.5511\n","0.9000          82.9927   7842.0000    0.5738\n","0.9500          -5.4756   4033.0000    0.5207\n","0.9900          -0.8449    772.0000    0.6477\n","\n","Epsilon: 1e-05\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         106.1638  12158.0000    0.5511\n","0.9000          82.9830   7841.0000    0.5739\n","0.9500          -5.4756   4033.0000    0.5207\n","0.9900          -0.8449    772.0000    0.6477\n","\n","Epsilon: 0.0001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         106.1475  12159.0000    0.5510\n","0.9000          83.0107   7840.0000    0.5740\n","0.9500          -5.5244   4032.0000    0.5208\n","0.9900          -0.8449    772.0000    0.6477\n","\n","Epsilon: 0.001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         106.0481  12139.0000    0.5519\n","0.9000          83.1711   7826.0000    0.5750\n","0.9500          -5.5382   4028.0000    0.5214\n","0.9900          -0.7773    770.0000    0.6494\n","\n","FGSM Attack Summary by Threshold:\n","\n","FGSM Analysis Results:\n","\n","Epsilon: 1e-06\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         106.1638  12158.0000    0.5511\n","0.9000          82.9927   7842.0000    0.5738\n","0.9500          -5.4756   4033.0000    0.5207\n","0.9900          -0.8449    772.0000    0.6477\n","\n","Epsilon: 1e-05\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         106.0865  12160.0000    0.5510\n","0.9000          83.0107   7839.0000    0.5741\n","0.9500          -5.5244   4032.0000    0.5208\n","0.9900          -0.8449    772.0000    0.6477\n","\n","Epsilon: 0.0001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         106.1486  12147.0000    0.5516\n","0.9000          83.0245   7836.0000    0.5743\n","0.9500          -5.5244   4030.0000    0.5211\n","0.9900          -0.8449    772.0000    0.6477\n","\n","Epsilon: 0.001\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         105.7232  12087.0000    0.5543\n","0.9000          82.9172   7801.0000    0.5768\n","0.9500          -5.2551   3997.0000    0.5004\n","0.9900          -0.7614    766.0000    0.6527\n"]}]},{"cell_type":"code","source":["\"\"\"TRADING STRATEGY AFTER ATTACK ON 4 EPSILON VALUES\"\"\"\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","def run_adversarial_trading_analysis(model, testX_CNN, testY_CNN, dec_test, epsilon_values, batch_size=2000):\n","    \"\"\"Run trading strategy analysis with adversarial attacks\"\"\"\n","    results_pgd = []\n","    results_fgsm = []\n","    thresholds = [0.85, 0.90, 0.95, 0.99]  # Explicit thresholds\n","\n","    def data_set(testX_CNN, start_idx, end_idx):\n","        \"\"\"Prepare the dataset by shifting\"\"\"\n","        shifted_testX_CNN = tf.concat([\n","            testX_CNN[start_idx:end_idx, 1:100, :, :],\n","            testX_CNN[start_idx:end_idx, 99:, :, :]\n","        ], axis=1)\n","        return tf.cast(shifted_testX_CNN, tf.float32)\n","\n","    def volume_constraint(images, testX_CNN, dimension, start_idx, end_idx):\n","        \"\"\"Apply volume constraints to the images\"\"\"\n","        images = images.numpy()\n","        slices = [slice(None)] * images.ndim\n","        testX_CNN_batch = testX_CNN[start_idx:end_idx]\n","        for idx in range(images.shape[dimension]):\n","            slices[dimension] = idx\n","            images[tuple(slices)] = np.maximum(\n","                images[tuple(slices)],\n","                testX_CNN_batch[tuple(slices)]\n","            )\n","        return tf.convert_to_tensor(images, dtype=tf.float32)\n","\n","    def get_model_predictions(perturbed_images):\n","        \"\"\"Get model predictions with error handling\"\"\"\n","        try:\n","            with tf.device('/CPU:0'):\n","                predictions = model(perturbed_images, training=False)\n","                return predictions.numpy()\n","        except Exception as e:\n","            print(f\"Error in model prediction: {str(e)}\")\n","            return None\n","\n","    def fgsm_attack(images, labels, epsilon):\n","        \"\"\"Implement FGSM attack\"\"\"\n","        try:\n","            with tf.GradientTape() as tape:\n","                tape.watch(images)\n","                predictions = model(images, training=False)\n","                loss = tf.keras.losses.CategoricalCrossentropy()(labels, predictions)\n","\n","            gradient = tape.gradient(loss, images)\n","            signed_grad = tf.sign(gradient)\n","\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            perturbed_images = images + epsilon * signed_masked\n","            return tf.clip_by_value(perturbed_images, 0, 1)\n","        except Exception as e:\n","            print(f\"Error in FGSM attack: {str(e)}\")\n","            return None\n","\n","    def pgd_attack(images, labels, epsilon):\n","        perturbed_images = tf.identity(images)\n","        for _ in range(num_iterations):\n","            with tf.GradientTape() as tape:\n","                tape.watch(perturbed_images)\n","                predictions = model(perturbed_images)\n","                loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(labels, predictions)\n","            gradient = tape.gradient(loss, perturbed_images)\n","            signed_grad = tf.sign(gradient)\n","\n","            signed_masked = signed_grad.numpy()\n","            signed_masked[:, :99, :, :] = 0\n","            signed_masked[:, 99:, ::2, :] = 0\n","            signed_masked = tf.convert_to_tensor(signed_masked, dtype=tf.float32)\n","\n","            perturbed_images = perturbed_images + step_size * signed_masked\n","\n","            # Add projection step here with fixed norm calculation:\n","            delta = perturbed_images - images  # Calculate current perturbation\n","\n","            # Reshape to flatten all dimensions except batch\n","            delta_flat = tf.reshape(delta, [tf.shape(delta)[0], -1])\n","\n","            # Calculate L2 norm on the flattened dimensions\n","            norm = tf.norm(delta_flat, axis=1, keepdims=True)\n","\n","            # Reshape norm for broadcasting\n","            norm = tf.reshape(norm, [tf.shape(delta)[0], 1, 1, 1])\n","\n","            # Scale perturbation\n","            scaling = tf.clip_by_value(epsilon / (norm + 1e-12), 0, 1)\n","            delta = delta * scaling\n","\n","            perturbed_images = images + delta  # Apply constrained perturbation\n","            perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n","        return perturbed_images\n","\n","    max_test_size = testX_CNN.shape[0]\n","    num_batches = max_test_size // batch_size\n","\n","    for epsilon in epsilon_values:\n","        print(f\"\\nAnalyzing epsilon: {epsilon}\")\n","\n","        pgd_predictions = []\n","        fgsm_predictions = []\n","\n","        for i in range(num_batches):\n","            start_idx = i * batch_size\n","            end_idx = min((i + 1) * batch_size, max_test_size)\n","\n","            try:\n","                # Prepare batch data\n","                batch_images = data_set(testX_CNN, start_idx, end_idx)\n","                batch_images = volume_constraint(batch_images, testX_CNN, 2, start_idx, end_idx)\n","                batch_labels = testY_CNN[start_idx:end_idx]\n","\n","                # Generate adversarial examples\n","                perturbed_images_pgd = pgd_attack(batch_images, batch_labels, epsilon)\n","                perturbed_images_fgsm = fgsm_attack(batch_images, batch_labels, epsilon)\n","\n","                if perturbed_images_pgd is not None and perturbed_images_fgsm is not None:\n","                    # Calculate perturbation volumes\n","                    pgd_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_pgd - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    fgsm_volume = np.mean(np.linalg.norm(\n","                        (perturbed_images_fgsm - batch_images).numpy().reshape(batch_images.shape[0], -1),\n","                        axis=1\n","                    ))\n","                    print(f\"Batch {i+1}/{num_batches} - PGD volume: {pgd_volume:.6f}, FGSM volume: {fgsm_volume:.6f}\")\n","\n","                    # Get predictions\n","                    pgd_pred = get_model_predictions(perturbed_images_pgd)\n","                    fgsm_pred = get_model_predictions(perturbed_images_fgsm)\n","\n","                    if pgd_pred is not None:\n","                        pgd_predictions.append(pgd_pred)\n","                    if fgsm_pred is not None:\n","                        fgsm_predictions.append(fgsm_pred)\n","\n","            except Exception as e:\n","                print(f\"Error processing batch {i}: {str(e)}\")\n","                continue\n","\n","            tf.keras.backend.clear_session()\n","\n","        if pgd_predictions and fgsm_predictions:\n","            pgd_predictions = np.vstack(pgd_predictions)\n","            fgsm_predictions = np.vstack(fgsm_predictions)\n","\n","            # Process for each threshold\n","            for threshold in thresholds:\n","                # Process PGD results\n","                pgd_result = implement_fi2010_strategy(\n","                    predictions=pgd_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if pgd_result:\n","                    pgd_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'PGD'\n","                    })\n","                    results_pgd.append(pgd_result)\n","\n","                # Process FGSM results\n","                fgsm_result = implement_fi2010_strategy(\n","                    predictions=fgsm_predictions,\n","                    dec_data=dec_test,\n","                    prob_threshold=threshold\n","                )\n","                if fgsm_result:\n","                    fgsm_result.update({\n","                        'epsilon': epsilon,\n","                        'threshold': threshold,\n","                        'attack_type': 'FGSM'\n","                    })\n","                    results_fgsm.append(fgsm_result)\n","\n","    # Create DataFrames\n","    pgd_df = pd.DataFrame(results_pgd) if results_pgd else pd.DataFrame()\n","    fgsm_df = pd.DataFrame(results_fgsm) if results_fgsm else pd.DataFrame()\n","\n","    # Display detailed summaries\n","    if not pgd_df.empty:\n","        print(\"\\nPGD Attack Summary by Threshold:\")\n","        summary_pgd = pgd_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        # Format the display\n","        pd.set_option('display.float_format', lambda x: '%.4f' % x)\n","        print(\"\\nPGD Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_pgd.loc[eps])\n","\n","    if not fgsm_df.empty:\n","        print(\"\\nFGSM Attack Summary by Threshold:\")\n","        summary_fgsm = fgsm_df.groupby(['epsilon', 'threshold'])[\n","            ['total_profit', 'num_trades', 'win_rate']\n","        ].mean().round(4)\n","\n","        print(\"\\nFGSM Analysis Results:\")\n","        for eps in epsilon_values:\n","            print(f\"\\nEpsilon: {eps}\")\n","            print(summary_fgsm.loc[eps])\n","\n","    return pgd_df, fgsm_df\n","\n","def implement_fi2010_strategy(predictions, dec_data, prob_threshold=0.5, k=4, alpha=0.001):\n","    \"\"\"Implementation of the FI-2010 trading strategy\"\"\"\n","    ask_prices = dec_data[0, :]\n","    bid_prices = dec_data[2, :]\n","    mid_prices = (ask_prices + bid_prices) / 2\n","\n","    min_length = min(len(predictions), len(mid_prices) - k)\n","    predictions = predictions[:min_length]\n","    trades_info = []\n","    budget = 100\n","\n","    for i in range(k, min_length):\n","        m_plus = np.mean(mid_prices[i+1:i+k+1])\n","        lt = (m_plus - mid_prices[i]) / mid_prices[i]\n","\n","        pred_class = np.argmax(predictions[i])\n","        max_prob = np.max(predictions[i])\n","\n","        if max_prob > prob_threshold and pred_class != 1:\n","            actual_direction = 1 if lt > alpha else (-1 if lt < -alpha else 0)\n","            shares = budget / mid_prices[i]\n","\n","            if pred_class == 2:  # Long trade\n","                cost = shares * mid_prices[i]\n","                proceeds = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'up',\n","                    'profit': profit,\n","                    'correct': actual_direction == 1\n","                })\n","            elif pred_class == 0:  # Short trade\n","                proceeds = shares * mid_prices[i]\n","                cost = shares * m_plus\n","                profit = proceeds - cost\n","                trades_info.append({\n","                    'movement': 'down',\n","                    'profit': profit,\n","                    'correct': actual_direction == -1\n","                })\n","\n","    if trades_info:\n","        trades_df = pd.DataFrame(trades_info)\n","        return {\n","            'threshold': prob_threshold,\n","            'total_profit': trades_df['profit'].sum(),\n","            'num_trades': len(trades_df),\n","            'win_rate': trades_df['correct'].mean() * 100,\n","            'avg_profit': trades_df['profit'].mean(),\n","            'long_trades': len(trades_df[trades_df['movement'] == 'up']),\n","            'short_trades': len(trades_df[trades_df['movement'] == 'down'])\n","        }\n","    return None\n","\n","epsilon_values = [0.01, 0.1, 1, 10]\n","results_pgd, results_fgsm = run_adversarial_trading_analysis(\n","    model=lstm2,\n","    testX_CNN=testX_CNN,\n","    testY_CNN=testY_CNN,\n","    dec_test=dec_test,\n","    epsilon_values=epsilon_values,\n","    batch_size=2000\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab2dgikxkhgN","executionInfo":{"status":"ok","timestamp":1741412976433,"user_tz":300,"elapsed":376219,"user":{"displayName":"HFT ResearchPSU","userId":"06323769305056854517"}},"outputId":"63e3865b-499f-4019-e7b5-ef6eaa7d7ad1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Analyzing epsilon: 0.01\n","Batch 1/69 - PGD volume: 0.009347, FGSM volume: 0.036556\n","Batch 2/69 - PGD volume: 0.009798, FGSM volume: 0.041113\n","Batch 3/69 - PGD volume: 0.009968, FGSM volume: 0.043195\n","Batch 4/69 - PGD volume: 0.009954, FGSM volume: 0.043010\n","Batch 5/69 - PGD volume: 0.009981, FGSM volume: 0.043341\n","Batch 6/69 - PGD volume: 0.009975, FGSM volume: 0.043549\n","Batch 7/69 - PGD volume: 0.009963, FGSM volume: 0.043866\n","Batch 8/69 - PGD volume: 0.009961, FGSM volume: 0.043783\n","Batch 9/69 - PGD volume: 0.009967, FGSM volume: 0.043678\n","Batch 10/69 - PGD volume: 0.009980, FGSM volume: 0.043950\n","Batch 11/69 - PGD volume: 0.009938, FGSM volume: 0.043021\n","Batch 12/69 - PGD volume: 0.009951, FGSM volume: 0.043194\n","Batch 13/69 - PGD volume: 0.009954, FGSM volume: 0.043039\n","Batch 14/69 - PGD volume: 0.009945, FGSM volume: 0.043432\n","Batch 15/69 - PGD volume: 0.009951, FGSM volume: 0.043208\n","Batch 16/69 - PGD volume: 0.009971, FGSM volume: 0.043737\n","Batch 17/69 - PGD volume: 0.009852, FGSM volume: 0.040464\n","Batch 18/69 - PGD volume: 0.009671, FGSM volume: 0.036414\n","Batch 19/69 - PGD volume: 0.009660, FGSM volume: 0.036660\n","Batch 20/69 - PGD volume: 0.009646, FGSM volume: 0.036469\n","Batch 21/69 - PGD volume: 0.009690, FGSM volume: 0.036855\n","Batch 22/69 - PGD volume: 0.009663, FGSM volume: 0.036611\n","Batch 23/69 - PGD volume: 0.009662, FGSM volume: 0.036466\n","Batch 24/69 - PGD volume: 0.009661, FGSM volume: 0.038097\n","Batch 25/69 - PGD volume: 0.009665, FGSM volume: 0.037543\n","Batch 26/69 - PGD volume: 0.009695, FGSM volume: 0.037791\n","Batch 27/69 - PGD volume: 0.009684, FGSM volume: 0.036956\n","Batch 28/69 - PGD volume: 0.009560, FGSM volume: 0.035932\n","Batch 29/69 - PGD volume: 0.009618, FGSM volume: 0.038567\n","Batch 30/69 - PGD volume: 0.009981, FGSM volume: 0.043440\n","Batch 31/69 - PGD volume: 0.009963, FGSM volume: 0.042710\n","Batch 32/69 - PGD volume: 0.009985, FGSM volume: 0.043162\n","Batch 33/69 - PGD volume: 0.009983, FGSM volume: 0.042572\n","Batch 34/69 - PGD volume: 0.009983, FGSM volume: 0.043909\n","Batch 35/69 - PGD volume: 0.009981, FGSM volume: 0.044042\n","Batch 36/69 - PGD volume: 0.009956, FGSM volume: 0.043960\n","Batch 37/69 - PGD volume: 0.009955, FGSM volume: 0.043535\n","Batch 38/69 - PGD volume: 0.009984, FGSM volume: 0.043813\n","Batch 39/69 - PGD volume: 0.009962, FGSM volume: 0.043624\n","Batch 40/69 - PGD volume: 0.009972, FGSM volume: 0.043300\n","Batch 41/69 - PGD volume: 0.009979, FGSM volume: 0.043525\n","Batch 42/69 - PGD volume: 0.009970, FGSM volume: 0.043348\n","Batch 43/69 - PGD volume: 0.009963, FGSM volume: 0.043290\n","Batch 44/69 - PGD volume: 0.009959, FGSM volume: 0.043488\n","Batch 45/69 - PGD volume: 0.009854, FGSM volume: 0.041080\n","Batch 46/69 - PGD volume: 0.009664, FGSM volume: 0.036193\n","Batch 47/69 - PGD volume: 0.009640, FGSM volume: 0.036719\n","Batch 48/69 - PGD volume: 0.009640, FGSM volume: 0.037124\n","Batch 49/69 - PGD volume: 0.009525, FGSM volume: 0.036011\n","Batch 50/69 - PGD volume: 0.009560, FGSM volume: 0.036550\n","Batch 51/69 - PGD volume: 0.009687, FGSM volume: 0.036701\n","Batch 52/69 - PGD volume: 0.009686, FGSM volume: 0.037033\n","Batch 53/69 - PGD volume: 0.009623, FGSM volume: 0.036568\n","Batch 54/69 - PGD volume: 0.009665, FGSM volume: 0.036596\n","Batch 55/69 - PGD volume: 0.009581, FGSM volume: 0.038426\n","Batch 56/69 - PGD volume: 0.009966, FGSM volume: 0.043539\n","Batch 57/69 - PGD volume: 0.009981, FGSM volume: 0.043482\n","Batch 58/69 - PGD volume: 0.009984, FGSM volume: 0.043791\n","Batch 59/69 - PGD volume: 0.009988, FGSM volume: 0.044086\n","Batch 60/69 - PGD volume: 0.009988, FGSM volume: 0.044174\n","Batch 61/69 - PGD volume: 0.009965, FGSM volume: 0.043534\n","Batch 62/69 - PGD volume: 0.009963, FGSM volume: 0.043558\n","Batch 63/69 - PGD volume: 0.009959, FGSM volume: 0.043673\n","Batch 64/69 - PGD volume: 0.009730, FGSM volume: 0.036436\n","Batch 65/69 - PGD volume: 0.009711, FGSM volume: 0.037246\n","Batch 66/69 - PGD volume: 0.009686, FGSM volume: 0.036646\n","Batch 67/69 - PGD volume: 0.009722, FGSM volume: 0.036829\n","Batch 68/69 - PGD volume: 0.009726, FGSM volume: 0.036433\n","Batch 69/69 - PGD volume: 0.009708, FGSM volume: 0.036878\n","\n","Analyzing epsilon: 0.1\n","Batch 1/69 - PGD volume: 0.095945, FGSM volume: 0.317808\n","Batch 2/69 - PGD volume: 0.097265, FGSM volume: 0.333232\n","Batch 3/69 - PGD volume: 0.097938, FGSM volume: 0.337808\n","Batch 4/69 - PGD volume: 0.098074, FGSM volume: 0.342564\n","Batch 5/69 - PGD volume: 0.097585, FGSM volume: 0.335469\n","Batch 6/69 - PGD volume: 0.098049, FGSM volume: 0.342229\n","Batch 7/69 - PGD volume: 0.098316, FGSM volume: 0.346260\n","Batch 8/69 - PGD volume: 0.098084, FGSM volume: 0.340951\n","Batch 9/69 - PGD volume: 0.098181, FGSM volume: 0.341251\n","Batch 10/69 - PGD volume: 0.098207, FGSM volume: 0.342331\n","Batch 11/69 - PGD volume: 0.097289, FGSM volume: 0.330288\n","Batch 12/69 - PGD volume: 0.097612, FGSM volume: 0.336851\n","Batch 13/69 - PGD volume: 0.096878, FGSM volume: 0.333772\n","Batch 14/69 - PGD volume: 0.097779, FGSM volume: 0.337233\n","Batch 15/69 - PGD volume: 0.097741, FGSM volume: 0.333704\n","Batch 16/69 - PGD volume: 0.097022, FGSM volume: 0.333187\n","Batch 17/69 - PGD volume: 0.096806, FGSM volume: 0.327845\n","Batch 18/69 - PGD volume: 0.096061, FGSM volume: 0.320539\n","Batch 19/69 - PGD volume: 0.095843, FGSM volume: 0.323845\n","Batch 20/69 - PGD volume: 0.095904, FGSM volume: 0.327070\n","Batch 21/69 - PGD volume: 0.095474, FGSM volume: 0.320883\n","Batch 22/69 - PGD volume: 0.095839, FGSM volume: 0.322846\n","Batch 23/69 - PGD volume: 0.095977, FGSM volume: 0.326649\n","Batch 24/69 - PGD volume: 0.095435, FGSM volume: 0.327635\n","Batch 25/69 - PGD volume: 0.095716, FGSM volume: 0.323628\n","Batch 26/69 - PGD volume: 0.095554, FGSM volume: 0.326149\n","Batch 27/69 - PGD volume: 0.095770, FGSM volume: 0.324453\n","Batch 28/69 - PGD volume: 0.096042, FGSM volume: 0.320931\n","Batch 29/69 - PGD volume: 0.096763, FGSM volume: 0.325247\n","Batch 30/69 - PGD volume: 0.097864, FGSM volume: 0.341139\n","Batch 31/69 - PGD volume: 0.097403, FGSM volume: 0.337178\n","Batch 32/69 - PGD volume: 0.097669, FGSM volume: 0.336794\n","Batch 33/69 - PGD volume: 0.097489, FGSM volume: 0.336847\n","Batch 34/69 - PGD volume: 0.097863, FGSM volume: 0.337765\n","Batch 35/69 - PGD volume: 0.098280, FGSM volume: 0.345390\n","Batch 36/69 - PGD volume: 0.098322, FGSM volume: 0.347623\n","Batch 37/69 - PGD volume: 0.097943, FGSM volume: 0.343777\n","Batch 38/69 - PGD volume: 0.097957, FGSM volume: 0.336773\n","Batch 39/69 - PGD volume: 0.098087, FGSM volume: 0.343025\n","Batch 40/69 - PGD volume: 0.097546, FGSM volume: 0.338502\n","Batch 41/69 - PGD volume: 0.097718, FGSM volume: 0.332146\n","Batch 42/69 - PGD volume: 0.097625, FGSM volume: 0.335991\n","Batch 43/69 - PGD volume: 0.097713, FGSM volume: 0.338981\n","Batch 44/69 - PGD volume: 0.097699, FGSM volume: 0.335939\n","Batch 45/69 - PGD volume: 0.097251, FGSM volume: 0.333397\n","Batch 46/69 - PGD volume: 0.096116, FGSM volume: 0.320741\n","Batch 47/69 - PGD volume: 0.096050, FGSM volume: 0.322263\n","Batch 48/69 - PGD volume: 0.095684, FGSM volume: 0.324927\n","Batch 49/69 - PGD volume: 0.096076, FGSM volume: 0.323137\n","Batch 50/69 - PGD volume: 0.096093, FGSM volume: 0.323589\n","Batch 51/69 - PGD volume: 0.096017, FGSM volume: 0.323005\n","Batch 52/69 - PGD volume: 0.096069, FGSM volume: 0.328183\n","Batch 53/69 - PGD volume: 0.095887, FGSM volume: 0.327614\n","Batch 54/69 - PGD volume: 0.095893, FGSM volume: 0.321366\n","Batch 55/69 - PGD volume: 0.096491, FGSM volume: 0.323626\n","Batch 56/69 - PGD volume: 0.098160, FGSM volume: 0.339856\n","Batch 57/69 - PGD volume: 0.098239, FGSM volume: 0.344783\n","Batch 58/69 - PGD volume: 0.098263, FGSM volume: 0.346650\n","Batch 59/69 - PGD volume: 0.098387, FGSM volume: 0.345287\n","Batch 60/69 - PGD volume: 0.098625, FGSM volume: 0.354236\n","Batch 61/69 - PGD volume: 0.097852, FGSM volume: 0.336230\n","Batch 62/69 - PGD volume: 0.097814, FGSM volume: 0.336896\n","Batch 63/69 - PGD volume: 0.097825, FGSM volume: 0.334836\n","Batch 64/69 - PGD volume: 0.095900, FGSM volume: 0.319602\n","Batch 65/69 - PGD volume: 0.095851, FGSM volume: 0.323940\n","Batch 66/69 - PGD volume: 0.095866, FGSM volume: 0.319920\n","Batch 67/69 - PGD volume: 0.095609, FGSM volume: 0.321482\n","Batch 68/69 - PGD volume: 0.095660, FGSM volume: 0.323101\n","Batch 69/69 - PGD volume: 0.095535, FGSM volume: 0.320771\n","\n","Analyzing epsilon: 1\n","Batch 1/69 - PGD volume: 0.138223, FGSM volume: 3.153496\n","Batch 2/69 - PGD volume: 0.152122, FGSM volume: 3.059651\n","Batch 3/69 - PGD volume: 0.158426, FGSM volume: 3.076681\n","Batch 4/69 - PGD volume: 0.157140, FGSM volume: 3.080697\n","Batch 5/69 - PGD volume: 0.151412, FGSM volume: 3.082915\n","Batch 6/69 - PGD volume: 0.157268, FGSM volume: 3.109885\n","Batch 7/69 - PGD volume: 0.160690, FGSM volume: 3.075386\n","Batch 8/69 - PGD volume: 0.155762, FGSM volume: 3.067265\n","Batch 9/69 - PGD volume: 0.156502, FGSM volume: 3.076102\n","Batch 10/69 - PGD volume: 0.155881, FGSM volume: 3.068432\n","Batch 11/69 - PGD volume: 0.149944, FGSM volume: 3.062668\n","Batch 12/69 - PGD volume: 0.150052, FGSM volume: 3.120986\n","Batch 13/69 - PGD volume: 0.141870, FGSM volume: 3.123224\n","Batch 14/69 - PGD volume: 0.149946, FGSM volume: 3.104710\n","Batch 15/69 - PGD volume: 0.149286, FGSM volume: 3.087984\n","Batch 16/69 - PGD volume: 0.145889, FGSM volume: 3.106388\n","Batch 17/69 - PGD volume: 0.143676, FGSM volume: 3.143147\n","Batch 18/69 - PGD volume: 0.135847, FGSM volume: 3.178693\n","Batch 19/69 - PGD volume: 0.131456, FGSM volume: 3.214848\n","Batch 20/69 - PGD volume: 0.129441, FGSM volume: 3.250757\n","Batch 21/69 - PGD volume: 0.126058, FGSM volume: 3.181050\n","Batch 22/69 - PGD volume: 0.131201, FGSM volume: 3.203019\n","Batch 23/69 - PGD volume: 0.130265, FGSM volume: 3.245451\n","Batch 24/69 - PGD volume: 0.123209, FGSM volume: 3.241576\n","Batch 25/69 - PGD volume: 0.128338, FGSM volume: 3.203911\n","Batch 26/69 - PGD volume: 0.125046, FGSM volume: 3.224795\n","Batch 27/69 - PGD volume: 0.129453, FGSM volume: 3.219334\n","Batch 28/69 - PGD volume: 0.135553, FGSM volume: 3.186460\n","Batch 29/69 - PGD volume: 0.146570, FGSM volume: 3.104210\n","Batch 30/69 - PGD volume: 0.160838, FGSM volume: 3.052938\n","Batch 31/69 - PGD volume: 0.155479, FGSM volume: 3.099397\n","Batch 32/69 - PGD volume: 0.154711, FGSM volume: 3.083839\n","Batch 33/69 - PGD volume: 0.154753, FGSM volume: 3.090306\n","Batch 34/69 - PGD volume: 0.155252, FGSM volume: 3.056207\n","Batch 35/69 - PGD volume: 0.156653, FGSM volume: 3.090770\n","Batch 36/69 - PGD volume: 0.156817, FGSM volume: 3.113790\n","Batch 37/69 - PGD volume: 0.157298, FGSM volume: 3.087552\n","Batch 38/69 - PGD volume: 0.154892, FGSM volume: 3.084429\n","Batch 39/69 - PGD volume: 0.156321, FGSM volume: 3.065850\n","Batch 40/69 - PGD volume: 0.150431, FGSM volume: 3.101335\n","Batch 41/69 - PGD volume: 0.145711, FGSM volume: 3.019359\n","Batch 42/69 - PGD volume: 0.147415, FGSM volume: 3.060274\n","Batch 43/69 - PGD volume: 0.148587, FGSM volume: 3.102023\n","Batch 44/69 - PGD volume: 0.150873, FGSM volume: 3.080926\n","Batch 45/69 - PGD volume: 0.147735, FGSM volume: 3.153227\n","Batch 46/69 - PGD volume: 0.135974, FGSM volume: 3.181639\n","Batch 47/69 - PGD volume: 0.134796, FGSM volume: 3.196753\n","Batch 48/69 - PGD volume: 0.128037, FGSM volume: 3.222351\n","Batch 49/69 - PGD volume: 0.131302, FGSM volume: 3.208037\n","Batch 50/69 - PGD volume: 0.133493, FGSM volume: 3.211585\n","Batch 51/69 - PGD volume: 0.131930, FGSM volume: 3.201077\n","Batch 52/69 - PGD volume: 0.128815, FGSM volume: 3.255528\n","Batch 53/69 - PGD volume: 0.126529, FGSM volume: 3.252659\n","Batch 54/69 - PGD volume: 0.134046, FGSM volume: 3.186228\n","Batch 55/69 - PGD volume: 0.144182, FGSM volume: 3.130565\n","Batch 56/69 - PGD volume: 0.160670, FGSM volume: 3.068462\n","Batch 57/69 - PGD volume: 0.159102, FGSM volume: 3.053800\n","Batch 58/69 - PGD volume: 0.159016, FGSM volume: 3.031841\n","Batch 59/69 - PGD volume: 0.160121, FGSM volume: 3.067627\n","Batch 60/69 - PGD volume: 0.161742, FGSM volume: 3.070635\n","Batch 61/69 - PGD volume: 0.156523, FGSM volume: 3.083638\n","Batch 62/69 - PGD volume: 0.155237, FGSM volume: 3.090238\n","Batch 63/69 - PGD volume: 0.152696, FGSM volume: 3.087950\n","Batch 64/69 - PGD volume: 0.131022, FGSM volume: 3.149871\n","Batch 65/69 - PGD volume: 0.131620, FGSM volume: 3.208520\n","Batch 66/69 - PGD volume: 0.132079, FGSM volume: 3.165228\n","Batch 67/69 - PGD volume: 0.130596, FGSM volume: 3.187762\n","Batch 68/69 - PGD volume: 0.127968, FGSM volume: 3.210002\n","Batch 69/69 - PGD volume: 0.128879, FGSM volume: 3.179981\n","\n","Analyzing epsilon: 10\n","Batch 1/69 - PGD volume: 0.138000, FGSM volume: 3.153496\n","Batch 2/69 - PGD volume: 0.152109, FGSM volume: 3.059651\n","Batch 3/69 - PGD volume: 0.158326, FGSM volume: 3.076681\n","Batch 4/69 - PGD volume: 0.156880, FGSM volume: 3.080697\n","Batch 5/69 - PGD volume: 0.151350, FGSM volume: 3.082915\n","Batch 6/69 - PGD volume: 0.157238, FGSM volume: 3.109885\n","Batch 7/69 - PGD volume: 0.160333, FGSM volume: 3.075386\n","Batch 8/69 - PGD volume: 0.155313, FGSM volume: 3.067265\n","Batch 9/69 - PGD volume: 0.156704, FGSM volume: 3.076102\n","Batch 10/69 - PGD volume: 0.155857, FGSM volume: 3.068432\n","Batch 11/69 - PGD volume: 0.150271, FGSM volume: 3.062668\n","Batch 12/69 - PGD volume: 0.149798, FGSM volume: 3.120986\n","Batch 13/69 - PGD volume: 0.142321, FGSM volume: 3.123224\n","Batch 14/69 - PGD volume: 0.150334, FGSM volume: 3.104710\n","Batch 15/69 - PGD volume: 0.149132, FGSM volume: 3.087984\n","Batch 16/69 - PGD volume: 0.146001, FGSM volume: 3.106388\n","Batch 17/69 - PGD volume: 0.143954, FGSM volume: 3.143147\n","Batch 18/69 - PGD volume: 0.135834, FGSM volume: 3.178693\n","Batch 19/69 - PGD volume: 0.131628, FGSM volume: 3.214848\n","Batch 20/69 - PGD volume: 0.129215, FGSM volume: 3.250757\n","Batch 21/69 - PGD volume: 0.125928, FGSM volume: 3.181050\n","Batch 22/69 - PGD volume: 0.131301, FGSM volume: 3.203019\n","Batch 23/69 - PGD volume: 0.130932, FGSM volume: 3.245451\n","Batch 24/69 - PGD volume: 0.123678, FGSM volume: 3.241576\n","Batch 25/69 - PGD volume: 0.128711, FGSM volume: 3.203911\n","Batch 26/69 - PGD volume: 0.124959, FGSM volume: 3.224795\n","Batch 27/69 - PGD volume: 0.129255, FGSM volume: 3.219334\n","Batch 28/69 - PGD volume: 0.135617, FGSM volume: 3.186460\n","Batch 29/69 - PGD volume: 0.145931, FGSM volume: 3.104210\n","Batch 30/69 - PGD volume: 0.161318, FGSM volume: 3.052938\n","Batch 31/69 - PGD volume: 0.155619, FGSM volume: 3.099397\n","Batch 32/69 - PGD volume: 0.154639, FGSM volume: 3.083839\n","Batch 33/69 - PGD volume: 0.155039, FGSM volume: 3.090306\n","Batch 34/69 - PGD volume: 0.155395, FGSM volume: 3.056207\n","Batch 35/69 - PGD volume: 0.156808, FGSM volume: 3.090770\n","Batch 36/69 - PGD volume: 0.156865, FGSM volume: 3.113790\n","Batch 37/69 - PGD volume: 0.157317, FGSM volume: 3.087552\n","Batch 38/69 - PGD volume: 0.154887, FGSM volume: 3.084429\n","Batch 39/69 - PGD volume: 0.156473, FGSM volume: 3.065850\n","Batch 40/69 - PGD volume: 0.150454, FGSM volume: 3.101335\n","Batch 41/69 - PGD volume: 0.146378, FGSM volume: 3.019359\n","Batch 42/69 - PGD volume: 0.147370, FGSM volume: 3.060274\n","Batch 43/69 - PGD volume: 0.148323, FGSM volume: 3.102023\n","Batch 44/69 - PGD volume: 0.150811, FGSM volume: 3.080926\n","Batch 45/69 - PGD volume: 0.147631, FGSM volume: 3.153227\n","Batch 46/69 - PGD volume: 0.135883, FGSM volume: 3.181639\n","Batch 47/69 - PGD volume: 0.134786, FGSM volume: 3.196753\n","Batch 48/69 - PGD volume: 0.128667, FGSM volume: 3.222351\n","Batch 49/69 - PGD volume: 0.131419, FGSM volume: 3.208037\n","Batch 50/69 - PGD volume: 0.132867, FGSM volume: 3.211585\n","Batch 51/69 - PGD volume: 0.131566, FGSM volume: 3.201077\n","Batch 52/69 - PGD volume: 0.128602, FGSM volume: 3.255528\n","Batch 53/69 - PGD volume: 0.126325, FGSM volume: 3.252659\n","Batch 54/69 - PGD volume: 0.134364, FGSM volume: 3.186228\n","Batch 55/69 - PGD volume: 0.143886, FGSM volume: 3.130565\n","Batch 56/69 - PGD volume: 0.160376, FGSM volume: 3.068462\n","Batch 57/69 - PGD volume: 0.158571, FGSM volume: 3.053800\n","Batch 58/69 - PGD volume: 0.158935, FGSM volume: 3.031841\n","Batch 59/69 - PGD volume: 0.160554, FGSM volume: 3.067627\n","Batch 60/69 - PGD volume: 0.161959, FGSM volume: 3.070635\n","Batch 61/69 - PGD volume: 0.156695, FGSM volume: 3.083638\n","Batch 62/69 - PGD volume: 0.155536, FGSM volume: 3.090238\n","Batch 63/69 - PGD volume: 0.152987, FGSM volume: 3.087950\n","Batch 64/69 - PGD volume: 0.131800, FGSM volume: 3.149871\n","Batch 65/69 - PGD volume: 0.131274, FGSM volume: 3.208520\n","Batch 66/69 - PGD volume: 0.131573, FGSM volume: 3.165228\n","Batch 67/69 - PGD volume: 0.129997, FGSM volume: 3.187762\n","Batch 68/69 - PGD volume: 0.127563, FGSM volume: 3.210002\n","Batch 69/69 - PGD volume: 0.128368, FGSM volume: 3.179981\n","\n","PGD Attack Summary by Threshold:\n","\n","PGD Analysis Results:\n","\n","Epsilon: 0.01\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         155.5605  12022.0000    0.5490\n","0.9000          82.6659   7747.0000    0.5680\n","0.9500          -5.0054   3947.0000    0.5067\n","0.9900          -0.7151    757.0000    0.6605\n","\n","Epsilon: 0.1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         156.0651  11327.0000    0.5562\n","0.9000          32.8723   7072.0000    0.5373\n","0.9500          -3.4636   3409.0000    0.5573\n","0.9900          -0.9320    591.0000    0.3384\n","\n","Epsilon: 1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         115.8055  11132.0000    0.5210\n","0.9000           5.2292   6850.0000    0.5255\n","0.9500          -2.5806   3166.0000    0.6317\n","0.9900          -0.8447    542.0000    0.3690\n","\n","Epsilon: 10\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         116.3033  11139.0000    0.5117\n","0.9000           4.8690   6834.0000    0.5268\n","0.9500          -2.8135   3190.0000    0.6270\n","0.9900          -0.8234    539.0000    0.3711\n","\n","FGSM Attack Summary by Threshold:\n","\n","FGSM Analysis Results:\n","\n","Epsilon: 0.01\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500         155.4706  11684.0000    0.5478\n","0.9000          57.6477   7437.0000    0.5647\n","0.9500          -4.9058   3727.0000    0.5098\n","0.9900          -0.6606    692.0000    0.5780\n","\n","Epsilon: 0.1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500          65.7872  12023.0000    0.4408\n","0.9000          -3.2498   6969.0000    0.4018\n","0.9500          -1.2246   2941.0000    0.5780\n","0.9900          -1.1641    429.0000    0.0000\n","\n","Epsilon: 1\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500        -252.2165  94017.0000    0.4372\n","0.9000        -250.7744  83309.0000    0.4573\n","0.9500         423.1290  55916.0000    0.5061\n","0.9900          34.0725   8373.0000    0.3225\n","\n","Epsilon: 10\n","           total_profit  num_trades  win_rate\n","threshold                                    \n","0.8500        -252.2165  94017.0000    0.4372\n","0.9000        -250.7744  83309.0000    0.4573\n","0.9500         423.1290  55916.0000    0.5061\n","0.9900          34.0725   8373.0000    0.3225\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"x3DrBPxBmF-M"},"execution_count":null,"outputs":[]}]}